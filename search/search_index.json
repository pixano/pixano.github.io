{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Pixano Documentation!","text":"<p>Pixano is a library of data-centric AI building blocks for computer vision applications.</p> <p>Get started</p> <p>Check out the API reference</p> <p>Check out the Pixano Inference documentation</p>"},{"location":"code/","title":"Pixano API reference","text":"<p>Here you will find the documentation for all of our Python API.</p> <ul> <li>The analytics module contains useful functions for computing statistics on a dataset.</li> <li>The api module contains the API functions to send relevant data to the User Interface.</li> <li>The apps module contains the Pixano Explorer and Annotator Apps.</li> <li>The core module contains the Pixano custom data types and their corresponding PyArrow types.</li> <li>The data module contains the Pixano Datasets, as well as the Importers and Exporters for importing and exporting datasets.</li> <li>The models module contains the Pixano InferenceModel for inference generation and embedding precomputing.</li> <li>The utils module contains many useful functions to work with images, bounding boxes, and labels.</li> </ul>"},{"location":"code/SUMMARY/","title":"SUMMARY","text":"<ul> <li>index</li> <li>analytics<ul> <li>feature_statistics</li> </ul> </li> <li>api<ul> <li>datasets</li> <li>items</li> </ul> </li> <li>apps<ul> <li>annotator<ul> <li>serve</li> </ul> </li> <li>display</li> <li>explorer<ul> <li>serve</li> </ul> </li> <li>main</li> <li>serve</li> </ul> </li> <li>core<ul> <li>bbox</li> <li>camera</li> <li>compressed_rle</li> <li>depth_image</li> <li>gt_info</li> <li>image</li> <li>pixano_type</li> <li>pose</li> <li>utils</li> </ul> </li> <li>data<ul> <li>dataset</li> <li>dataset_info</li> <li>exporters<ul> <li>coco_exporter</li> <li>exporter</li> </ul> </li> <li>fields</li> <li>importers<ul> <li>coco_importer</li> <li>dota_importer</li> <li>image_importer</li> <li>importer</li> </ul> </li> </ul> </li> <li>models<ul> <li>inference_model</li> </ul> </li> <li>utils<ul> <li>boxes</li> <li>image</li> <li>labels</li> <li>python</li> </ul> </li> </ul>"},{"location":"code/analytics/feature_statistics/","title":"feature_statistics","text":""},{"location":"code/analytics/feature_statistics/#pixano.analytics.feature_statistics","title":"<code>pixano.analytics.feature_statistics</code>","text":""},{"location":"code/analytics/feature_statistics/#pixano.analytics.feature_statistics.categorical_stats","title":"<code>categorical_stats(df, split, field_name)</code>","text":"<p>Compute feature categorical statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>field_name</code> <code>str</code> <p>Selected field</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def categorical_stats(df: pd.DataFrame, split: str, field_name: str) -&gt; list[dict]:\n    \"\"\"Compute feature categorical statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        field_name (str): Selected field\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    counts = df.value_counts(subset=field_name)\n    return [{field_name: k, \"counts\": v, \"split\": split} for k, v in counts.items()]\n</code></pre>"},{"location":"code/analytics/feature_statistics/#pixano.analytics.feature_statistics.compute_additional_data","title":"<code>compute_additional_data(data_table)</code>","text":"<p>Convert Table to DataFrame and add resolution and aspect ratio</p> <p>Parameters:</p> Name Type Description Default <code>data_table</code> <code>Table</code> <p>Input Table</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with added resolution and aspect ratio</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def compute_additional_data(data_table: pa.Table) -&gt; pd.DataFrame:\n    \"\"\"Convert Table to DataFrame and add resolution and aspect ratio\n\n    Args:\n        data_table (pa.Table): Input Table\n\n    Returns:\n        pd.DataFrame: DataFrame with added resolution and aspect ratio\n    \"\"\"\n\n    # Take a subset of table without image columns (which can't be converted to pandas)\n    if not all(p in data_table.column_names for p in [\"width\", \"height\"]):\n        return None\n    data = data_table.select([\"width\", \"height\"]).to_pandas()\n\n    # Compute additional data\n    data[\"resolution\"] = data.apply(\n        lambda x: str(x[\"width\"]) + \"x\" + str(x[\"height\"]), axis=1\n    )\n    data[\"aspect_ratio\"] = data.apply(\n        lambda x: str(Fraction(x[\"width\"], x[\"height\"])).replace(\"/\", \":\"), axis=1\n    )\n\n    return data\n</code></pre>"},{"location":"code/analytics/feature_statistics/#pixano.analytics.feature_statistics.compute_stats","title":"<code>compute_stats(df, split, feature)</code>","text":"<p>Compute feature statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>feature</code> <code>dict</code> <p>Selected feature</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def compute_stats(df: pd.DataFrame, split: str, feature: dict[str, Any]) -&gt; list[dict]:\n    \"\"\"Compute feature statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        feature (dict): Selected feature\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    # Categorical\n    if feature[\"type\"] == \"categorical\":\n        return categorical_stats(df, split, feature[\"name\"])\n    # Numerical\n    elif feature[\"type\"] == \"numerical\":\n        return numerical_stats(df, split, feature[\"name\"], feature.get(\"range\", None))\n    # Else\n    else:\n        return []\n</code></pre>"},{"location":"code/analytics/feature_statistics/#pixano.analytics.feature_statistics.numerical_stats","title":"<code>numerical_stats(df, split, field_name, field_range=None)</code>","text":"<p>Compute feature numerical statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>field_name</code> <code>str</code> <p>Selected field</p> required <code>field_range</code> <code>list[float]</code> <p>Selected field range. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def numerical_stats(\n    df: pd.DataFrame, split: str, field_name: str, field_range: list[float] = None\n) -&gt; list[dict]:\n    \"\"\"Compute feature numerical statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        field_name (str): Selected field\n        field_range (list[float], optional): Selected field range. Defaults to None.\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    counts, bins = np.histogram(df[field_name], range=field_range)\n    return [\n        {\n            \"bin_start\": float(bins[i]),\n            \"bin_end\": float(bins[i + 1]),\n            \"counts\": int(counts[i]),\n            \"split\": split,\n        }\n        for i in range(len(counts))\n    ]\n</code></pre>"},{"location":"code/analytics/feature_statistics/#pixano.analytics.feature_statistics.objects_table_to_df","title":"<code>objects_table_to_df(data_table, field)</code>","text":"<p>Convert a field from the objects column to a DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>data_table</code> <code>Table</code> <p>Table with an objects column</p> required <code>field</code> <code>str</code> <p>Selected field from the objects column</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Selected field as DataFrame</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def objects_table_to_df(data_table: pa.Table, field: str) -&gt; pd.DataFrame:\n    \"\"\"Convert a field from the objects column to a DataFrame\n\n    Args:\n        data_table (pa.Table): Table with an objects column\n        field (str): Selected field from the objects column\n\n    Returns:\n        pd.DataFrame: Selected field as DataFrame\n    \"\"\"\n\n    try:\n        df_objs = data_table.select([\"objects\"]).to_pandas()\n        sel = [{field: d[field]} for objs in df_objs[\"objects\"] for d in objs]\n        return pd.DataFrame.from_dict(sel)\n    except ValueError as e:\n        raise ValueError(\"Unable to convert table Pandas DataFrame\") from e\n</code></pre>"},{"location":"code/api/datasets/","title":"datasets","text":""},{"location":"code/api/datasets/#pixano.api.datasets","title":"<code>pixano.api.datasets</code>","text":""},{"location":"code/api/datasets/#pixano.api.datasets.Settings","title":"<code>Settings</code>","text":"<p>             Bases: <code>BaseSettings</code></p> <p>Dataset library settings</p> <p>Attributes:</p> Name Type Description <code>data_dir</code> <code>Path</code> <p>Dataset library directory</p>"},{"location":"code/api/datasets/#pixano.api.datasets.load_dataset","title":"<code>load_dataset(ds_id, settings)</code>","text":"<p>Load dataset based on its ID</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>settings</code> <code>Settings</code> <p>Dataset library</p> required <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset</p> Source code in <code>pixano/api/datasets.py</code> <pre><code>def load_dataset(ds_id: str, settings: Settings) -&gt; Dataset:\n    \"\"\"Load dataset based on its ID\n\n    Args:\n        ds_id (str): Dataset ID\n        settings (Settings): Dataset library\n\n    Returns:\n        Dataset: Dataset\n    \"\"\"\n\n    for json_file in settings.data_dir.glob(\"*/db.json\"):\n        info = DatasetInfo.from_json(json_file)\n        if ds_id == info.id:\n            return Dataset(json_file.parent)\n</code></pre>"},{"location":"code/api/datasets/#pixano.api.datasets.load_dataset_list","title":"<code>load_dataset_list(settings)</code>","text":"<p>Load all dataset info files in library</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>Dataset library settings</p> required <p>Returns:</p> Type Description <code>list[DatasetInfo]</code> <p>Dataset info files</p> Source code in <code>pixano/api/datasets.py</code> <pre><code>def load_dataset_list(settings: Settings) -&gt; list[DatasetInfo]:\n    \"\"\"Load all dataset info files in library\n\n    Args:\n        settings (Settings): Dataset library settings\n\n    Returns:\n        list[DatasetInfo]: Dataset info files\n    \"\"\"\n\n    infos = []\n    for json_file in sorted(settings.data_dir.glob(\"*/db.json\")):\n        # Load dataset info\n        info = DatasetInfo.from_json(json_file)\n        # Load thumbnail\n        preview_path = json_file.parent / \"preview.png\"\n        if preview_path.is_file():\n            im = Image(uri=preview_path.absolute().as_uri())\n            info.preview = im.url\n        # Load categories\n        info.categories = getattr(info, \"categories\", [])\n        if info.categories is None:\n            info.categories = []\n        # Save dataset info\n        infos.append(info)\n    return infos\n</code></pre>"},{"location":"code/api/datasets/#pixano.api.datasets.load_dataset_stats","title":"<code>load_dataset_stats(ds, settings)</code>","text":"<p>Load dataset stats based on its ID</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>Dataset</code> <p>Dataset</p> required <code>settings</code> <code>Settings</code> <p>Dataset Library</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Dataset stats</p> Source code in <code>pixano/api/datasets.py</code> <pre><code>def load_dataset_stats(ds: Dataset, settings: Settings) -&gt; dict:\n    \"\"\"Load dataset stats based on its ID\n\n    Args:\n        ds (Dataset): Dataset\n        settings (Settings): Dataset Library\n\n    Returns:\n        list[dict]: Dataset stats\n    \"\"\"\n\n    stats_file = ds.path / \"stats.json\"\n    if stats_file.is_file():\n        with open(stats_file, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n</code></pre>"},{"location":"code/api/items/","title":"items","text":""},{"location":"code/api/items/#pixano.api.items","title":"<code>pixano.api.items</code>","text":""},{"location":"code/api/items/#pixano.api.items.ItemFeature","title":"<code>ItemFeature(__pydantic_self__, **data)</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Feature</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Feature name</p> <code>dtype</code> <code>str</code> <p>Feature dtype</p> <code>value</code> <code>Any</code> <p>Feature value</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>__init__</code> uses <code>__pydantic_self__</code> instead of the more common <code>self</code> for the first arg to allow <code>self</code> as a field name.</p> Source code in <code></code> <pre><code>def __init__(__pydantic_self__, **data: Any) -&gt; None:  # type: ignore\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `__init__` uses `__pydantic_self__` instead of the more common `self` for the first arg to\n    allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\n</code></pre>"},{"location":"code/api/items/#pixano.api.items.load_item_details","title":"<code>load_item_details(dataset, item_id)</code>","text":"<p>Load dataset item details</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset</p> required <code>item_id</code> <code>str</code> <p>Selected item ID</p> required <p>Returns:</p> Type Description <code>dict</code> <p>ImageDetails features for UI</p> Source code in <code>pixano/api/items.py</code> <pre><code>def load_item_details(dataset: Dataset, item_id: str) -&gt; dict:\n    \"\"\"Load dataset item details\n\n    Args:\n        dataset (Dataset): Dataset\n        item_id (str): Selected item ID\n\n    Returns:\n        dict: ImageDetails features for UI\n    \"\"\"\n\n    # Load dataset\n    ds = dataset.connect()\n    main_table: lancedb.db.LanceTable = ds.open_table(\"db\")\n\n    media_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"media\" in dataset.info.tables:\n        for md_info in dataset.info.tables[\"media\"]:\n            media_tables[md_info[\"name\"]] = ds.open_table(md_info[\"name\"])\n\n    obj_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"objects\" in dataset.info.tables:\n        for obj_info in dataset.info.tables[\"objects\"]:\n            try:\n                obj_tables[obj_info[\"source\"]] = ds.open_table(obj_info[\"name\"])\n            except FileNotFoundError:\n                # Remove missing objects tables from DatasetInfo\n                dataset.info.tables[\"objects\"].remove(obj_info)\n                dataset.save_info()\n\n    al_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"active_learning\" in dataset.info.tables:\n        for al_info in dataset.info.tables[\"active_learning\"]:\n            try:\n                al_tables[al_info[\"source\"]] = ds.open_table(al_info[\"name\"])\n            except FileNotFoundError:\n                # Remove missing Active Learning tables from DatasetInfo\n                dataset.info.tables[\"active_learning\"].remove(al_info)\n                dataset.save_info()\n\n    # Get item\n    main_scanner = main_table.to_lance().scanner(filter=f\"id in ('{item_id}')\")\n    pyarrow_item = main_scanner.to_table()\n\n    for media_table in media_tables.values():\n        media_scanner = media_table.to_lance().scanner(filter=f\"id in ('{item_id}')\")\n        media_pyarrow_item = media_scanner.to_table()\n        pyarrow_item = duckdb.query(\n            \"SELECT * FROM pyarrow_item LEFT JOIN media_pyarrow_item USING (id)\"\n        ).to_arrow_table()\n\n    for al_table in al_tables.values():\n        al_scanner = al_table.to_lance().scanner(filter=f\"id in ('{item_id}')\")\n        al_pyarrow_item = al_scanner.to_table()\n        pyarrow_item = duckdb.query(\n            \"SELECT * FROM pyarrow_item LEFT JOIN al_pyarrow_item USING (id)\"\n        ).to_arrow_table()\n\n    item = pyarrow_item.to_pylist()[0]\n\n    # Get item objects\n    objects = {}\n    for obj_source, obj_table in obj_tables.items():\n        media_scanner = obj_table.to_lance().scanner(filter=f\"item_id in ('{item_id}')\")\n        objects[obj_source] = media_scanner.to_table().to_pylist()\n\n    # Create features\n    item_details = {\n        \"itemData\": {\n            \"id\": item[\"id\"],\n            \"views\": defaultdict(dict),\n            \"features\": _create_features(item, pyarrow_item.schema),\n        },\n        \"itemObjects\": defaultdict(lambda: defaultdict(list)),\n    }\n\n    # Iterate on view\n    for field in pyarrow_item.schema:\n        if field.name in item[\"views\"]:\n            # TODO: get type from db.json to handle other media like videos\n            if isinstance(item[field.name], dict):\n                item[field.name] = Image.from_dict(item[field.name])\n            image = item[field.name]\n            image.uri_prefix = dataset.media_dir.absolute().as_uri()\n            item_details[\"itemData\"][\"views\"][field.name] = {\n                \"id\": field.name,\n                \"url\": image.url,\n                \"height\": image.size[1],\n                \"width\": image.size[0],\n            }\n\n            for obj_source, obj_list in objects.items():\n                for obj in obj_list:\n                    # If object in view\n                    if obj[\"view_id\"] == field.name:\n                        # Object mask\n                        mask = obj[\"mask\"].to_urle() if \"mask\" in obj else None\n                        # Object bounding box\n                        bbox = (\n                            format_bbox(\n                                obj[\"bbox\"].xywh_coords,\n                                obj[\"bbox\"].confidence,\n                            )\n                            if \"bbox\" in obj\n                            else None\n                        )\n                        # Object category\n                        category = (\n                            {\"id\": obj[\"category_id\"], \"name\": obj[\"category_name\"]}\n                            if \"category_id\" in obj and \"category_name\" in obj\n                            else None\n                        )\n                        # Add object\n                        item_details[\"itemObjects\"][obj_source][field.name].append(\n                            {\n                                \"id\": obj[\"id\"],\n                                \"mask\": mask,\n                                \"bbox\": bbox,\n                                \"category\": category,\n                            }\n                        )\n\n    return item_details\n</code></pre>"},{"location":"code/api/items/#pixano.api.items.load_item_embeddings","title":"<code>load_item_embeddings(dataset, item_id)</code>","text":"<p>Load dataset item embeddings</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset</p> required <code>item_id</code> <code>str</code> <p>Selected item ID</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Item embeddings</p> Source code in <code>pixano/api/items.py</code> <pre><code>def load_item_embeddings(dataset: Dataset, item_id: str) -&gt; dict:\n    \"\"\"Load dataset item embeddings\n\n    Args:\n        dataset (Dataset): Dataset\n        item_id (str): Selected item ID\n\n    Returns:\n        dict: Item embeddings\n    \"\"\"\n\n    # Load dataset\n    ds = dataset.connect()\n\n    emb_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"embeddings\" in dataset.info.tables:\n        for emb_info in dataset.info.tables[\"embeddings\"]:\n            if emb_info[\"type\"] == \"segment\":\n                try:\n                    emb_tables[emb_info[\"source\"]] = ds.open_table(emb_info[\"name\"])\n                except FileNotFoundError:\n                    # Remove missing embeddings tables from DatasetInfo\n                    dataset.info.tables[\"embeddings\"].remove(emb_info)\n                    dataset.save_info()\n\n    # Get item embeddings\n    embeddings = {}\n    for emb_source, emb_table in emb_tables.items():\n        media_scanner = emb_table.to_lance().scanner(filter=f\"id in ('{item_id}')\")\n        embeddings[emb_source] = media_scanner.to_table().to_pylist()[0]\n\n    # Return first embeddings for first table containing SAM (Segment Anything Model)\n    # TODO: Add embeddings table select option\n    for emb_source in embeddings.keys():\n        if \"SAM\" in emb_source:\n            # Keep only embedding fields\n            embeddings[emb_source].pop(\"id\")\n            # Convert binary embeddings to b64 strings for FastAPI\n            for name, value in embeddings[emb_source].items():\n                if isinstance(value, bytes):\n                    embeddings[emb_source][name] = base64.b64encode(value).decode(\n                        \"ascii\"\n                    )\n            return embeddings[emb_source]\n</code></pre>"},{"location":"code/api/items/#pixano.api.items.load_items","title":"<code>load_items(dataset, params=None)</code>","text":"<p>Load dataset items</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset</p> required <code>params</code> <code>AbstractParams</code> <p>FastAPI params for pagination. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>AbstractPage</code> <p>List of ItemFeatures for UI (DatasetExplorer)</p> Source code in <code>pixano/api/items.py</code> <pre><code>def load_items(dataset: Dataset, params: AbstractParams = None) -&gt; AbstractPage:\n    \"\"\"Load dataset items\n\n    Args:\n        dataset (Dataset): Dataset\n        params (AbstractParams, optional): FastAPI params for pagination. Defaults to None.\n\n    Returns:\n        AbstractPage: List of ItemFeatures for UI (DatasetExplorer)\n    \"\"\"\n\n    # Load dataset\n    ds = dataset.connect()\n    main_table: lancedb.db.LanceTable = ds.open_table(\"db\")\n\n    media_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"media\" in dataset.info.tables:\n        for md_info in dataset.info.tables[\"media\"]:\n            media_tables[md_info[\"name\"]] = ds.open_table(md_info[\"name\"])\n\n    al_tables: list[lancedb.db.LanceTable] = []\n    if \"active_learning\" in dataset.info.tables:\n        for al_info in dataset.info.tables[\"active_learning\"]:\n            al_tables.append(ds.open_table(al_info[\"name\"]))\n\n    # Get page parameters\n    params = resolve_params(params)\n    raw_params = params.to_raw_params()\n    total = main_table.to_lance().count_rows()\n\n    # Get page items\n    start = raw_params.offset\n    stop = min(raw_params.offset + raw_params.limit, total)\n    if start &gt;= stop:\n        return None\n\n    ## For Active Learning\n    if len(al_tables) &gt; 0:\n        # Selecting first active learning table\n        al_table = al_tables[0].to_lance()\n        pyarrow_table = duckdb.query(\n            f\"SELECT * FROM al_table ORDER BY round DESC, len(id), id LIMIT {raw_params.limit} OFFSET {raw_params.offset}\"\n        ).to_arrow_table()\n        table_id_list = pyarrow_table[\"id\"].to_pylist()\n        table_ids = \"'\" + \"', '\".join(table_id_list) + \"'\"\n\n        # Main table\n        pyarrow_main_table = (\n            main_table.to_lance().scanner(filter=f\"id in ({table_ids})\").to_table()\n        )\n        pyarrow_table = duckdb.query(\n            \"SELECT * FROM pyarrow_table LEFT JOIN pyarrow_main_table USING (id) ORDER BY round DESC, len(id), id\"\n        ).to_arrow_table()\n\n        # Media tables\n        for media_table in media_tables.values():\n            pyarrow_media_table = (\n                media_table.to_lance().scanner(filter=f\"id in ({table_ids})\").to_table()\n            )\n            pyarrow_table = duckdb.query(\n                \"SELECT * FROM pyarrow_table LEFT JOIN pyarrow_media_table USING (id) ORDER BY round DESC, len(id), id\"\n            ).to_arrow_table()\n\n    ## Else\n    else:\n        # Main table\n        pyarrow_table = main_table.to_lance()\n        pyarrow_table = duckdb.query(\n            f\"SELECT * FROM pyarrow_table ORDER BY len(id), id LIMIT {raw_params.limit} OFFSET {raw_params.offset}\"\n        ).to_arrow_table()\n\n        # Media tables\n        for media_table in media_tables.values():\n            pyarrow_media_table = media_table.to_lance()\n            pyarrow_media_table = duckdb.query(\n                f\"SELECT * FROM pyarrow_media_table ORDER BY len(id), id LIMIT {raw_params.limit} OFFSET {raw_params.offset}\"\n            ).to_arrow_table()\n            pyarrow_table = duckdb.query(\n                \"SELECT * FROM pyarrow_table LEFT JOIN pyarrow_media_table USING (id) ORDER BY len(id), id\"\n            ).to_arrow_table()\n\n        # Active Learning tables\n        for al_table in al_tables:\n            pyarrow_al_table = al_table.to_lance()\n            pyarrow_media_table = duckdb.query(\n                f\"SELECT * FROM pyarrow_al_table ORDER BY len(id), id LIMIT {raw_params.limit} OFFSET {raw_params.offset}\"\n            ).to_arrow_table()\n            pyarrow_table = duckdb.query(\n                \"SELECT * FROM pyarrow_table LEFT JOIN pyarrow_al_table USING (id) ORDER BY len(id), id\"\n            ).to_arrow_table()\n\n    # Create items features\n    items = [\n        _create_features(item, pyarrow_table.schema)\n        for item in pyarrow_table.to_pylist()\n    ]\n\n    return create_page(items, total=total, params=params)\n</code></pre>"},{"location":"code/api/items/#pixano.api.items.save_item_details","title":"<code>save_item_details(dataset, item_id, item_details)</code>","text":"<p>Save dataset item objects</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset</p> required <code>item_id</code> <code>str</code> <p>Selected item ID</p> required <code>item_details</code> <code>dict[str, list]</code> <p>Item details</p> required Source code in <code>pixano/api/items.py</code> <pre><code>def save_item_details(\n    dataset: Dataset,\n    item_id: str,\n    item_details: dict[str, list],\n):\n    \"\"\"Save dataset item objects\n\n    Args:\n        dataset (Dataset): Dataset\n        item_id (str): Selected item ID\n        item_details (dict[str, list]): Item details\n    \"\"\"\n\n    # Load dataset\n    ds = dataset.connect()\n\n    main_table: lancedb.db.LanceTable = ds.open_table(\"db\")\n\n    obj_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"objects\" in dataset.info.tables:\n        for obj_info in dataset.info.tables[\"objects\"]:\n            obj_tables[obj_info[\"source\"]] = ds.open_table(obj_info[\"name\"])\n\n    al_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"active_learning\" in dataset.info.tables:\n        for al_info in dataset.info.tables[\"active_learning\"]:\n            al_tables[al_info[\"source\"]] = ds.open_table(al_info[\"name\"])\n\n    ### Save item features (classification label)\n\n    features = item_details[\"itemData\"]\n\n    # Classification\n    for feature in features:\n        if feature[\"name\"] == \"label\":\n            # If label not in main table\n            if \"label\" not in main_table.schema.names:\n                main_table_ds = main_table.to_lance()\n                # Create label table\n                label_table = main_table_ds.to_table(columns=[\"id\"])\n                label_array = pa.array([\"\"] * len(main_table), type=pa.string())\n                label_table = label_table.append_column(\n                    pa.field(\"label\", pa.string()), label_array\n                )\n                # Merge with main table\n                main_table_ds.merge(label_table, \"id\")\n                # Update DatasetInfo\n                dataset.info.tables[\"main\"][0][\"fields\"][\"label\"] = \"str\"\n                dataset.save_info()\n\n            # Get item\n            scanner = main_table.to_lance().scanner(filter=f\"id in ('{item_id}')\")\n            item = scanner.to_table().to_pylist()[0]\n            # Update item\n            item[\"label\"] = feature[\"value\"]\n            main_table.update(f\"id in ('{item_id}')\", item)\n\n            # Clear change history to prevent dataset from becoming too large\n            main_table.to_lance().cleanup_old_versions()\n\n    ### Save item objects\n\n    # Convert objects\n    for obj in item_details[\"itemObjects\"]:\n        # Convert mask from URLE to RLE\n        if \"mask\" in obj:\n            obj[\"mask\"] = CompressedRLE.from_urle(obj[\"mask\"]).to_dict()\n            # If empty bounding box, convert from mask\n            if \"bbox\" in obj and obj[\"bbox\"][\"coords\"] == [0.0, 0.0, 0.0, 0.0]:\n                obj[\"bbox\"] = BBox.from_mask(rle_to_mask(obj[\"mask\"])).to_dict()\n\n    # Get current item objects\n    current_objects = {}\n    for obj_source, obj_table in obj_tables.items():\n        media_scanner = obj_table.to_lance().scanner(filter=f\"item_id in ('{item_id}')\")\n        current_objects[obj_source] = media_scanner.to_table().to_pylist()\n\n    # Save or update new item objects\n    for obj in item_details[\"itemObjects\"]:\n        source = obj[\"source_id\"]\n        # If objects table exists\n        if source in obj_tables:\n            # Remove keys not in schema (mostly for removing source_id for now)\n            for key in list(obj):\n                if key not in obj_tables[source].schema.names:\n                    obj.pop(key)\n\n            # Look for existing object\n            scanner = (\n                obj_tables[source].to_lance().scanner(filter=f\"id in ('{obj['id']}')\")\n            )\n            pyarrow_obj = scanner.to_table()\n\n            # If object exists\n            if pyarrow_obj.num_rows &gt; 0:\n                obj_tables[source].update(f\"id in ('{obj['id']}')\", obj)\n\n            # If object does not exists\n            else:\n                pa_obj = pa.Table.from_pylist(\n                    [obj],\n                    schema=obj_tables[source].schema,\n                )\n                obj_tables[source].add(pa_obj)\n\n            # Clear change history to prevent dataset from becoming too large\n            obj_tables[source].to_lance().cleanup_old_versions()\n\n        # If objects table does not exist\n        else:\n            if source == \"Pixano Annotator\":\n                annnotator_fields = {\n                    \"id\": \"str\",\n                    \"item_id\": \"str\",\n                    \"view_id\": \"str\",\n                    \"bbox\": \"bbox\",\n                    \"mask\": \"compressedrle\",\n                    \"category_id\": \"int\",\n                    \"category_name\": \"str\",\n                }\n                annotator_table = {\n                    \"name\": \"obj_annotator\",\n                    \"source\": source,\n                    \"fields\": annnotator_fields,\n                }\n\n                # Create new objects table\n                obj_tables[source] = ds.create_table(\n                    \"obj_annotator\",\n                    schema=Fields(annnotator_fields).to_schema(),\n                    mode=\"overwrite\",\n                )\n\n                # Add new objects table to DatasetInfo\n                if \"objects\" in dataset.info.tables:\n                    dataset.info.tables[\"objects\"].append(annotator_table)\n                else:\n                    dataset.info.tables[\"objects\"] = [annotator_table]\n                dataset.save_info()\n\n                # Remove keys not in schema (mostly for removing source_id for now)\n                for key in list(obj):\n                    if key not in obj_tables[source].schema.names:\n                        obj.pop(key)\n\n                # Add object\n                pa_obj = pa.Table.from_pylist(\n                    [obj],\n                    schema=obj_tables[source].schema,\n                )\n                obj_tables[source].add(pa_obj)\n\n                # Clear change history to prevent dataset from becoming too large\n                obj_tables[source].to_lance().cleanup_old_versions()\n\n    # Delete removed item objects\n    for obj_source, cur_objects in current_objects.items():\n        for cur_obj in cur_objects:\n            # If object has been deleted\n            if not any(\n                obj[\"id\"] == cur_obj[\"id\"] for obj in item_details[\"itemObjects\"]\n            ):\n                # Remove object from table\n                obj_tables[obj_source].delete(f\"id in ('{cur_obj['id']}')\")\n</code></pre>"},{"location":"code/apps/display/","title":"display","text":""},{"location":"code/apps/display/#pixano.apps.display","title":"<code>pixano.apps.display</code>","text":""},{"location":"code/apps/display/#pixano.apps.display.display_cli","title":"<code>display_cli(url, port, height)</code>","text":"<p>Display a Pixano app inside a command line interface</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/apps/display.py</code> <pre><code>def display_cli(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a command line interface\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    print(f\"Please visit {url}:{port} in a web browser.\")\n</code></pre>"},{"location":"code/apps/display/#pixano.apps.display.display_colab","title":"<code>display_colab(url, port, height)</code>","text":"<p>Display a Pixano app inside a Google Colab</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/apps/display.py</code> <pre><code>def display_colab(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a Google Colab\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    # Define frame template\n    shell = \"\"\"\n        (() =&gt; {\n            const url = new URL(%URL%);\n            const port = %PORT%;\n            if (port) {\n                url.port = port;\n            }\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '%HEIGHT%');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    \"\"\"\n\n    # Replace variables in template\n    replacements = [\n        (\"%HEIGHT%\", \"%d\" % height),\n        (\"%PORT%\", \"%d\" % port),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    script = IPython.display.Javascript(shell)\n    IPython.display.display(script)\n</code></pre>"},{"location":"code/apps/display/#pixano.apps.display.display_ipython","title":"<code>display_ipython(url, port, height)</code>","text":"<p>Display a Pixano app inside a Jupyter notebook</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/apps/display.py</code> <pre><code>def display_ipython(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a Jupyter notebook\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    # Define frame template\n    shell = \"\"\"\n        &lt;iframe id=\"%HTML_ID%\" width=\"100%\" height=\"%HEIGHT%\" frameborder=\"0\"&gt;\n        &lt;/iframe&gt;\n        &lt;script&gt;\n            (function() {\n                const frame = document.getElementById(%JSON_ID%);\n                const url = new URL(%URL%, window.location);\n                const port = %PORT%;\n                if (port) {\n                    url.port = port;\n                }\n                frame.src = url;\n            })();\n        &lt;/script&gt;\n    \"\"\"\n\n    # Replace variables in template\n    frame_id = f\"frame-{shortuuid.uuid()}\"\n    replacements = [\n        (\"%HTML_ID%\", html.escape(frame_id, quote=True)),\n        (\"%JSON_ID%\", json.dumps(frame_id)),\n        (\"%HEIGHT%\", \"%d\" % height),\n        (\"%PORT%\", \"%d\" % port),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    iframe = IPython.display.HTML(shell)\n    IPython.display.display(iframe)\n</code></pre>"},{"location":"code/apps/main/","title":"main","text":""},{"location":"code/apps/main/#pixano.apps.main","title":"<code>pixano.apps.main</code>","text":""},{"location":"code/apps/main/#pixano.apps.main.create_app","title":"<code>create_app(settings=Settings())</code>","text":"<p>Run Pixano app</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>Settings containing dataset library path. Defaults to empty Settings().</p> <code>Settings()</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Dataset library not found</p> <code>HTTPException</code> <p>Dataset / dataset stats / dataset items not found</p> <p>Returns:</p> Type Description <code>FastAPI</code> <p>Pixano App</p> Source code in <code>pixano/apps/main.py</code> <pre><code>def create_app(settings: Settings = Settings()) -&gt; FastAPI:\n    \"\"\"Run Pixano app\n\n    Args:\n        settings (Settings, optional): Settings containing dataset library path. Defaults to empty Settings().\n\n    Raises:\n        FileNotFoundError: Dataset library not found\n        HTTPException: Dataset / dataset stats / dataset items not found\n\n    Returns:\n        FastAPI: Pixano App\n    \"\"\"\n\n    app = FastAPI()\n\n    app.add_middleware(\n        CORSMiddleware,\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Check if library exists\n    if not settings.data_dir.exists():\n        raise FileNotFoundError(\n            f\"Dataset library '{settings.data_dir.absolute()}' not found\"\n        )\n\n    # Create models folder\n    model_dir = settings.data_dir / \"models\"\n    model_dir.mkdir(exist_ok=True)\n    app.mount(\"/models\", StaticFiles(directory=model_dir), name=\"models\")\n\n    @app.get(\"/datasets\", response_model=list[DatasetInfo])\n    async def get_dataset_list():\n        # Load dataset list\n        return load_dataset_list(settings)\n\n    @app.get(\"/datasets/{ds_id}\", response_model=DatasetInfo)\n    async def get_dataset(ds_id: str):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            return ds.info\n\n    @app.get(\"/datasets/{ds_id}/items\", response_model=Page[ItemFeatures])\n    async def get_dataset_items(ds_id: str, params: Params = Depends()):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            # Load dataset items\n            res = load_items(ds, params)\n            if res is None:\n                raise HTTPException(status_code=404, detail=\"Dataset items not found\")\n            else:\n                return res\n\n    @app.get(\"/datasets/{ds_id}/stats\")\n    async def get_dataset_stats(ds_id: str):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            # Load dataset stats\n            stats = load_dataset_stats(ds, settings)\n            if stats is None:\n                raise HTTPException(status_code=404, detail=\"Dataset stats not found\")\n            else:\n                return stats\n\n    @app.get(\"/datasets/{ds_id}/items/{item_id}\")\n    async def get_item_details(ds_id: str, item_id: str):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            # Load item objects\n            return load_item_details(ds, item_id)\n\n    @app.get(\"/datasets/{ds_id}/items/{item_id}/embeddings\")\n    async def get_item_embeddings(ds_id: str, item_id: str):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            # Load item embeddings\n            return load_item_embeddings(ds, item_id)\n\n    @app.post(\n        \"/datasets/{ds_id}/items/{item_id}/details\",\n        response_model=dict[str, list],\n    )\n    async def post_item_details(\n        ds_id: str,\n        item_id: str,\n        item_details: dict[str, list],\n    ):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            # Save item objects\n            save_item_details(ds, item_id, item_details)\n            return Response()\n\n    @app.post(\n        \"/datasets/{ds_id}/search\",\n        response_model=Page[ItemFeatures],\n    )\n    async def post_search_query(\n        ds_id: str,\n        query_rep: dict,\n        params: Params = Depends()\n    ):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        else:\n            if \"query\" in query_rep:\n                try:\n                    res = search_query(ds, query_rep[\"query\"], params)\n                    return res\n                except Exception as err:\n                    raise HTTPException(status_code=404, detail=str(err))\n            else:\n                raise HTTPException(status_code=404, detail=\"Error in query input\")\n\n    add_pagination(app)\n    return app\n</code></pre>"},{"location":"code/apps/serve/","title":"serve","text":""},{"location":"code/apps/serve/#pixano.apps.serve","title":"<code>pixano.apps.serve</code>","text":""},{"location":"code/apps/serve/#pixano.apps.serve.App","title":"<code>App(library_dir, assets_path, template_path, host='127.0.0.1', port=8000)</code>","text":"<p>Base class for Annotator and Explorer apps</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>Config</code> <p>App config</p> <code>server</code> <code>Server</code> <p>App server</p> <code>task_function</code> <code>Callable</code> <p>Run task function for running environment</p> <code>display_function</code> <code>Callable</code> <p>Display function for running environment</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Dataset library directory</p> required <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 8000.</p> <code>8000</code> Source code in <code>pixano/apps/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    assets_path: str,\n    template_path: str,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n):\n    \"\"\"Initialize and run Pixano app\n\n    Args:\n        library_dir (str): Dataset library directory\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 8000.\n    \"\"\"\n\n    # Create app\n    templates = Jinja2Templates(directory=template_path)\n    settings = Settings(data_dir=Path(library_dir))\n    app = create_app(settings)\n\n    @app.get(\"/\", response_class=HTMLResponse)\n    def main(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    app.mount(\"/assets\", StaticFiles(directory=assets_path), name=\"assets\")\n    self.config = uvicorn.Config(app, host=host, port=port)\n    self.server = uvicorn.Server(self.config)\n\n    # Get environmennt\n    self.task_function = {\n        \"colab\": asyncio.get_event_loop().create_task,\n        \"ipython\": asyncio.get_event_loop().create_task,\n        \"none\": asyncio.run,\n    }[self.get_env()]\n    self.display_function = {\n        \"colab\": display_colab,\n        \"ipython\": display_ipython,\n        \"none\": display_cli,\n    }[self.get_env()]\n\n    # Serve app\n    self.task_function(self.server.serve())\n</code></pre>"},{"location":"code/apps/serve/#pixano.apps.serve.App.display","title":"<code>display(height=1000)</code>","text":"<p>Display Pixano app</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Frame height. Defaults to 1000.</p> <code>1000</code> Source code in <code>pixano/apps/serve.py</code> <pre><code>def display(self, height: int = 1000) -&gt; None:\n    \"\"\"Display Pixano app\n\n    Args:\n        height (int, optional): Frame height. Defaults to 1000.\n    \"\"\"\n\n    # Wait for app to be online\n    while not self.server.started:\n        self.task_function(asyncio.wait(0.1))\n\n    # Display app\n    for server in self.server.servers:\n        for socket in server.sockets:\n            address = socket.getsockname()\n            self.display_function(\n                url=f\"http://{address[0]}\", port=address[1], height=height\n            )\n</code></pre>"},{"location":"code/apps/serve/#pixano.apps.serve.App.get_env","title":"<code>get_env()</code>","text":"<p>Get the app's current running environment</p> <p>Returns:</p> Type Description <code>str</code> <p>Running environment</p> Source code in <code>pixano/apps/serve.py</code> <pre><code>def get_env(self) -&gt; str:\n    \"\"\"Get the app's current running environment\n\n    Returns:\n        str: Running environment\n    \"\"\"\n\n    # If Google colab import succeeds\n    try:\n        import google.colab\n        import IPython\n    except ImportError:\n        pass\n    else:\n        if IPython.get_ipython() is not None:\n            return \"colab\"\n\n    # If IPython import succeeds\n    try:\n        import IPython\n    except ImportError:\n        pass\n    else:\n        ipython = IPython.get_ipython()\n        if ipython is not None and ipython.has_trait(\"kernel\"):\n            return \"ipython\"\n\n    # Else\n    return \"none\"\n</code></pre>"},{"location":"code/apps/annotator/serve/","title":"serve","text":""},{"location":"code/apps/annotator/serve/#pixano.apps.annotator.serve","title":"<code>pixano.apps.annotator.serve</code>","text":""},{"location":"code/apps/annotator/serve/#pixano.apps.annotator.serve.Annotator","title":"<code>Annotator(library_dir, host='127.0.0.1', port=0)</code>","text":"<p>             Bases: <code>App</code></p> <p>Pixano Annotator App</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>Config</code> <p>App config</p> <code>server</code> <code>Server</code> <p>App server</p> <code>task_function</code> <code>Callable</code> <p>Run task function for running environment</p> <code>display_function</code> <code>Callable</code> <p>Display function for running environment</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Dataset library directory</p> required <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 0.</p> <code>0</code> Source code in <code>pixano/apps/annotator/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    host: str = \"127.0.0.1\",\n    port: int = 0,\n) -&gt; None:\n    \"\"\"Initialize and run Pixano Annotator app\n\n    Args:\n        library_dir (str): Dataset library directory\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 0.\n    \"\"\"\n\n    super().__init__(library_dir, ASSETS_PATH, TEMPLATE_PATH, host, port)\n</code></pre>"},{"location":"code/apps/annotator/serve/#pixano.apps.annotator.serve.main","title":"<code>main(library_dir, host, port)</code>","text":"<p>Launch Pixano Annotator</p> <p>LIBRARY_DIR: Dataset library directory</p> Source code in <code>pixano/apps/annotator/serve.py</code> <pre><code>@click.command(context_settings={\"auto_envvar_prefix\": \"UVICORN\"})\n@click.argument(\n    \"library_dir\",\n    type=str,\n)\n@click.option(\n    \"--host\",\n    type=str,\n    default=\"127.0.0.1\",\n    help=\"Bind socket to this host.\",\n    show_default=True,\n)\n@click.option(\n    \"--port\",\n    type=int,\n    default=0,\n    help=\"Bind socket to this port.\",\n    show_default=True,\n)\ndef main(library_dir: str, host: str, port: int):\n    \"\"\"Launch Pixano Annotator\n\n    LIBRARY_DIR: Dataset library directory\n    \"\"\"\n    Annotator(library_dir, host, port)\n</code></pre>"},{"location":"code/apps/explorer/serve/","title":"serve","text":""},{"location":"code/apps/explorer/serve/#pixano.apps.explorer.serve","title":"<code>pixano.apps.explorer.serve</code>","text":""},{"location":"code/apps/explorer/serve/#pixano.apps.explorer.serve.Explorer","title":"<code>Explorer(library_dir, host='127.0.0.1', port=0)</code>","text":"<p>             Bases: <code>App</code></p> <p>Pixano Explorer App</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>Config</code> <p>App config</p> <code>server</code> <code>Server</code> <p>App server</p> <code>task_function</code> <code>Callable</code> <p>Run task function for running environment</p> <code>display_function</code> <code>Callable</code> <p>Display function for running environment</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Dataset library directory</p> required <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 0.</p> <code>0</code> Source code in <code>pixano/apps/explorer/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    host: str = \"127.0.0.1\",\n    port: int = 0,\n) -&gt; None:\n    \"\"\"Initialize and run Pixano Explorer app\n\n    Args:\n        library_dir (str): Dataset library directory\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 0.\n    \"\"\"\n\n    super().__init__(library_dir, ASSETS_PATH, TEMPLATE_PATH, host, port)\n</code></pre>"},{"location":"code/apps/explorer/serve/#pixano.apps.explorer.serve.main","title":"<code>main(library_dir, host, port)</code>","text":"<p>Launch Pixano Explorer</p> <p>LIBRARY_DIR: Dataset library directory</p> Source code in <code>pixano/apps/explorer/serve.py</code> <pre><code>@click.command(context_settings={\"auto_envvar_prefix\": \"UVICORN\"})\n@click.argument(\n    \"library_dir\",\n    type=str,\n)\n@click.option(\n    \"--host\",\n    type=str,\n    default=\"127.0.0.1\",\n    help=\"Bind socket to this host.\",\n    show_default=True,\n)\n@click.option(\n    \"--port\",\n    type=int,\n    default=0,\n    help=\"Bind socket to this port.\",\n    show_default=True,\n)\ndef main(library_dir: str, host: str, port: int):\n    \"\"\"Launch Pixano Explorer\n\n    LIBRARY_DIR: Dataset library directory\n    \"\"\"\n    Explorer(library_dir, host, port)\n</code></pre>"},{"location":"code/core/bbox/","title":"bbox","text":""},{"location":"code/core/bbox/#pixano.core.bbox","title":"<code>pixano.core.bbox</code>","text":""},{"location":"code/core/bbox/#pixano.core.bbox.BBox","title":"<code>BBox(coords, format, is_normalized=True, confidence=None)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Bounding box type using coordinates in xyxy or xywh format</p> <p>Attributes:</p> Name Type Description <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format</p> <code>format</code> <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p> <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size</p> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format</p> required <code>format</code> <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p> required <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size. Defaults to True.</p> <code>True</code> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. Defaults to None.</p> <code>None</code> Source code in <code>pixano/core/bbox.py</code> <pre><code>def __init__(\n    self,\n    coords: list[float],\n    format: str,\n    is_normalized: bool = True,\n    confidence: float = None,\n):\n    \"\"\"Initialize Bounding box\n\n    Args:\n        coords (list[float]): List of coordinates in given format\n        format (str): Coordinates format, 'xyxy' or 'xywh'\n        is_normalized (bool, optional): True if coordinates are normalized to image size. Defaults to True.\n        confidence (float, optional): Bounding box confidence if predicted. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._coords = coords\n    self._format = format\n    self._is_normalized = is_normalized\n    self._confidence = confidence\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.confidence","title":"<code>confidence: float</code>  <code>property</code>","text":"<p>Return bounding box confidence</p> <p>Returns:</p> Type Description <code>float</code> <p>Bounding box confidence if predicted, else None</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.coords","title":"<code>coords: list[float]</code>  <code>property</code>","text":"<p>Return bounding box coordinates</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.format","title":"<code>format: str</code>  <code>property</code>","text":"<p>Return bounding box coordinates format</p> <p>Returns:</p> Type Description <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.is_normalized","title":"<code>is_normalized: bool</code>  <code>property</code>","text":"<p>Return bounding box normalization information</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if coordinates are normalized to image size</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.is_predicted","title":"<code>is_predicted: bool</code>  <code>property</code>","text":"<p>Return True if bounding box is predicted and has a confidence value</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bounding box is predicted and has a confidence value</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.xywh_coords","title":"<code>xywh_coords: list[float]</code>  <code>property</code>","text":"<p>Return bounding box xywh coordinates</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates in xywh format</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.xyxy_coords","title":"<code>xyxy_coords: list[float]</code>  <code>property</code>","text":"<p>Return bounding box xyxy coordinates</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates in xyxy format</p>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.denormalize","title":"<code>denormalize(height, width)</code>","text":"<p>Return bounding box with coordinates denormalized from image size</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box with coordinates denormalized from image size</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def denormalize(self, height: int, width: int) -&gt; \"BBox\":\n    \"\"\"Return bounding box with coordinates denormalized from image size\n\n    Args:\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        BBox: Bounding box with coordinates denormalized from image size\n    \"\"\"\n\n    return BBox(\n        denormalize_coords(self.coords, height, width),\n        self.format,\n        False,\n        self.confidence,\n    )\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.from_mask","title":"<code>from_mask(mask)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using a NumPy array mask</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>NumPy array mask</p> required <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_mask(mask: np.ndarray) -&gt; \"BBox\":\n    \"\"\"Create bounding box using a NumPy array mask\n\n    Args:\n        mask (np.ndarray): NumPy array mask\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox.from_xywh(mask_to_bbox(mask))\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.from_xywh","title":"<code>from_xywh(xywh, confidence=None)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using normalized xywh coordinates</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>List of coordinates in xywh format</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_xywh(xywh: list[float], confidence: float = None) -&gt; \"BBox\":\n    \"\"\"Create bounding box using normalized xywh coordinates\n\n    Args:\n        xywh (list[float]): List of coordinates in xywh format\n        confidence (float, optional): Bounding box confidence if predicted. Defaults to None.\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox(xywh, \"xywh\", confidence=confidence)\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.from_xyxy","title":"<code>from_xyxy(xyxy, confidence=None)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using normalized xyxy coordinates</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>List of coordinates in xyxy format</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_xyxy(xyxy: list[float], confidence: float = None) -&gt; \"BBox\":\n    \"\"\"Create bounding box using normalized xyxy coordinates\n\n    Args:\n        xyxy (list[float]): List of coordinates in xyxy format\n        confidence (float, optional): Bounding box confidence if predicted. Defaults to None.\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox(xyxy, \"xyxy\", confidence=confidence)\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.normalize","title":"<code>normalize(height, width)</code>","text":"<p>Return bounding box with coordinates normalized to image size</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box with coordinates normalized to image size</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def normalize(self, height: int, width: int) -&gt; \"BBox\":\n    \"\"\"Return bounding box with coordinates normalized to image size\n\n    Args:\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        BBox: Bounding box with coordinates normalized to image size\n    \"\"\"\n\n    return BBox(\n        normalize_coords(self.coords, height, width),\n        self.format,\n        True,\n        self.confidence,\n    )\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return BBox type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return BBox type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"coords\", pa.list_(pa.float32(), list_size=4)),\n            pa.field(\"is_normalized\", pa.bool_()),\n            pa.field(\"format\", pa.string()),\n            pa.field(\"confidence\", pa.float32()),\n        ]\n    )\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.to_xywh","title":"<code>to_xywh()</code>","text":"<p>Return bounding box in xywh format</p> <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box in xyxy format</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def to_xywh(self) -&gt; \"BBox\":\n    \"\"\"Return bounding box in xywh format\n\n    Returns:\n        BBox: Bounding box in xyxy format\n    \"\"\"\n\n    return BBox(self.xywh_coords, \"xywh\", self.is_normalized, self.confidence)\n</code></pre>"},{"location":"code/core/bbox/#pixano.core.bbox.BBox.to_xyxy","title":"<code>to_xyxy()</code>","text":"<p>Return bounding box in xyxy format</p> <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box in xyxy format</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def to_xyxy(self) -&gt; \"BBox\":\n    \"\"\"Return bounding box in xyxy format\n\n    Returns:\n        BBox: Bounding box in xyxy format\n    \"\"\"\n\n    return BBox(self.xyxy_coords, \"xyxy\", self.is_normalized, self.confidence)\n</code></pre>"},{"location":"code/core/camera/","title":"camera","text":""},{"location":"code/core/camera/#pixano.core.camera","title":"<code>pixano.core.camera</code>","text":""},{"location":"code/core/camera/#pixano.core.camera.Camera","title":"<code>Camera(depth_scale, cam_K, cam_R_w2c=[0.0] * 9, cam_t_w2c=[0.0] * 3)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Camera type</p> <p>Attributes:</p> Name Type Description <code>depth_scale</code> <code>float</code> <p>Depth scale</p> <code>cam_K</code> <code>list[float]</code> <p>Camera matrix K</p> <code>cam_R_w2c</code> <code>list[float]</code> <p>3*3 orientation matrix</p> <code>cam_t_w2c</code> <code>list[float]</code> <p>3*1 translation matrix</p> <p>Parameters:</p> Name Type Description Default <code>depth_scale</code> <code>float</code> <p>Depth scale</p> required <code>cam_K</code> <code>list[float]</code> <p>Camera matrix K</p> required <code>cam_R_w2c</code> <code>list[float]</code> <p>3*3 orientation matrix. Defaults to None.</p> <code>[0.0] * 9</code> <code>cam_t_w2c</code> <code>list[float]</code> <p>3*1 translation matrix. Defaults to None.</p> <code>[0.0] * 3</code> Source code in <code>pixano/core/camera.py</code> <pre><code>def __init__(\n    self,\n    depth_scale: float,\n    cam_K: list[float],\n    cam_R_w2c: list[float] = [0.0] * 9,\n    cam_t_w2c: list[float] = [0.0] * 3,\n):\n    \"\"\"Initialize Camera\n\n    Args:\n        depth_scale (float): Depth scale\n        cam_K (list[float]): Camera matrix K\n        cam_R_w2c (list[float], optional): 3*3 orientation matrix. Defaults to None.\n        cam_t_w2c (list[float], optional): 3*1 translation matrix. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        depth_scale=depth_scale,\n        cam_K=cam_K,\n        cam_R_w2c=cam_R_w2c,\n        cam_t_w2c=cam_t_w2c,\n    )\n</code></pre>"},{"location":"code/core/camera/#pixano.core.camera.Camera.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return Camera type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/camera.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return Camera type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"depth_scale\", pa.float64()),\n            pa.field(\"cam_K\", pa.list_(pa.float64())),\n            pa.field(\"cam_R_w2c\", pa.list_(pa.float64())),\n            pa.field(\"cam_t_w2c\", pa.list_(pa.float64())),\n        ]\n    )\n</code></pre>"},{"location":"code/core/compressed_rle/","title":"compressed_rle","text":""},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle","title":"<code>pixano.core.compressed_rle</code>","text":""},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE","title":"<code>CompressedRLE(size, counts)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Compressed RLE mask type</p> <p>Attributes:</p> Name Type Description <code>_size</code> <code>list[float]</code> <p>Mask size</p> <code>_counts</code> <code>bytes</code> <p>Mask RLE encoding</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[float]</code> <p>Mask size</p> required <code>counts</code> <code>bytes</code> <p>Mask RLE encoding</p> required Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def __init__(self, size: list[float], counts: bytes):\n    \"\"\"Initalize compressed RLE mask\n\n    Args:\n        size (list[float]): Mask size\n        counts (bytes): Mask RLE encoding\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._size = size\n    self._counts = counts\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.counts","title":"<code>counts: bytes</code>  <code>property</code>","text":"<p>Return mask RLE encoding</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Mask RLE encoding</p>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.size","title":"<code>size: list[float]</code>  <code>property</code>","text":"<p>Return mask size</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Mask size</p>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.encode","title":"<code>encode(mask, height, width)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from polygons / uncompressed RLE / compressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict[str, Any]</code> <p>Mask as polygons / uncompressed RLE / compressed RLE</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef encode(\n    mask: list[list] | dict[str, Any], height: int, width: int\n) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from polygons / uncompressed RLE / compressed RLE\n\n    Args:\n        mask (list[list] | dict[str, Any]): Mask as polygons / uncompressed RLE / compressed RLE\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(encode_rle(mask, height, width))\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.from_mask","title":"<code>from_mask(mask)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from NumPy array</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image | ndarray</code> <p>Mask as NumPy array</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_mask(mask: Image.Image | np.ndarray) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from NumPy array\n\n    Args:\n        mask (Image.Image | np.ndarray): Mask as NumPy array\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(mask_to_rle(mask))\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.from_polygons","title":"<code>from_polygons(polygons, height, width)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from polygons</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>Mask as polygons</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_polygons(\n    polygons: list[list],\n    height: int,\n    width: int,\n) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from polygons\n\n    Args:\n        polygons (list[list]): Mask as polygons\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(polygons_to_rle(polygons, height, width))\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.from_urle","title":"<code>from_urle(urle)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from uncompressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict[str, Any]</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_urle(urle: dict[str, Any]) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from uncompressed RLE\n\n    Args:\n        urle (dict[str, Any]): Mask as uncompressed RLE\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(urle_to_rle(urle))\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_mask","title":"<code>to_mask()</code>","text":"<p>Convert compressed RLE mask to NumPy array</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Mask as NumPy array</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def to_mask(self) -&gt; np.ndarray:\n    \"\"\"Convert compressed RLE mask to NumPy array\n\n    Returns:\n        np.ndarray: Mask as NumPy array\n    \"\"\"\n\n    return rle_to_mask(self.to_dict())\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_polygons","title":"<code>to_polygons()</code>","text":"<p>Convert compressed RLE mask to poylgons</p> <p>Returns:</p> Type Description <code>list[list]</code> <p>Mask as polygons</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def to_polygons(self) -&gt; list[list]:\n    \"\"\"Convert compressed RLE mask to poylgons\n\n    Returns:\n        list[list]: Mask as polygons\n    \"\"\"\n\n    return rle_to_polygons(self.to_dict())\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return CompressedRLE type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return CompressedRLE type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"size\", pa.list_(pa.int32(), list_size=2)),\n            pa.field(\"counts\", pa.binary()),\n        ]\n    )\n</code></pre>"},{"location":"code/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_urle","title":"<code>to_urle()</code>","text":"<p>Convert compressed RLE mask to uncompressed RLE</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Mask as uncompressed RLE</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def to_urle(self) -&gt; dict[str, Any]:\n    \"\"\"Convert compressed RLE mask to uncompressed RLE\n\n    Returns:\n        dict[str, Any]: Mask as uncompressed RLE\n    \"\"\"\n\n    return rle_to_urle(self.to_dict())\n</code></pre>"},{"location":"code/core/depth_image/","title":"depth_image","text":""},{"location":"code/core/depth_image/#pixano.core.depth_image","title":"<code>pixano.core.depth_image</code>","text":""},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage","title":"<code>DepthImage(depth_map=None, bytes=None, shape=None)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Depth image type</p> <p>Attributes:</p> Name Type Description <code>_depth_map</code> <code>ndarray</code> <p>Depth image as NumPy array</p> <code>_bytes</code> <code>bytes</code> <p>Depth image as bytes</p> <code>_shape</code> <code>list[int]</code> <p>Depth image shape</p> <p>Parameters:</p> Name Type Description Default <code>depth_map</code> <code>ndarray</code> <p>Depth image as NumPy array. Defaults to None.</p> <code>None</code> <code>bytes</code> <code>bytes</code> <p>Depth image as bytes. Defaults to None.</p> <code>None</code> <code>shape</code> <code>list[int]</code> <p>Depth image shape. Defaults to None.</p> <code>None</code> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def __init__(\n    self,\n    depth_map: np.ndarray = None,\n    bytes: bytes = None,\n    shape: list[int] = None,\n):\n    \"\"\"Initialize Depth image\n\n    Args:\n        depth_map (np.ndarray, optional): Depth image as NumPy array. Defaults to None.\n        bytes (bytes, optional): Depth image as bytes. Defaults to None.\n        shape (list[int], optional): Depth image shape. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._depth_map = depth_map\n    self._bytes = bytes\n    self._shape = shape\n</code></pre>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.bytes","title":"<code>bytes: bytes</code>  <code>property</code>","text":"<p>Return Depth image as bytes</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Depth image as bytes</p>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.depth_map","title":"<code>depth_map: np.ndarray</code>  <code>property</code>","text":"<p>Returns Depth image as NumPy array</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Depth image as NumPy array</p>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.shape","title":"<code>shape: list[int]</code>  <code>property</code>","text":"<p>Return Depth image shape</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>Depth image shape</p>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.display","title":"<code>display()</code>","text":"<p>Display Depth image with matplotlib</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def display(self):\n    \"\"\"Display Depth image with matplotlib\"\"\"\n\n    plt.imshow(self.depth_map.astype(np.int8), cmap=\"gray\", vmin=0, vmax=255)\n    plt.axis(\"off\")\n    if self._shape is not None:\n        plt.figure(figsize=self._shape)\n    plt.show()\n</code></pre>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.load","title":"<code>load(path)</code>  <code>staticmethod</code>","text":"<p>Create depth image from 16-bit .png file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of .png file of depth image</p> required <p>Returns:</p> Type Description <code>DepthImage</code> <p>Depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>@staticmethod\ndef load(path: str) -&gt; \"DepthImage\":\n    \"\"\"Create depth image from 16-bit .png file\n\n    Args:\n        path (str): Path of .png file of depth image\n\n    Returns:\n        DepthImage: Depth image\n    \"\"\"\n\n    map = imageio.v3.imread(path).astype(np.uint16)\n    return DepthImage(depth_map=map, shape=map.shape)\n</code></pre>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.load_npy","title":"<code>load_npy(path)</code>  <code>staticmethod</code>","text":"<p>Create depth image from .npy file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to .npy file containing depth image as NumPy Array.</p> required <p>Returns:</p> Type Description <code>DepthImage</code> <p>Depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>@staticmethod\ndef load_npy(path: str) -&gt; \"DepthImage\":\n    \"\"\"Create depth image from .npy file\n\n    Args:\n        path (str): Path to .npy file containing depth image as NumPy Array.\n\n    Returns:\n        DepthImage: Depth image\n    \"\"\"\n\n    map = np.load(path)\n    return DepthImage(depth_map=map, shape=map.shape)\n</code></pre>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.save","title":"<code>save(path)</code>","text":"<p>Save depth image to .png file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to .png file to save</p> required Source code in <code>pixano/core/depth_image.py</code> <pre><code>def save(self, path):\n    \"\"\"Save depth image to .png file.\n\n    Args:\n        path (str): Path to .png file to save\n    \"\"\"\n\n    depth_image = self.depth_map.astype(np.uint16)\n    imageio.v3.imwrite(path, depth_image)\n</code></pre>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.to_grayscale","title":"<code>to_grayscale()</code>","text":"<p>Transform Depth image to 8-bit grayscale depth image</p> <p>Returns:</p> Type Description <code>DepthImage</code> <p>8-bit grayscale depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def to_grayscale(\n    self,\n) -&gt; \"DepthImage\":\n    \"\"\"Transform Depth image to 8-bit grayscale depth image\n\n    Returns:\n        DepthImage: 8-bit grayscale depth image\n    \"\"\"\n\n    depth = self.depth_map\n    min, max = depth.min(), depth.max()\n    depth_n: np.ndarray = ((depth - min) / (max - min)) * 255\n    return DepthImage(depth_map=depth_n.astype(np.uint8), shape=depth.shape)\n</code></pre>"},{"location":"code/core/depth_image/#pixano.core.depth_image.DepthImage.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return DepthImage type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return DepthImage type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"bytes\", pa.binary()),\n            pa.field(\"shape\", pa.list_(pa.int32(), list_size=2)),\n        ]\n    )\n</code></pre>"},{"location":"code/core/gt_info/","title":"gt_info","text":""},{"location":"code/core/gt_info/#pixano.core.gt_info","title":"<code>pixano.core.gt_info</code>","text":""},{"location":"code/core/gt_info/#pixano.core.gt_info.GtInfo","title":"<code>GtInfo(bbox_obj, bbox_visib, px_count_all, px_count_valid, px_count_visib, visib_fract)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>GtInfo type</p> <p>Attributes:</p> Name Type Description <code>bbox_obj</code> <code>BBox</code> <p>bbox_obj</p> <code>bbox_visib</code> <code>BBox</code> <p>bbox_visib</p> <code>px_count_all</code> <code>int</code> <p>px_count_all</p> <code>px_count_valid</code> <code>int</code> <p>px_count_valid</p> <code>px_count_visib</code> <code>int</code> <p>px_count_visib</p> <code>visib_fract</code> <code>float</code> <p>visib_fract</p> <p>Parameters:</p> Name Type Description Default <code>bbox_obj</code> <code>BBox</code> <p>bbox_obj</p> required <code>bbox_visib</code> <code>BBox</code> <p>bbox_visib</p> required <code>px_count_all</code> <code>int</code> <p>px_count_all</p> required <code>px_count_valid</code> <code>int</code> <p>px_count_valid</p> required <code>px_count_visib</code> <code>int</code> <p>px_count_visib</p> required <code>visib_fract</code> <code>float</code> <p>visib_fract</p> required Source code in <code>pixano/core/gt_info.py</code> <pre><code>def __init__(\n    self,\n    bbox_obj: BBox,\n    bbox_visib: BBox,\n    px_count_all: int,\n    px_count_valid: int,\n    px_count_visib: int,\n    visib_fract: float,\n):\n    \"\"\"Initialize GtInfo\n\n    Args:\n        bbox_obj (BBox): bbox_obj\n        bbox_visib (BBox): bbox_visib\n        px_count_all (int): px_count_all\n        px_count_valid (int): px_count_valid\n        px_count_visib (int): px_count_visib\n        visib_fract (float): visib_fract\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        bbox_obj=bbox_obj,\n        bbox_visib=bbox_visib,\n        px_count_all=px_count_all,\n        px_count_valid=px_count_valid,\n        px_count_visib=px_count_visib,\n        visib_fract=visib_fract,\n    )\n</code></pre>"},{"location":"code/core/gt_info/#pixano.core.gt_info.GtInfo.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return GtInfo type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/gt_info.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return GtInfo type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"bbox_obj\", BBoxType),\n            pa.field(\"bbox_visib\", BBoxType),\n            pa.field(\"px_count_all\", pa.int64()),\n            pa.field(\"px_count_valid\", pa.int64()),\n            pa.field(\"px_count_visib\", pa.int64()),\n            pa.field(\"visib_fract\", pa.float64()),\n        ]\n    )\n</code></pre>"},{"location":"code/core/image/","title":"image","text":""},{"location":"code/core/image/#pixano.core.image","title":"<code>pixano.core.image</code>","text":""},{"location":"code/core/image/#pixano.core.image.Image","title":"<code>Image(uri, bytes=None, preview_bytes=None, uri_prefix=None)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Image type using URI or bytes</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>str</code> <p>Image URI</p> <code>bytes</code> <code>bytes</code> <p>Image bytes</p> <code>preview_bytes</code> <code>bytes</code> <p>Image preview bytes</p> <code>uri_prefix</code> <code>str</code> <p>URI prefix for relative URIs</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>str</code> <p>Image URI</p> <code>bytes</code> <code>bytes</code> <p>Image bytes. Defaults to None.</p> <code>preview_bytes</code> <code>bytes</code> <p>Image preview bytes. Defaults to None.</p> <code>uri_prefix</code> <code>str</code> <p>URI prefix for relative URIs. Defaults to None.</p> Source code in <code>pixano/core/image.py</code> <pre><code>def __init__(\n    self,\n    uri: str,\n    bytes: bytes = None,\n    preview_bytes: bytes = None,\n    uri_prefix: str = None,\n):\n    \"\"\"Initialize Image\n\n    Attributes:\n        uri (str): Image URI\n        bytes (bytes, optional): Image bytes. Defaults to None.\n        preview_bytes (bytes, optional): Image preview bytes. Defaults to None.\n        uri_prefix (str, optional): URI prefix for relative URIs. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        uri=uri,\n        bytes=bytes,\n        preview_bytes=preview_bytes,\n        uri_prefix=uri_prefix,\n    )\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.preview_url","title":"<code>preview_url: str</code>  <code>property</code>","text":"<p>Return image preview URL</p> <p>Returns:</p> Type Description <code>str</code> <p>Image preview URL</p>"},{"location":"code/core/image/#pixano.core.image.Image.size","title":"<code>size: list[int]</code>  <code>property</code>","text":"<p>Return image size</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>Image size</p>"},{"location":"code/core/image/#pixano.core.image.Image.url","title":"<code>url: str</code>  <code>property</code>","text":"<p>Return image URL</p> <p>Returns:</p> Type Description <code>str</code> <p>Image URL</p>"},{"location":"code/core/image/#pixano.core.image.Image.as_cv2","title":"<code>as_cv2()</code>","text":"<p>Open image as OpenCV</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Image as OpenCV</p> Source code in <code>pixano/core/image.py</code> <pre><code>def as_cv2(self) -&gt; np.ndarray:\n    \"\"\"Open image as OpenCV\n\n    Returns:\n        np.ndarray: Image as OpenCV\n    \"\"\"\n\n    im_arr = np.frombuffer(self.open().read(), dtype=np.uint8)\n    return cv2.imdecode(im_arr, cv2.IMREAD_COLOR)\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.as_pillow","title":"<code>as_pillow()</code>","text":"<p>Open image as Pillow</p> <p>Returns:</p> Type Description <code>Image</code> <p>Image as Pillow</p> Source code in <code>pixano/core/image.py</code> <pre><code>def as_pillow(self) -&gt; PILImage.Image:\n    \"\"\"Open image as Pillow\n\n    Returns:\n        PIL.Image.Image: Image as Pillow\n    \"\"\"\n\n    return PILImage.open(self.open()).convert(\"RGB\")\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.display","title":"<code>display(preview=False)</code>","text":"<p>Display image</p> <p>Parameters:</p> Name Type Description Default <code>preview</code> <code>bool</code> <p>True to display image preview instead of full image. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Image</code> <p>Image as IPython Display</p> Source code in <code>pixano/core/image.py</code> <pre><code>def display(self, preview=False) -&gt; IPyImage:\n    \"\"\"Display image\n\n    Args:\n        preview (bool, optional): True to display image preview instead of full image. Defaults to False.\n\n    Returns:\n        IPython.core.display.Image: Image as IPython Display\n    \"\"\"\n\n    im_bytes = self.preview_bytes if preview else self.get_bytes()\n    return IPyImage(url=binary_to_url(im_bytes), format=IPyImage(im_bytes).format)\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.get_bytes","title":"<code>get_bytes()</code>","text":"<p>Get image bytes from attribute or from reading file from URI</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Image bytes</p> Source code in <code>pixano/core/image.py</code> <pre><code>def get_bytes(self) -&gt; bytes:\n    \"\"\"Get image bytes from attribute or from reading file from URI\n\n    Returns:\n        bytes: Image bytes\n    \"\"\"\n\n    if self.bytes is not None:\n        return self.bytes\n    elif self.uri is not None:\n        with self.open() as f:\n            return f.read()\n    else:\n        return None\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.get_uri","title":"<code>get_uri()</code>","text":"<p>Return complete image URI from URI and URI prefix</p> <p>Returns:</p> Type Description <code>str</code> <p>Image URI</p> Source code in <code>pixano/core/image.py</code> <pre><code>def get_uri(self) -&gt; str:\n    \"\"\"Return complete image URI from URI and URI prefix\n\n    Returns:\n        str: Image URI\n    \"\"\"\n\n    # Relative URI\n    if urlparse(self.uri).scheme == \"\":\n        # If URI prefix exists\n        if self.uri_prefix is not None:\n            parsed_uri = urlparse(self.uri_prefix)\n            if parsed_uri.scheme == \"\":\n                raise Exception(\n                    \"URI prefix is incomplete, no scheme provided (http://, file://, ...)\"\n                )\n            combined_path = Path(parsed_uri.path) / self.uri\n            parsed_uri = parsed_uri._replace(path=str(combined_path))\n            return parsed_uri.geturl()\n        # No URI prefix\n        else:\n            raise Exception(\"Need Uri prefix for relative uri\")\n    # Complete URI\n    else:\n        return self.uri\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.open","title":"<code>open()</code>","text":"<p>Open image</p> <p>Returns:</p> Type Description <code>IO</code> <p>Opened image</p> Source code in <code>pixano/core/image.py</code> <pre><code>def open(self) -&gt; IO:\n    \"\"\"Open image\n\n    Returns:\n        IO: Opened image\n    \"\"\"\n\n    return urlopen(self.get_uri())\n</code></pre>"},{"location":"code/core/image/#pixano.core.image.Image.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return Image type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/image.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return Image type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"uri\", pa.utf8()),\n            pa.field(\"bytes\", pa.binary()),\n            pa.field(\"preview_bytes\", pa.binary()),\n        ]\n    )\n</code></pre>"},{"location":"code/core/pixano_type/","title":"pixano_type","text":""},{"location":"code/core/pixano_type/#pixano.core.pixano_type","title":"<code>pixano.core.pixano_type</code>","text":""},{"location":"code/core/pixano_type/#pixano.core.pixano_type.PixanoType","title":"<code>PixanoType(__pydantic_self__, **data)</code>","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Base class for all Pixano custom types</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>__init__</code> uses <code>__pydantic_self__</code> instead of the more common <code>self</code> for the first arg to allow <code>self</code> as a field name.</p> Source code in <code></code> <pre><code>def __init__(__pydantic_self__, **data: Any) -&gt; None:  # type: ignore\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `__init__` uses `__pydantic_self__` instead of the more common `self` for the first arg to\n    allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\n</code></pre>"},{"location":"code/core/pixano_type/#pixano.core.pixano_type.PixanoType.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Instance custom type from dict</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[PixanoType]</code> <p>Pixano custom type to instance</p> required <code>data</code> <code>dict[str, Any]</code> <p>Data to instance from</p> required <p>Returns:</p> Type Description <code>PixanoType</code> <p>New instance of Pixano custom type</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>@classmethod\ndef from_dict(cls: Type[\"PixanoType\"], data: dict[str, Any]) -&gt; \"PixanoType\":\n    \"\"\"Instance custom type from dict\n\n    Args:\n        cls (Type[PixanoType]): Pixano custom type to instance\n        data (dict[str, Any]): Data to instance from\n\n    Returns:\n        PixanoType: New instance of Pixano custom type\n    \"\"\"\n\n    return cls(**data)\n</code></pre>"},{"location":"code/core/pixano_type/#pixano.core.pixano_type.PixanoType.to_dict","title":"<code>to_dict()</code>","text":"<p>Return custom type as dict based on corresponding PyArrow Struct</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Custom type as dict</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Return custom type as dict based on corresponding PyArrow Struct\n\n    Returns:\n        dict[str, Any]: Custom type as dict\n    \"\"\"\n\n    def _convert_value_as_dict(value):\n        \"\"\"Recursively convert value to dict if possible\"\"\"\n\n        if isinstance(value, PixanoType):\n            return value.to_dict()\n        elif isinstance(value, dict):\n            return {k: _convert_value_as_dict(v) for k, v in value.items()}\n        elif isinstance(value, (list, tuple)):\n            return [_convert_value_as_dict(item) for item in value]\n        else:\n            return value\n\n    struct_fields = self.to_struct()\n    return {\n        field.name: _convert_value_as_dict(getattr(self, field.name))\n        for field in struct_fields\n    }\n</code></pre>"},{"location":"code/core/pixano_type/#pixano.core.pixano_type.PixanoType.to_struct","title":"<code>to_struct()</code>  <code>abstractmethod</code>","text":"<p>Return custom type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>@abstractmethod\ndef to_struct(cls) -&gt; pa.StructType:\n    \"\"\"Return custom type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code/core/pixano_type/#pixano.core.pixano_type.convert_field","title":"<code>convert_field(field_name, field_type, field_data)</code>","text":"<p>Convert PyArrow ExtensionTypes properly</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name</p> required <code>field_type</code> <code>DataType</code> <p>Target PyArrow format</p> required <code>field_data</code> <code>list</code> <p>Data in Python format</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Data in target PyArrow format</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>def convert_field(\n    field_name: str, field_type: pa.DataType, field_data: list\n) -&gt; pa.Array:\n    \"\"\"Convert PyArrow ExtensionTypes properly\n\n    Args:\n        field_name (str): Name\n        field_type (pa.DataType): Target PyArrow format\n        field_data (list): Data in Python format\n\n    Returns:\n        pa.Array: Data in target PyArrow format\n    \"\"\"\n\n    # If target format is an ExtensionType\n    if isinstance(field_type, pa.ExtensionType):\n        storage = pa.array(field_data, type=field_type.storage_type)\n        return pa.ExtensionArray.from_storage(field_type, storage)\n\n    # If target format is an extension of ListType\n    elif pa.types.is_list(field_type):\n        native_arr = pa.array(field_data)\n        if isinstance(native_arr, pa.NullArray):\n            return pa.nulls(len(native_arr), field_type)\n        offsets = native_arr.offsets\n        values = native_arr.values.to_numpy(zero_copy_only=False)\n        return pa.ListArray.from_arrays(\n            offsets,\n            convert_field(f\"{field_name}.elements\", field_type.value_type, values),\n        )\n\n    # If target format is an extension of StructType\n    elif pa.types.is_struct(field_type):\n        native_arr = pa.array(field_data)\n        if isinstance(native_arr, pa.NullArray):\n            return pa.nulls(len(native_arr), field_type)\n        arrays = []\n        for subfield in field_type:\n            sub_arr = native_arr.field(subfield.name)\n            converted = convert_field(\n                f\"{field_name}.{subfield.name}\",\n                subfield.type,\n                sub_arr.to_numpy(zero_copy_only=False),\n            )\n            arrays.append(converted)\n        return pa.StructArray.from_arrays(arrays, fields=field_type)\n\n    # For other target formats\n    else:\n        return pa.array(field_data, type=field_type)\n</code></pre>"},{"location":"code/core/pixano_type/#pixano.core.pixano_type.create_pyarrow_type","title":"<code>create_pyarrow_type(struct_type, name, pyType)</code>","text":"<p>Create PyArrow ExtensionType for Pixano custom type</p> <p>Parameters:</p> Name Type Description Default <code>struct_type</code> <code>StructType</code> <p>Pixano custom type as PyArrow Struct</p> required <code>name</code> <code>str</code> <p>Pixano custom type name</p> required <code>pyType</code> <code>Type</code> <p>Pixano custom type Python type</p> required <p>Returns:</p> Type Description <code>ExtensionType</code> <p>PyArrow ExtensionType</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>def create_pyarrow_type(\n    struct_type: pa.StructType, name: str, pyType: Type\n) -&gt; pa.ExtensionType:\n    \"\"\"Create PyArrow ExtensionType for Pixano custom type\n\n    Args:\n        struct_type (pa.StructType): Pixano custom type as PyArrow Struct\n        name (str): Pixano custom type name\n        pyType (Type): Pixano custom type Python type\n\n    Returns:\n        pa.ExtensionType: PyArrow ExtensionType\n    \"\"\"\n\n    class CustomExtensionType(pa.ExtensionType):\n        def __init__(self, struct_type: pa.StructType, name: str):\n            super().__init__(struct_type, name)\n\n        @classmethod\n        def __arrow_ext_deserialize__(cls, storage_type, serialized):\n            return cls(struct_type, name)\n\n        def __arrow_ext_serialize__(self):\n            return b\"\"\n\n        def __arrow_ext_scalar_class__(self):\n            return self.Scalar\n\n        def __arrow_ext_class__(self):\n            return self.Array\n\n        def __repr__(self):\n            return f\"ExtensionType&lt;{name}Type&gt;\"\n\n        class Scalar(pa.ExtensionScalar):\n            def as_py(self):\n                def as_py_dict(pa_dict: dict[str, Any]) -&gt; dict[str, Any]:\n                    \"\"\"Recusively convert dictionary of PyArrow objects to dictionary of Python objects\n\n                    Args:\n                        pa_dict (dict[str, Any]): Dictionary of PyArrow objects\n\n                    Returns:\n                        dict[str, Any]: Dictionary of Python objects\n                    \"\"\"\n\n                    py_dict = {}\n                    for key, value in pa_dict.items():\n                        if hasattr(value, \"as_py\") and callable(\n                            getattr(value, \"as_py\")\n                        ):\n                            py_dict[key] = value.as_py()\n                        elif isinstance(value, dict):\n                            py_dict[key] = as_py_dict(value)\n                    return py_dict\n\n                return pyType.from_dict(as_py_dict(self.value))\n\n        class Array(pa.ExtensionArray):\n            def __repr__(self):\n                return f\"&lt;{name}Array object at {hex(id(self))}&gt;\\n{self}\"\n\n            @staticmethod\n            def from_pylist(lst: list | list[list]):\n                def from_list(lst: list):\n                    fields = struct_type\n                    arrays = []\n\n                    for field in fields:\n                        data = []\n                        for obj in lst:\n                            if obj is not None:\n                                if hasattr(obj, \"to_dict\") and callable(\n                                    getattr(obj, \"to_dict\")\n                                ):\n                                    data.append(obj.to_dict().get(field.name))\n                                elif isinstance(obj, dict):\n                                    data.append(obj.get(field.name))\n                                else:\n                                    data.append(obj)\n                            else:\n                                data.append(None)\n\n                        arrays.append(\n                            convert_field(\n                                field.name,\n                                field.type,\n                                data,\n                            )\n                        )\n                    sto = pa.StructArray.from_arrays(arrays, fields=fields)\n                    return pa.ExtensionArray.from_storage(pyarrow_type, sto)\n\n                def from_lists(list: list[list[Type]]) -&gt; pa.ListArray:\n                    \"\"\"Return paListArray corresponding to list of list of type\n\n                    Args:\n                        list (list[list[Type]]): list of list of type\n\n                    Returns:\n                        pa.ListArray: List array with offset corresponding to list\n                    \"\"\"\n\n                    offset = [0]\n                    for sub_list in list:\n                        offset.append(len(sub_list) + offset[-1])\n\n                    flat_list = [item for sublist in list for item in sublist]\n                    flat_array = from_list(flat_list)\n\n                    return pa.ListArray.from_arrays(\n                        offset, flat_array, type=pa.list_(pyarrow_type)\n                    )\n\n                def is_nested(lst: list) -&gt; bool:\n                    \"\"\"Check if list contains only sublists\"\"\"\n                    return all(isinstance(item, list) for item in lst)\n\n                def is_flat(lst: list) -&gt; bool:\n                    \"\"\"Check if list does not contain sublists\"\"\"\n                    return all(not isinstance(item, list) for item in lst)\n\n                if is_nested(lst):\n                    return from_lists(lst)\n                elif is_flat(lst):\n                    return from_list(lst)\n                else:\n                    raise ValueError(\n                        \"Input list must be either a nested list or a flat list\"\n                    )\n\n    # Create ExtensionType\n    pyarrow_type = CustomExtensionType(struct_type, name)\n\n    # Try and register ExtensionType\n    try:\n        pa.register_extension_type(pyarrow_type)\n    # If ExtensionType is already registered\n    except pa.ArrowKeyError:\n        pass\n\n    return pyarrow_type\n</code></pre>"},{"location":"code/core/pose/","title":"pose","text":""},{"location":"code/core/pose/#pixano.core.pose","title":"<code>pixano.core.pose</code>","text":""},{"location":"code/core/pose/#pixano.core.pose.Pose","title":"<code>Pose(cam_R_m2c, cam_t_m2c)</code>","text":"<p>             Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Pose type using orientation and translation matrices</p> <p>Attributes:</p> Name Type Description <code>_cam_R_m2c</code> <code>list[float]</code> <p>3*3 orientation matrix</p> <code>_cam_t_m2c</code> <code>list[float]</code> <p>3*1 translation matrix</p> <p>Parameters:</p> Name Type Description Default <code>cam_R_m2c</code> <code>list[float]</code> <p>3*3 orientation matrix</p> required <code>cam_t_m2c</code> <code>list[float]</code> <p>3*1 translation matrix</p> required Source code in <code>pixano/core/pose.py</code> <pre><code>def __init__(self, cam_R_m2c: list[float], cam_t_m2c: list[float]):\n    \"\"\"Initialize pose from orientation and translation matrices\n\n    Args:\n        cam_R_m2c (list[float]): 3*3 orientation matrix\n        cam_t_m2c (list[float]): 3*1 translation matrix\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._cam_R_m2c = cam_R_m2c\n    self._cam_t_m2c = cam_t_m2c\n</code></pre>"},{"location":"code/core/pose/#pixano.core.pose.Pose.cam_R_m2c","title":"<code>cam_R_m2c: list[float]</code>  <code>property</code>","text":"<p>Return Pose orientation matrix</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>3*3 orientation matrix</p>"},{"location":"code/core/pose/#pixano.core.pose.Pose.cam_t_m2c","title":"<code>cam_t_m2c: list[float]</code>  <code>property</code>","text":"<p>Return Pose translation matrix</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>1*3 translation matrix</p>"},{"location":"code/core/pose/#pixano.core.pose.Pose.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return Pose type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/pose.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return Pose type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"cam_R_m2c\", pa.list_(pa.float64(), list_size=9)),\n            pa.field(\"cam_t_m2c\", pa.list_(pa.float64(), list_size=3)),\n        ]\n    )\n</code></pre>"},{"location":"code/core/utils/","title":"utils","text":""},{"location":"code/core/utils/#pixano.core.utils","title":"<code>pixano.core.utils</code>","text":""},{"location":"code/core/utils/#pixano.core.utils.is_image_type","title":"<code>is_image_type(t)</code>","text":"<p>Check if DataType is an Image</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is an Image</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_image_type(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is an Image\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is an Image\n    \"\"\"\n\n    return (\n        ImageType.equals(t)\n        or str(t) == \"struct&lt;uri: string, bytes: binary, preview_bytes: binary&gt;\"\n    )\n</code></pre>"},{"location":"code/core/utils/#pixano.core.utils.is_number","title":"<code>is_number(t)</code>","text":"<p>Check if DataType is a number (integer or float)</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is an integer or a float</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_number(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is a number (integer or float)\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is an integer or a float\n    \"\"\"\n\n    return pa.types.is_integer(t) or pa.types.is_floating(t)\n</code></pre>"},{"location":"code/core/utils/#pixano.core.utils.is_string","title":"<code>is_string(t)</code>","text":"<p>Check if DataType is a string</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is a string</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_string(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is a string\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is a string\n    \"\"\"\n\n    return pa.types.is_string(t) or pa.types.is_large_string(t)\n</code></pre>"},{"location":"code/core/utils/#pixano.core.utils.pyarrow_array_from_list","title":"<code>pyarrow_array_from_list(list_data, type)</code>","text":"<p>Convert data from Python list to PyArrow array</p> <p>Parameters:</p> Name Type Description Default <code>list_data</code> <code>list</code> <p>Data as Python list</p> required <code>type</code> <code>ExtensionType | DataType</code> <p>PyArrow base or custom extension type</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Unknow type</p> <p>Returns:</p> Type Description <code>Array</code> <p>Data as PyArrow array</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def pyarrow_array_from_list(\n    list_data: list, type: pa.ExtensionType | pa.DataType\n) -&gt; pa.Array:\n    \"\"\"Convert data from Python list to PyArrow array\n\n    Args:\n        list_data (list): Data as Python list\n        type (pa.ExtensionType | pa.DataType): PyArrow base or custom extension type\n\n    Raises:\n        ValueError: Unknow type\n\n    Returns:\n        pa.Array: Data as PyArrow array\n    \"\"\"\n\n    if pa.types.is_list(type):\n        type = type.value_type\n\n    if isinstance(type, pa.ExtensionType):\n        return type.Array.from_pylist(list_data)\n    elif isinstance(type, pa.DataType) and not isinstance(type, pa.ExtensionType):\n        return pa.array(list_data)\n    else:\n        raise ValueError(\"Unknow type\")\n</code></pre>"},{"location":"code/data/dataset/","title":"dataset","text":""},{"location":"code/data/dataset/#pixano.data.dataset","title":"<code>pixano.data.dataset</code>","text":""},{"location":"code/data/dataset/#pixano.data.dataset.Dataset","title":"<code>Dataset(path)</code>","text":"<p>Dataset class</p> <p>Attributes:</p> Name Type Description <code>_path</code> <code>Path</code> <p>Dataset path</p> <code>_info</code> <code>DatasetInfo</code> <p>Dataset info</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Dataset path</p> required Source code in <code>pixano/data/dataset.py</code> <pre><code>def __init__(self, path: Path):\n    \"\"\"Initialize dataset\n\n    Args:\n        path (Path): Dataset path\n    \"\"\"\n\n    self._path = path\n    self._info = DatasetInfo.from_json(self._path / \"db.json\")\n</code></pre>"},{"location":"code/data/dataset/#pixano.data.dataset.Dataset.info","title":"<code>info: DatasetInfo</code>  <code>property</code>","text":"<p>Return Dataset info</p> <p>Returns:</p> Type Description <code>DatasetInfo</code> <p>Dataset info</p>"},{"location":"code/data/dataset/#pixano.data.dataset.Dataset.media_dir","title":"<code>media_dir: Path</code>  <code>property</code>","text":"<p>Return Dataset media directory</p> <p>Returns:</p> Type Description <code>Path</code> <p>Dataset media directory</p>"},{"location":"code/data/dataset/#pixano.data.dataset.Dataset.path","title":"<code>path: Path</code>  <code>property</code>","text":"<p>Return Dataset path</p> <p>Returns:</p> Type Description <code>Path</code> <p>Dataset path</p>"},{"location":"code/data/dataset/#pixano.data.dataset.Dataset.connect","title":"<code>connect()</code>","text":"<p>Connect to dataset with LanceDB</p> <p>Returns:</p> Type Description <code>DBConnection</code> <p>Dataset LanceDB connection</p> Source code in <code>pixano/data/dataset.py</code> <pre><code>def connect(self) -&gt; lancedb.DBConnection:\n    \"\"\"Connect to dataset with LanceDB\n\n    Returns:\n        lancedb.DBConnection: Dataset LanceDB connection\n    \"\"\"\n\n    return lancedb.connect(self._path)\n</code></pre>"},{"location":"code/data/dataset/#pixano.data.dataset.Dataset.save_info","title":"<code>save_info()</code>","text":"<p>Save dataset info to file</p> Source code in <code>pixano/data/dataset.py</code> <pre><code>def save_info(self):\n    \"\"\"Save dataset info to file\"\"\"\n\n    self.info.save(self.path)\n</code></pre>"},{"location":"code/data/dataset_info/","title":"dataset_info","text":""},{"location":"code/data/dataset_info/#pixano.data.dataset_info","title":"<code>pixano.data.dataset_info</code>","text":""},{"location":"code/data/dataset_info/#pixano.data.dataset_info.DatasetInfo","title":"<code>DatasetInfo(id, name, description, estimated_size=None, num_elements=None, preview=None, splits=None, tables=None, categories=None)</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>DatasetInfo</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Dataset ID</p> <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>estimated_size</code> <code>str</code> <p>Dataset estimated size</p> <code>num_elements</code> <code>int</code> <p>Number of elements in dataset</p> <code>preview</code> <code>str</code> <p>Dataset preview</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>tables</code> <code>dict[str, list]</code> <p>Dataset tables</p> <code>categories</code> <code>list[dict]</code> <p>Dataset categories</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Dataset ID</p> required <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>estimated_size</code> <code>str</code> <p>Dataset estimated size. Defaults to None.</p> <code>None</code> <code>num_elements</code> <code>int</code> <p>Number of elements in dataset. Defaults to None.</p> <code>None</code> <code>preview</code> <code>str</code> <p>Dataset preview. Defaults to None.</p> <code>None</code> <code>splits</code> <code>list[str]</code> <p>Dataset splits. Defaults to None.</p> <code>None</code> <code>tables</code> <code>dict[str, list]</code> <p>Dataset tables. Defaults to None.</p> <code>None</code> <code>categories</code> <code>list[dict]</code> <p>Dataset categories. Defaults to None.</p> <code>None</code> Source code in <code>pixano/data/dataset_info.py</code> <pre><code>def __init__(\n    self,\n    id: str,\n    name: str,\n    description: str,\n    estimated_size: str = None,\n    num_elements: int = None,\n    preview: str = None,\n    splits: list[str] = None,\n    tables: dict[str, list] = None,\n    categories: list[dict] = None,\n):\n    \"\"\"Initialize Bounding box\n\n    Args:\n        id (str): Dataset ID\n        name (str): Dataset name\n        description (str): Dataset description\n        estimated_size (str, optional): Dataset estimated size. Defaults to None.\n        num_elements (int, optional): Number of elements in dataset. Defaults to None.\n        preview (str, optional): Dataset preview. Defaults to None.\n        splits (list[str]): Dataset splits. Defaults to None.\n        tables (dict[str, list], optional): Dataset tables. Defaults to None.\n        categories (list[dict], optional): Dataset categories. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        id=id,\n        name=name,\n        description=description,\n        estimated_size=estimated_size,\n        num_elements=num_elements,\n        preview=preview,\n        splits=splits,\n        tables=tables,\n        categories=categories,\n    )\n</code></pre>"},{"location":"code/data/dataset_info/#pixano.data.dataset_info.DatasetInfo.from_json","title":"<code>from_json(json_fp)</code>  <code>staticmethod</code>","text":"<p>Read DatasetInfo from JSON file</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path</code> <p>JSON file path</p> required <p>Returns:</p> Type Description <code>DatasetInfo</code> <p>DatasetInfo</p> Source code in <code>pixano/data/dataset_info.py</code> <pre><code>@staticmethod\ndef from_json(json_fp: Path) -&gt; \"DatasetInfo\":\n    \"\"\"Read DatasetInfo from JSON file\n\n    Args:\n        json_fp (Path): JSON file path\n\n    Returns:\n        DatasetInfo: DatasetInfo\n    \"\"\"\n\n    with open(json_fp) as json_file:\n        info_json = json.load(json_file)\n\n    return DatasetInfo.model_validate(info_json)\n</code></pre>"},{"location":"code/data/dataset_info/#pixano.data.dataset_info.DatasetInfo.save","title":"<code>save(save_dir)</code>","text":"<p>Save DatasetInfo to json file</p> Source code in <code>pixano/data/dataset_info.py</code> <pre><code>def save(self, save_dir: Path):\n    \"\"\"Save DatasetInfo to json file\"\"\"\n\n    with open(save_dir / \"db.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(self.model_dump(), f)\n</code></pre>"},{"location":"code/data/fields/","title":"fields","text":""},{"location":"code/data/fields/#pixano.data.fields","title":"<code>pixano.data.fields</code>","text":""},{"location":"code/data/fields/#pixano.data.fields.Fields","title":"<code>Fields(field_dict)</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Dataset PyArrow fields as string dictionary</p> <p>Attributes:</p> Name Type Description <code>field_dict</code> <code>dict[str, str]</code> <p>PyArrow fields as string dictionary</p> <p>Parameters:</p> Name Type Description Default <code>field_dict</code> <code>dict[str, str]</code> <p>PyArrow fields as string dictionary</p> required Source code in <code>pixano/data/fields.py</code> <pre><code>def __init__(self, field_dict: dict[str, str]) -&gt; None:\n    \"\"\"Create Fields from string dictionary\n\n    Args:\n        field_dict (dict[str, str]): PyArrow fields as string dictionary\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(field_dict=field_dict)\n</code></pre>"},{"location":"code/data/fields/#pixano.data.fields.Fields.to_schema","title":"<code>to_schema()</code>","text":"<p>Convert Fields string dictionary to PyArrow schema</p> <p>Returns:</p> Type Description <code>schema</code> <p>Fields as PyArrow schema</p> Source code in <code>pixano/data/fields.py</code> <pre><code>def to_schema(self) -&gt; pa.schema:\n    \"\"\"Convert Fields string dictionary to PyArrow schema\n\n    Returns:\n        pa.schema: Fields as PyArrow schema\n    \"\"\"\n\n    def _pyarrow_mapping(input_type: str) -&gt; pa.DataType:\n        \"\"\"Convert string types to PyArrow type\n\n        Args:\n            input_type (str): String type. Can be written as list form: [myType]\n\n        Returns:\n            pa.DataType: PyArrow DataType or PyArrow list of DataType\n        \"\"\"\n\n        pa_type_mapping = {\n            \"int\": pa.int64(),\n            \"float\": pa.float32(),\n            \"bool\": pa.bool_(),\n            \"str\": pa.string(),\n            \"bytes\": pa.binary(),\n            \"np.ndarray\": pa.list_(pa.float32()),\n            \"image\": ImageType,\n            \"depthimage\": DepthImageType,\n            \"camera\": CameraType,\n            \"compressedrle\": CompressedRLEType,\n            \"pose\": PoseType,\n            \"bbox\": BBoxType,\n            \"gtinfo\": GtInfoType,\n        }\n\n        # str\n        if isinstance(input_type, str):\n            if input_type.startswith(\"[\") and input_type.endswith(\"]\"):\n                return pa.list_(\n                    pa_type_mapping[\n                        input_type.removeprefix(\"[\").removesuffix(\"]\").lower()\n                    ]\n                )\n            if input_type.startswith(\"vector(\") and input_type.endswith(\")\"):\n                size_str = input_type.removeprefix(\"vector(\").removesuffix(\")\")\n                if size_str.isnumeric():\n                    return pa.list_(pa.float32(), list_size=int(size_str))\n            return pa_type_mapping[input_type.lower()]\n\n    fields = []\n    for field_name, field_type in self.field_dict.items():\n        # Convert the field type to PyArrow type\n        field = pa.field(field_name, _pyarrow_mapping(field_type), nullable=True)\n        fields.append(field)\n    return pa.schema(fields)\n</code></pre>"},{"location":"code/data/exporters/coco_exporter/","title":"coco_exporter","text":""},{"location":"code/data/exporters/coco_exporter/#pixano.data.exporters.coco_exporter","title":"<code>pixano.data.exporters.coco_exporter</code>","text":""},{"location":"code/data/exporters/coco_exporter/#pixano.data.exporters.coco_exporter.COCOExporter","title":"<code>COCOExporter</code>","text":"<p>             Bases: <code>Exporter</code></p> <p>Exporter class for COCO instances dataset</p>"},{"location":"code/data/exporters/coco_exporter/#pixano.data.exporters.coco_exporter.COCOExporter.export_dataset","title":"<code>export_dataset(input_dir, export_dir, splits=None, objects_sources=None, portable=False)</code>","text":"<p>Export dataset back to original format</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input directory</p> required <code>export_dir</code> <code>Path</code> <p>Export directory</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits to export, all if None. Defaults to None.</p> <code>None</code> <code>objects_sources</code> <code>list[str]</code> <p>Objects sources to export, all if None. Defaults to None.</p> <code>None</code> <code>portable</code> <code>bool</code> <p>True to copy or download files to export directory and use relative paths. Defaults to False.</p> <code>False</code> Source code in <code>pixano/data/exporters/coco_exporter.py</code> <pre><code>def export_dataset(\n    self,\n    input_dir: Path,\n    export_dir: Path,\n    splits: list[str] = None,\n    objects_sources: list[str] = None,\n    portable: bool = False,\n):\n    \"\"\"Export dataset back to original format\n\n    Args:\n        input_dir (Path): Input directory\n        export_dir (Path): Export directory\n        splits (list[str], optional): Dataset splits to export, all if None. Defaults to None.\n        objects_sources (list[str], optional): Objects sources to export, all if None. Defaults to None.\n        portable (bool, optional): True to copy or download files to export directory and use relative paths. Defaults to False.\n    \"\"\"\n\n    # Create URI prefix\n    media_dir = input_dir / \"media\"\n    uri_prefix = media_dir.absolute().as_uri()\n    export_uri_prefix = (export_dir / \"media\").absolute().as_uri()\n\n    # Load dataset\n    dataset = Dataset(input_dir)\n    ds = dataset.connect()\n    main_table: lancedb.db.LanceTable = ds.open_table(\"db\")\n\n    image_table: dict[str, lancedb.db.LanceTable]\n    image_field_names = []\n    if \"media\" in dataset.info.tables:\n        for md_info in dataset.info.tables[\"media\"]:\n            if md_info[\"name\"] == \"image\":\n                image_table = ds.open_table(md_info[\"name\"])\n                image_field_names.extend(\n                    [\n                        field_name\n                        for field_name, field_type in md_info[\"fields\"].items()\n                        if field_type == \"image\"\n                    ]\n                )\n\n    obj_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"objects\" in dataset.info.tables:\n        for obj_info in dataset.info.tables[\"objects\"]:\n            # If no objects tables provided, select all objects tables\n            if not objects_sources or (\n                objects_sources and obj_info[\"name\"] in objects_sources\n            ):\n                try:\n                    obj_tables[obj_info[\"source\"]] = ds.open_table(obj_info[\"name\"])\n                except FileNotFoundError as e:\n                    raise FileNotFoundError(f\"Objects table not found: {e}\") from e\n    else:\n        raise Exception(\"No objects table to export\")\n\n    # Create export directory\n    ann_dir = export_dir / f\"annotations [{', '.join(list(obj_tables.keys()))}]\"\n    ann_dir.mkdir(parents=True, exist_ok=True)\n\n    # If no splits provided, select all splits\n    if not splits:\n        splits = dataset.info.splits\n\n    # Iterate on splits\n    with tqdm(desc=\"Processing dataset\", total=len(main_table)) as progress:\n        for split in splits:\n            # Create COCO json\n            coco_json = {\n                \"info\": {\n                    \"description\": dataset.info.name,\n                    \"url\": \"N/A\",\n                    \"version\": f\"v{datetime.datetime.now().strftime('%y%m%d.%H%M%S')}\",\n                    \"year\": datetime.date.today().year,\n                    \"contributor\": \"Exported from Pixano\",\n                    \"date_created\": datetime.date.today().isoformat(),\n                },\n                \"licences\": [\n                    {\n                        \"url\": \"N/A\",\n                        \"id\": 1,\n                        \"name\": \"Unknown\",\n                    },\n                ],\n                \"images\": [],\n                \"annotations\": [],\n                \"categories\": [],\n            }\n            seen_category_ids = []\n            batch_size = 1024\n\n            for i in range(ceil(len(main_table) / batch_size)):\n                # Load rows\n                offset = i * batch_size\n                limit = min(len(main_table), offset + batch_size)\n                pyarrow_table = main_table.to_lance()\n                pyarrow_table = duckdb.query(\n                    f\"SELECT * FROM pyarrow_table ORDER BY len(id), id LIMIT {limit} OFFSET {offset}\"\n                ).to_arrow_table()\n                pyarrow_image_table = image_table.to_lance().to_table(\n                    limit=limit, offset=offset\n                )\n                pyarrow_image_table = duckdb.query(\n                    f\"SELECT * FROM pyarrow_image_table ORDER BY len(id), id LIMIT {limit} OFFSET {offset}\"\n                ).to_arrow_table()\n                pyarrow_table = duckdb.query(\n                    \"SELECT * FROM pyarrow_table LEFT JOIN pyarrow_image_table USING (id) ORDER BY len(id), id\"\n                ).to_arrow_table()\n                # Filter split\n                if splits:\n                    pyarrow_table = duckdb.query(\n                        f\"SELECT * FROM pyarrow_table WHERE split in ('{split}')\"\n                    ).to_arrow_table()\n\n                # Iterate on rows\n                for row_id in range(pyarrow_table.num_rows):\n                    row = pyarrow_table.take([row_id]).to_pylist()[0]\n                    # Export images\n                    ims = {}\n                    for field_name in image_field_names:\n                        # Open image\n                        ims[field_name] = Image.from_dict(row[field_name])\n                        ims[field_name].uri_prefix = (\n                            export_uri_prefix if portable else uri_prefix\n                        )\n                        im_filename = Path(\n                            urlparse(ims[field_name].get_uri()).path\n                        ).name\n                        # Append image info\n                        coco_json[\"images\"].append(\n                            {\n                                \"license\": 1,\n                                \"coco_url\": ims[field_name].get_uri(),\n                                \"file_name\": im_filename,\n                                \"height\": ims[field_name].size[1],\n                                \"width\": ims[field_name].size[0],\n                                \"id\": row[\"id\"],\n                            }\n                        )\n                    # Export objects\n                    objects = {}\n                    for obj_source, obj_table in obj_tables.items():\n                        media_scanner = obj_table.to_lance().scanner(\n                            filter=f\"item_id in ('{row['id']}')\"\n                        )\n                        objects[obj_source] = media_scanner.to_table().to_pylist()\n                    for obj_source, obj_list in objects.items():\n                        for obj in obj_list:\n                            if obj[\"view_id\"] in image_field_names:\n                                # Object mask\n                                mask = (\n                                    obj[\"mask\"].to_urle() if \"mask\" in obj else None\n                                )\n                                # Object bounding box\n                                bbox = (\n                                    obj[\"bbox\"]\n                                    .denormalize(\n                                        height=ims[obj[\"view_id\"]].size[1],\n                                        width=ims[obj[\"view_id\"]].size[0],\n                                    )\n                                    .xywh_coords\n                                    if \"bbox\" in obj\n                                    else None\n                                )\n                                # Object category\n                                category = (\n                                    {\n                                        \"id\": obj[\"category_id\"],\n                                        \"name\": obj[\"category_name\"],\n                                    }\n                                    if \"category_id\" in obj\n                                    and \"category_name\" in obj\n                                    else None\n                                )\n                                # Add object\n                                coco_json[\"annotations\"].append(\n                                    {\n                                        \"id\": obj[\"id\"],\n                                        \"image_id\": row[\"id\"],\n                                        \"segmentation\": mask,\n                                        \"bbox\": bbox,\n                                        \"area\": 0,\n                                        \"iscrowd\": 0,\n                                        \"category_id\": category[\"id\"],\n                                        \"category_name\": category[\"name\"],\n                                    }\n                                )\n                                # Append category if not seen yet\n                                if (\n                                    category[\"id\"] not in seen_category_ids\n                                    and category[\"name\"] is not None\n                                ):\n                                    coco_json[\"categories\"].append(\n                                        {\n                                            \"supercategory\": \"N/A\",\n                                            \"id\": category[\"id\"],\n                                            \"name\": category[\"name\"],\n                                        },\n                                    )\n                                    seen_category_ids.append(category[\"id\"])\n                    # Update progress bar after processing row\n                    progress.update(1)\n\n            # Sort categories\n            coco_json[\"categories\"] = sorted(\n                coco_json[\"categories\"], key=lambda c: c[\"id\"]\n            )\n            # Save COCO format .json file\n            with open(ann_dir / f\"instances_{split}.json\", \"w\") as f:\n                json.dump(coco_json, f)\n\n    # Copy media directory if portable\n    if portable:\n        if media_dir.exists():\n            if media_dir != export_dir / \"media\":\n                shutil.copytree(media_dir, export_dir / \"media\", dirs_exist_ok=True)\n        else:\n            raise Exception(\n                f\"Activated portable option for export but {media_dir} does not exist.\"\n            )\n</code></pre>"},{"location":"code/data/exporters/exporter/","title":"exporter","text":""},{"location":"code/data/exporters/exporter/#pixano.data.exporters.exporter","title":"<code>pixano.data.exporters.exporter</code>","text":""},{"location":"code/data/exporters/exporter/#pixano.data.exporters.exporter.Exporter","title":"<code>Exporter</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract Data Exmporter class</p>"},{"location":"code/data/exporters/exporter/#pixano.data.exporters.exporter.Exporter.export_dataset","title":"<code>export_dataset(input_dir, export_dir)</code>  <code>abstractmethod</code>","text":"<p>Export dataset back to original format</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input directory</p> required <code>export_dir</code> <code>Path</code> <p>Export directory</p> required Source code in <code>pixano/data/exporters/exporter.py</code> <pre><code>@abstractmethod\ndef export_dataset(self, input_dir: Path, export_dir: Path):\n    \"\"\"Export dataset back to original format\n\n    Args:\n        input_dir (Path): Input directory\n        export_dir (Path): Export directory\n    \"\"\"\n</code></pre>"},{"location":"code/data/importers/coco_importer/","title":"coco_importer","text":""},{"location":"code/data/importers/coco_importer/#pixano.data.importers.coco_importer","title":"<code>pixano.data.importers.coco_importer</code>","text":""},{"location":"code/data/importers/coco_importer/#pixano.data.importers.coco_importer.COCOImporter","title":"<code>COCOImporter(name, description, splits, media_fields={'image': 'image'})</code>","text":"<p>             Bases: <code>Importer</code></p> <p>Importer class for COCO instances format datasets</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required <code>media_fields</code> <code>dict[str, str]</code> <p>Dataset media fields, with field names as keys and field types as values. Default to {\"image\": \"image\"}.</p> <code>{'image': 'image'}</code> Source code in <code>pixano/data/importers/coco_importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n    media_fields: dict[str, str] = {\"image\": \"image\"},\n):\n    \"\"\"Initialize COCO Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n        media_fields (dict[str, str]): Dataset media fields, with field names as keys and field types as values. Default to {\"image\": \"image\"}.\n    \"\"\"\n\n    tables = {\n        \"main\": [\n            {\n                \"name\": \"db\",\n                \"fields\": {\n                    \"id\": \"str\",\n                    \"views\": \"[str]\",\n                    \"split\": \"str\",\n                },\n            }\n        ],\n        \"media\": [],\n        \"objects\": [\n            {\n                \"name\": \"objects\",\n                \"fields\": {\n                    \"id\": \"str\",\n                    \"item_id\": \"str\",\n                    \"view_id\": \"str\",\n                    \"bbox\": \"bbox\",\n                    \"mask\": \"compressedrle\",\n                    \"category_id\": \"int\",\n                    \"category_name\": \"str\",\n                },\n                \"source\": \"Ground Truth\",\n            }\n        ],\n    }\n\n    # Add media fields to tables\n    for field_name, field_type in media_fields.items():\n        table_exists = False\n        # If table for given field type exists\n        for media_table in tables[\"media\"]:\n            if field_type == media_table[\"name\"] and not table_exists:\n                media_table[\"fields\"][field_name] = field_type\n                table_exists = True\n        # Else, create that table\n        if not table_exists:\n            tables[\"media\"].append(\n                {\n                    \"name\": field_type,\n                    \"fields\": {\n                        \"id\": \"str\",\n                        field_name: field_type,\n                    },\n                }\n            )\n\n    # Initialize Importer\n    super().__init__(name, description, tables, splits)\n</code></pre>"},{"location":"code/data/importers/coco_importer/#pixano.data.importers.coco_importer.COCOImporter.import_rows","title":"<code>import_rows(input_dirs, portable=False)</code>","text":"<p>Process dataset rows for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/coco_importer.py</code> <pre><code>def import_rows(\n    self,\n    input_dirs: dict[str, Path],\n    portable: bool = False,\n) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    # iterate on splits\n    for split in self.info.splits:\n        # Open annotation files\n        with open(input_dirs[\"objects\"] / f\"instances_{split}.json\", \"r\") as f:\n            coco_instances = json.load(f)\n\n        # Group annotations by image ID\n        annotations = defaultdict(list)\n        for ann in coco_instances[\"annotations\"]:\n            annotations[ann[\"image_id\"]].append(ann)\n\n        # Process rows\n        for im in sorted(\n            coco_instances[\"images\"], key=lambda x: natural_key(str(x[\"id\"]))\n        ):\n            # Load image annotations\n            im_anns = annotations[im[\"id\"]]\n            # Load image\n            file_name_uri = urlparse(im[\"file_name\"])\n            if file_name_uri.scheme == \"\":\n                im_path = input_dirs[\"image\"] / split / im[\"file_name\"]\n            else:\n                im_path = Path(file_name_uri.path)\n\n            # Create image thumbnail\n            im_thumb = image_to_thumbnail(im_path.read_bytes())\n\n            # Set image URI\n            im_uri = (\n                f\"image/{split}/{im_path.name}\"\n                if portable\n                else im_path.absolute().as_uri()\n            )\n\n            # Return rows\n            rows = {\n                \"main\": {\n                    \"db\": [\n                        {\n                            \"id\": str(im[\"id\"]),\n                            \"views\": [\"image\"],\n                            \"split\": split,\n                        }\n                    ]\n                },\n                \"media\": {\n                    \"image\": [\n                        {\n                            \"id\": str(im[\"id\"]),\n                            \"image\": Image(im_uri, None, im_thumb).to_dict(),\n                        }\n                    ]\n                },\n                \"objects\": {\n                    \"objects\": [\n                        {\n                            \"id\": str(ann[\"id\"]),\n                            \"item_id\": str(im[\"id\"]),\n                            \"view_id\": \"image\",\n                            \"bbox\": BBox.from_xywh(ann[\"bbox\"])\n                            .normalize(im[\"height\"], im[\"width\"])\n                            .to_dict()\n                            if ann[\"bbox\"]\n                            else None,\n                            \"mask\": CompressedRLE.encode(\n                                ann[\"segmentation\"], im[\"height\"], im[\"width\"]\n                            ).to_dict()\n                            if ann[\"segmentation\"]\n                            else None,\n                            \"category_id\": int(ann[\"category_id\"]),\n                            \"category_name\": str(ann[\"category_name\"]),\n                        }\n                        for ann in im_anns\n                    ]\n                },\n            }\n\n            yield rows\n</code></pre>"},{"location":"code/data/importers/dota_importer/","title":"dota_importer","text":""},{"location":"code/data/importers/dota_importer/#pixano.data.importers.dota_importer","title":"<code>pixano.data.importers.dota_importer</code>","text":""},{"location":"code/data/importers/dota_importer/#pixano.data.importers.dota_importer.DOTAImporter","title":"<code>DOTAImporter(name, description, splits)</code>","text":"<p>             Bases: <code>Importer</code></p> <p>Importer class for DOTA dataset</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required Source code in <code>pixano/data/importers/dota_importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n):\n    \"\"\"Initialize DOTA Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n    \"\"\"\n\n    tables = {\n        \"main\": [\n            {\n                \"name\": \"db\",\n                \"fields\": {\n                    \"id\": \"str\",\n                    \"views\": \"[str]\",\n                    \"split\": \"str\",\n                },\n            }\n        ],\n        \"media\": [\n            {\n                \"name\": \"image\",\n                \"fields\": {\n                    \"id\": \"str\",\n                    \"image\": \"image\",\n                },\n            }\n        ],\n        \"objects\": [\n            {\n                \"name\": \"objects\",\n                \"fields\": {\n                    \"id\": \"str\",\n                    \"item_id\": \"str\",\n                    \"view_id\": \"str\",\n                    \"bbox\": \"bbox\",\n                    \"category_id\": \"int\",\n                    \"category_name\": \"str\",\n                },\n                \"source\": \"Ground Truth\",\n            }\n        ],\n    }\n\n    # Initialize Importer\n    super().__init__(name, description, tables, splits)\n</code></pre>"},{"location":"code/data/importers/dota_importer/#pixano.data.importers.dota_importer.DOTAImporter.import_rows","title":"<code>import_rows(input_dirs, portable=False)</code>","text":"<p>Process dataset rows for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/dota_importer.py</code> <pre><code>def import_rows(\n    self,\n    input_dirs: dict[str, Path],\n    portable: bool = False,\n) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n    for split in self.info.splits:\n        # Get images paths\n        image_paths = glob.glob(str(input_dirs[\"image\"] / split / \"*.png\"))\n        image_paths = [Path(p) for p in sorted(image_paths, key=natural_key)]\n\n        # Process rows\n        for im_path in image_paths:\n            # Load image annotations\n            im_anns_file = (\n                input_dirs[\"objects\"]\n                / split\n                / \"hbb\"\n                / im_path.name.replace(\"png\", \"txt\")\n            )\n            with open(im_anns_file) as f:\n                im_anns = [line.strip().split() for line in f]\n\n            # Allow DOTA largest images\n            PILImage.MAX_IMAGE_PIXELS = 806504000\n\n            # Get image dimensions and thumbnail\n            with PILImage.open(im_path) as im:\n                im_w, im_h = im.size\n                im_thumb = image_to_thumbnail(im)\n\n            # Set image URI\n            im_uri = (\n                f\"image/{split}/{im_path.name}\"\n                if portable\n                else im_path.absolute().as_uri()\n            )\n\n            # Return rows\n            rows = {\n                \"main\": {\n                    \"db\": [\n                        {\n                            \"id\": im_path.stem,\n                            \"views\": [\"image\"],\n                            \"split\": split,\n                        }\n                    ]\n                },\n                \"media\": {\n                    \"image\": [\n                        {\n                            \"id\": im_path.stem,\n                            \"image\": Image(im_uri, None, im_thumb).to_dict(),\n                        }\n                    ]\n                },\n                \"objects\": {\n                    \"objects\": [\n                        {\n                            \"id\": shortuuid.uuid(),\n                            \"item_id\": im_path.stem,\n                            \"view_id\": \"image\",\n                            \"bbox\": BBox.from_xyxy(\n                                [\n                                    float(ann[0]),\n                                    float(ann[1]),\n                                    float(ann[4]),\n                                    float(ann[5]),\n                                ]\n                            )\n                            .normalize(im_h, im_w)\n                            .to_dict(),\n                            \"category_id\": dota_ids(str(ann[8])),\n                            \"category_name\": str(ann[8]).replace(\"-\", \" \"),\n                        }\n                        for ann in im_anns\n                    ]\n                },\n            }\n\n            yield rows\n</code></pre>"},{"location":"code/data/importers/image_importer/","title":"image_importer","text":""},{"location":"code/data/importers/image_importer/#pixano.data.importers.image_importer","title":"<code>pixano.data.importers.image_importer</code>","text":""},{"location":"code/data/importers/image_importer/#pixano.data.importers.image_importer.ImageImporter","title":"<code>ImageImporter(name, description, splits=None, media_fields={'image': 'image'})</code>","text":"<p>             Bases: <code>Importer</code></p> <p>Importer class for image datasets</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits. Defaults to None for datasets with no subfolders for splits.</p> <code>None</code> <code>media_fields</code> <code>dict[str, str]</code> <p>Dataset media fields, with field names as keys and field types as values. Default to {\"image\": \"image\"}.</p> <code>{'image': 'image'}</code> Source code in <code>pixano/data/importers/image_importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str] = None,\n    media_fields: dict[str, str] = {\"image\": \"image\"},\n):\n    \"\"\"Initialize Image Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str], optional): Dataset splits. Defaults to None for datasets with no subfolders for splits.\n        media_fields (dict[str, str]): Dataset media fields, with field names as keys and field types as values. Default to {\"image\": \"image\"}.\n    \"\"\"\n\n    tables = {\n        \"main\": [\n            {\n                \"name\": \"db\",\n                \"fields\": {\n                    \"id\": \"str\",\n                    \"views\": \"[str]\",\n                    \"split\": \"str\",\n                },\n            }\n        ],\n        \"media\": [],\n    }\n\n    # Add media fields to tables\n    for field_name, field_type in media_fields.items():\n        table_exists = False\n        # If table for given field type exists\n        for media_table in tables[\"media\"]:\n            if field_type == media_table[\"name\"] and not table_exists:\n                media_table[\"fields\"][field_name] = field_type\n                table_exists = True\n        # Else, create that table\n        if not table_exists:\n            tables[\"media\"].append(\n                {\n                    \"name\": field_type,\n                    \"fields\": {\n                        \"id\": \"str\",\n                        field_name: field_type,\n                    },\n                }\n            )\n\n    # If no splits given, define a default single dataset split\n    if not splits:\n        splits = [\"dataset\"]\n\n    # Initialize Importer\n    super().__init__(name, description, tables, splits)\n</code></pre>"},{"location":"code/data/importers/image_importer/#pixano.data.importers.image_importer.ImageImporter.import_rows","title":"<code>import_rows(input_dirs, portable=False)</code>","text":"<p>Process dataset rows for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/image_importer.py</code> <pre><code>def import_rows(\n    self,\n    input_dirs: dict[str, Path],\n    portable: bool = False,\n) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    for split in self.info.splits:\n        # Get images paths\n        image_paths = []\n        for ftype in [\"*.png\", \"*.jpg\", \"*.jpeg\"]:\n            if split == \"dataset\":\n                image_paths.extend(glob.glob(str(input_dirs[\"image\"] / ftype)))\n            else:\n                image_paths.extend(\n                    glob.glob(str(input_dirs[\"image\"] / split / ftype))\n                )\n        image_paths = [Path(p) for p in sorted(image_paths, key=natural_key)]\n\n        # Process rows\n        for im_path in image_paths:\n            # Create image thumbnail\n            im_thumb = image_to_thumbnail(im_path.read_bytes())\n\n            # Set image URI\n            if portable:\n                im_uri = (\n                    f\"image/{im_path.name}\"\n                    if split == \"dataset\"\n                    else f\"image/{split}/{im_path.name}\"\n                )\n            else:\n                im_uri = im_path.absolute().as_uri()\n\n            # Return rows\n            rows = {\n                \"main\": {\n                    \"db\": [\n                        {\n                            \"id\": im_path.name,\n                            \"views\": [\"image\"],\n                            \"split\": split,\n                            \"label\": \"\",\n                        }\n                    ]\n                },\n                \"media\": {\n                    \"image\": [\n                        {\n                            \"id\": im_path.name,\n                            \"image\": Image(im_uri, None, im_thumb).to_dict(),\n                        }\n                    ]\n                },\n            }\n            yield rows\n</code></pre>"},{"location":"code/data/importers/importer/","title":"importer","text":""},{"location":"code/data/importers/importer/#pixano.data.importers.importer","title":"<code>pixano.data.importers.importer</code>","text":""},{"location":"code/data/importers/importer/#pixano.data.importers.importer.Importer","title":"<code>Importer(name, description, tables, splits)</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Dataset Importer class</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>tables</code> <code>dict[str, list]</code> <p>Dataset fields</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    tables: dict[str, list],\n    splits: list[str],\n):\n    \"\"\"Initialize Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        tables (dict[str, list]): Dataset fields\n        splits (list[str]): Dataset splits\n    \"\"\"\n\n    # Dataset info\n    self.info = DatasetInfo(\n        id=shortuuid.uuid(),\n        name=name,\n        description=description,\n        estimated_size=\"N/A\",\n        num_elements=0,\n        preview=None,\n        splits=splits,\n        tables=tables,\n        categories=[],\n    )\n</code></pre>"},{"location":"code/data/importers/importer/#pixano.data.importers.importer.Importer.create_json","title":"<code>create_json(import_dir, ds_tables)</code>","text":"<p>Create dataset spec.json</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>ds_tables</code> <code>dict[str, dict[str, LanceTable]]</code> <p>Dataset tables</p> required Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def create_json(\n    self,\n    import_dir: Path,\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]],\n):\n    \"\"\"Create dataset spec.json\n\n    Args:\n        import_dir (Path): Import directory\n        ds_tables (dict[str, dict[str, lancedb.db.LanceTable]]): Dataset tables\n    \"\"\"\n\n    self.info.num_elements = len(ds_tables[\"main\"][\"db\"])\n    self.info.estimated_size = estimate_size(import_dir)\n\n    # Save DatasetInfo\n    with tqdm(desc=\"Creating dataset info file\", total=1) as progress:\n        self.info.save(import_dir)\n        progress.update(1)\n</code></pre>"},{"location":"code/data/importers/importer/#pixano.data.importers.importer.Importer.create_preview","title":"<code>create_preview(import_dir, ds_tables)</code>","text":"<p>Create dataset preview image</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>ds_tables</code> <code>dict[str, dict[str, LanceTable]]</code> <p>Dataset tables</p> required Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def create_preview(\n    self,\n    import_dir: Path,\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]],\n):\n    \"\"\"Create dataset preview image\n\n    Args:\n        import_dir (Path): Import directory\n        ds_tables (dict[str, dict[str, lancedb.db.LanceTable]]): Dataset tables\n    \"\"\"\n\n    # Get list of image fields\n    if \"media\" in ds_tables:\n        if \"image\" in ds_tables[\"media\"]:\n            image_table = ds_tables[\"media\"][\"image\"]\n            if len(image_table) &gt; 0:\n                image_fields = [\n                    field.name for field in image_table.schema if field.name != \"id\"\n                ]\n                with tqdm(desc=\"Creating dataset thumbnail\", total=1) as progress:\n                    tile_w = 64\n                    tile_h = 64\n                    preview = Image.new(\"RGB\", (4 * tile_w, 2 * tile_h))\n                    for i in range(8):\n                        field = image_fields[i % len(image_fields)]\n                        item_id = random.randrange(len(image_table))\n                        item = image_table.to_lance().take([item_id]).to_pylist()[0]\n                        with Image.open(BytesIO(item[field].preview_bytes)) as im:\n                            preview.paste(\n                                im,\n                                ((i % 4) * tile_w, (int(i / 4) % 2) * tile_h),\n                            )\n                    preview.save(import_dir / \"preview.png\")\n                    progress.update(1)\n</code></pre>"},{"location":"code/data/importers/importer/#pixano.data.importers.importer.Importer.import_dataset","title":"<code>import_dataset(input_dirs, import_dir, portable=False)</code>","text":"<p>Import dataset to Pixano format</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>portable</code> <code>bool</code> <p>True to copy or download files to import directory and use relative paths. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Imported dataset</p> Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def import_dataset(\n    self,\n    input_dirs: dict[str, Path],\n    import_dir: Path,\n    portable: bool = False,\n) -&gt; Dataset:\n    \"\"\"Import dataset to Pixano format\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        import_dir (Path): Import directory\n        portable (bool, optional): True to copy or download files to import directory and use relative paths. Defaults to False.\n\n    Returns:\n        Dataset: Imported dataset\n    \"\"\"\n\n    # Check input directories\n    for source_path in input_dirs.values():\n        if not source_path.exists():\n            raise FileNotFoundError(f\"{source_path} does not exist.\")\n        if not any(source_path.iterdir()):\n            raise FileNotFoundError(f\"{source_path} is empty.\")\n\n    # Connect to dataset\n    import_dir.mkdir(parents=True, exist_ok=True)\n    ds = lancedb.connect(import_dir)\n\n    # Initialize dataset tables\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]] = defaultdict(dict)\n    ds_batches: dict[str, dict[str, list]] = defaultdict(dict)\n\n    # Create tables\n    for table_group, tables in self.info.tables.items():\n        for table in tables:\n            ds_tables[table_group][table[\"name\"]] = ds.create_table(\n                table[\"name\"],\n                schema=Fields(table[\"fields\"]).to_schema(),\n                mode=\"overwrite\",\n            )\n            ds_batches[table_group][table[\"name\"]] = []\n    save_batch_size = 1024\n\n    # Add rows to tables\n    for rows in tqdm(\n        self.import_rows(input_dirs, portable),\n        desc=\"Importing dataset\",\n    ):\n        for table_group, tables in self.info.tables.items():\n            for table in tables:\n                # Store rows in a batch\n                ds_batches[table_group][table[\"name\"]].extend(\n                    rows[table_group][table[\"name\"]]\n                )\n                # If batch reaches 1024 rows, store in table\n                if len(ds_batches[table_group][table[\"name\"]]) &gt;= save_batch_size:\n                    pa_batch = pa.Table.from_pylist(\n                        ds_batches[table_group][table[\"name\"]],\n                        schema=Fields(table[\"fields\"]).to_schema(),\n                    )\n                    lance.write_dataset(\n                        pa_batch,\n                        uri=ds_tables[table_group][table[\"name\"]].to_lance().uri,\n                        mode=\"append\",\n                    )\n                    ds_batches[table_group][table[\"name\"]] = []\n\n    # Store final batches\n    for table_group, tables in self.info.tables.items():\n        for table in tables:\n            if len(ds_batches[table_group][table[\"name\"]]) &gt; 0:\n                pa_batch = pa.Table.from_pylist(\n                    ds_batches[table_group][table[\"name\"]],\n                    schema=Fields(table[\"fields\"]).to_schema(),\n                )\n                lance.write_dataset(\n                    pa_batch,\n                    uri=ds_tables[table_group][table[\"name\"]].to_lance().uri,\n                    mode=\"append\",\n                )\n                ds_batches[table_group][table[\"name\"]] = []\n\n    # Optimize and clear creation history\n    for tables in ds_tables.values():\n        for table in tables.values():\n            table.to_lance().optimize.compact_files()\n            table.to_lance().cleanup_old_versions(older_than=timedelta(0))\n\n    # Refresh tables\n    for table_group, tables in self.info.tables.items():\n        for table in tables:\n            ds_tables[table_group][table[\"name\"]] = ds.open_table(table[\"name\"])\n\n    # Raise error if generated dataset is empty\n    if len(ds_tables[\"main\"][\"db\"]) == 0:\n        raise FileNotFoundError(\n            \"Generated dataset is empty. Please make sure that the paths to your media files are correct, and that they each contain subfolders for your splits.\"\n        )\n\n    # Copy media directories if portable\n    if portable and \"media\" in ds_tables:\n        for table in tqdm(\n            ds_tables[\"media\"].values(), desc=\"Copying media directories\"\n        ):\n            for field in table.schema:\n                if field.name in input_dirs:\n                    field_dir = import_dir / \"media\" / field.name\n                    field_dir.mkdir(parents=True, exist_ok=True)\n                    if input_dirs[field.name] != field_dir:\n                        shutil.copytree(\n                            input_dirs[field.name], field_dir, dirs_exist_ok=True\n                        )\n\n    # Create spec.json\n    self.create_json(import_dir, ds_tables)\n\n    # Create preview.png\n    self.create_preview(import_dir, ds_tables)\n\n    return Dataset(import_dir)\n</code></pre>"},{"location":"code/data/importers/importer/#pixano.data.importers.importer.Importer.import_rows","title":"<code>import_rows(input_dirs, portable=False)</code>  <code>abstractmethod</code>","text":"<p>Process dataset rows for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/importer.py</code> <pre><code>@abstractmethod\ndef import_rows(\n    self,\n    input_dirs: dict[str, Path],\n    portable: bool = False,\n) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n</code></pre>"},{"location":"code/models/inference_model/","title":"inference_model","text":""},{"location":"code/models/inference_model/#pixano.models.inference_model","title":"<code>pixano.models.inference_model</code>","text":""},{"location":"code/models/inference_model/#pixano.models.inference_model.InferenceModel","title":"<code>InferenceModel(name, id='', device='', description='')</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract parent class for OfflineModel and OnlineModel</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Model name</p> <code>id</code> <code>str</code> <p>Model ID</p> <code>device</code> <code>str</code> <p>Model GPU or CPU device</p> <code>description</code> <code>str</code> <p>Model description</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>id</code> <code>str</code> <p>Model ID. Defaults to \"\".</p> <code>''</code> <code>device</code> <code>str</code> <p>Model GPU or CPU device. Defaults to \"\".</p> <code>''</code> <code>description</code> <code>str</code> <p>Model description. Defaults to \"\".</p> <code>''</code> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    id: str = \"\",\n    device: str = \"\",\n    description: str = \"\",\n) -&gt; None:\n    \"\"\"Initialize model name and ID\n\n    Args:\n        name (str): Model name\n        id (str, optional): Model ID. Defaults to \"\".\n        device (str, optional): Model GPU or CPU device. Defaults to \"\".\n        description (str, optional): Model description. Defaults to \"\".\n    \"\"\"\n\n    self.name = name\n    if id == \"\":\n        self.id = f\"{datetime.now().strftime('%y%m%d_%H%M%S')}_{name}\"\n    else:\n        self.id = id\n    self.device = device\n    self.description = description\n</code></pre>"},{"location":"code/models/inference_model/#pixano.models.inference_model.InferenceModel.export_to_onnx","title":"<code>export_to_onnx(library_dir)</code>","text":"<p>Export Torch model to ONNX</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>Path</code> <p>Dataset library directory</p> required Source code in <code>pixano/models/inference_model.py</code> <pre><code>def export_to_onnx(self, library_dir: Path):\n    \"\"\"Export Torch model to ONNX\n\n    Args:\n        library_dir (Path): Dataset library directory\n    \"\"\"\n</code></pre>"},{"location":"code/models/inference_model/#pixano.models.inference_model.InferenceModel.preannotate","title":"<code>preannotate(batch, views, uri_prefix, threshold=0.0)</code>","text":"<p>Preannotate dataset rows</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>RecordBatch</code> <p>Input batch</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>uri_prefix</code> <code>str</code> <p>URI prefix for media files</p> required <code>threshold</code> <code>float</code> <p>Confidence threshold. Defaults to 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>Annotation rows</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def preannotate(\n    self,\n    batch: pa.RecordBatch,\n    views: list[str],\n    uri_prefix: str,\n    threshold: float = 0.0,\n) -&gt; list[dict]:\n    \"\"\"Preannotate dataset rows\n\n    Args:\n        batch (pa.RecordBatch): Input batch\n        views (list[str]): Dataset views\n        uri_prefix (str): URI prefix for media files\n        threshold (float, optional): Confidence threshold. Defaults to 0.0.\n\n    Returns:\n        list[dict]: Annotation rows\n    \"\"\"\n</code></pre>"},{"location":"code/models/inference_model/#pixano.models.inference_model.InferenceModel.precompute_embeddings","title":"<code>precompute_embeddings(batch, views, uri_prefix)</code>","text":"<p>Precompute embeddings for dataset rows</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>RecordBatch</code> <p>Input batch</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>uri_prefix</code> <code>str</code> <p>URI prefix for media files</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Embedding rows</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def precompute_embeddings(\n    self,\n    batch: pa.RecordBatch,\n    views: list[str],\n    uri_prefix: str,\n) -&gt; list[dict]:\n    \"\"\"Precompute embeddings for dataset rows\n\n    Args:\n        batch (pa.RecordBatch): Input batch\n        views (list[str]): Dataset views\n        uri_prefix (str): URI prefix for media files\n\n    Returns:\n        list[dict]: Embedding rows\n    \"\"\"\n</code></pre>"},{"location":"code/models/inference_model/#pixano.models.inference_model.InferenceModel.process_dataset","title":"<code>process_dataset(dataset_dir, process_type, views, splits=None, batch_size=1, threshold=0.0)</code>","text":"<p>Process dataset for preannotation or embedding precomputing</p> <p>Parameters:</p> Name Type Description Default <code>dataset_dir</code> <code>Path</code> <p>Dataset directory</p> required <code>process_type</code> <code>str</code> <p>Process type                 - 'obj' for preannotation                 - 'segment_emb' for segmentation embedding precomputing                 - 'search_emb' for semantic search embedding precomputing</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits, all if None. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Rows per batch. Defaults to 1.</p> <code>1</code> <code>threshold</code> <code>float</code> <p>Confidence threshold for predictions. Defaults to 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def process_dataset(\n    self,\n    dataset_dir: Path,\n    process_type: str,\n    views: list[str],\n    splits: list[str] = None,\n    batch_size: int = 1,\n    threshold: float = 0.0,\n) -&gt; Dataset:\n    \"\"\"Process dataset for preannotation or embedding precomputing\n\n    Args:\n        dataset_dir (Path): Dataset directory\n        process_type (str): Process type\n                            - 'obj' for preannotation\n                            - 'segment_emb' for segmentation embedding precomputing\n                            - 'search_emb' for semantic search embedding precomputing\n        views (list[str]): Dataset views\n        splits (list[str], optional): Dataset splits, all if None. Defaults to None.\n        batch_size (int, optional): Rows per batch. Defaults to 1.\n        threshold (float, optional): Confidence threshold for predictions. Defaults to 0.0.\n\n    Returns:\n        Dataset: Dataset\n    \"\"\"\n\n    output_filename = f\"{process_type}_{self.id}\"\n    if splits:\n        split_ids = \"'\" + \"', '\".join(splits) + \"'\"\n    if process_type not in [\"obj\", \"segment_emb\", \"search_emb\"]:\n        raise Exception(\n            \"Please choose a valid process type ('obj' for preannotation, 'segment_emb' or 'search_emb'\"\n            \"for segmentation or semantic search embedding precomputing)\"\n        )\n\n    # Load dataset\n    dataset = Dataset(dataset_dir)\n    ds = dataset.connect()\n\n    # Load dataset tables\n    main_table: lancedb.db.LanceTable = ds.open_table(\"db\")\n    media_tables: dict[str, lancedb.db.LanceTable] = {}\n    if \"media\" in dataset.info.tables:\n        for md_info in dataset.info.tables[\"media\"]:\n            media_tables[md_info[\"name\"]] = ds.open_table(md_info[\"name\"])\n\n    # Create URI prefix\n    uri_prefix = dataset.media_dir.absolute().as_uri()\n\n    # Objects preannotation schema\n    if process_type == \"obj\":\n        table_group = \"objects\"\n        table_fields = {\n            \"id\": \"str\",\n            \"item_id\": \"str\",\n            \"view_id\": \"str\",\n            \"bbox\": \"bbox\",\n            \"mask\": \"compressedrle\",\n            \"category_id\": \"int\",\n            \"category_name\": \"str\",\n        }\n    # Segmentation Embedding precomputing schema\n    elif process_type == \"segment_emb\":\n        table_group = \"embeddings\"\n        table_fields = {\"id\": \"str\"}\n        # Add embedding column for each selected view\n        for view in views:\n            table_fields[view] = \"bytes\"\n    # Semantic Search Embedding precomputing schema\n    elif process_type == \"search_emb\":\n        table_group = \"embeddings\"\n        table_fields = {\"id\": \"str\", \"view\": \"str\", \"vector\": \"vector(512)\"}\n\n    # Create new table\n    table: lancedb.db.LanceTable = ds.create_table(\n        output_filename,\n        schema=Fields(table_fields).to_schema(),\n        mode=\"overwrite\",\n    )\n    table_ds = table.to_lance()\n    output_batch = []\n    save_batch_size = 1024\n\n    # Add new table to DatasetInfo\n    table_info = {\n        \"name\": output_filename,\n        \"source\": self.name,\n        \"fields\": table_fields,\n    }\n    if process_type == \"segment_emb\":\n        table_info[\"type\"] = \"segment\"\n    elif process_type == \"search_emb\":\n        table_info[\"type\"] = \"search\"\n\n    if table_group in dataset.info.tables:\n        dataset.info.tables[table_group].append(table_info)\n    else:\n        dataset.info.tables[table_group] = [table_info]\n    dataset.save_info()\n\n    # Add rows to tables\n    with tqdm(desc=\"Processing dataset\", total=len(main_table)) as progress:\n        for i in range(ceil(len(main_table) / save_batch_size)):\n            # Load rows\n            offset = i * save_batch_size\n            limit = min(len(main_table), offset + save_batch_size)\n            pyarrow_table = main_table.to_lance()\n            pyarrow_table = duckdb.query(\n                f\"SELECT * FROM pyarrow_table ORDER BY len(id), id LIMIT {limit} OFFSET {offset}\"\n            ).to_arrow_table()\n            for media_table in media_tables.values():\n                pyarrow_media_table = media_table.to_lance().to_table(\n                    limit=limit, offset=offset\n                )\n                pyarrow_media_table = duckdb.query(\n                    f\"SELECT * FROM pyarrow_media_table ORDER BY len(id), id LIMIT {limit} OFFSET {offset}\"\n                ).to_arrow_table()\n                pyarrow_table = duckdb.query(\n                    \"SELECT * FROM pyarrow_table LEFT JOIN pyarrow_media_table USING (id) ORDER BY len(id), id\"\n                ).to_arrow_table()\n            # Filter splits\n            if splits:\n                pyarrow_table = duckdb.query(\n                    f\"SELECT * FROM pyarrow_table WHERE split in ({split_ids})\"\n                ).to_arrow_table()\n            # Convert to RecordBatch\n            input_batches = pyarrow_table.to_batches(max_chunksize=batch_size)\n\n            # Store rows in a batch\n            for input_batch in input_batches:\n                output_batch.extend(\n                    self.preannotate(input_batch, views, uri_prefix, threshold)\n                    if process_type == \"obj\"\n                    else self.precompute_embeddings(input_batch, views, uri_prefix)\n                    if process_type == \"segment_emb\" or process_type == \"search_emb\"\n                    else []\n                )\n                progress.update(batch_size)\n\n            # If batch reaches 1024 rows, store in table\n            if len(output_batch) &gt;= save_batch_size:\n                pa_batch = pa.Table.from_pylist(\n                    output_batch,\n                    schema=Fields(table_info[\"fields\"]).to_schema(),\n                )\n                lance.write_dataset(\n                    pa_batch,\n                    uri=table_ds.uri,\n                    mode=\"append\",\n                )\n                output_batch = []\n\n    # Store final batch\n    if len(output_batch) &gt; 0:\n        pa_batch = pa.Table.from_pylist(\n            output_batch,\n            schema=Fields(table_info[\"fields\"]).to_schema(),\n        )\n        lance.write_dataset(\n            pa_batch,\n            uri=table_ds.uri,\n            mode=\"append\",\n        )\n        output_batch = []\n\n    # Optimize and clear creation history\n    table_ds.optimize.compact_files()\n    table_ds.cleanup_old_versions(older_than=timedelta(0))\n\n    return dataset\n</code></pre>"},{"location":"code/utils/boxes/","title":"boxes","text":""},{"location":"code/utils/boxes/#pixano.utils.boxes","title":"<code>pixano.utils.boxes</code>","text":""},{"location":"code/utils/boxes/#pixano.utils.boxes.denormalize_coords","title":"<code>denormalize_coords(coord, height, width, rounded_int=True)</code>","text":"<p>Denormalize coordinates</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Normalized coordinates</p> required <code>height</code> <code>int</code> <p>Height</p> required <code>width</code> <code>int</code> <p>Width</p> required <code>rounded_int</code> <code>bool</code> <p>True to round denormalized float to nearest integer. Default to True</p> <code>True</code> <p>Returns:</p> Type Description <code>list[float]</code> <p>Unnormalized coordinates,</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def denormalize_coords(coord: list[float], height: int, width: int, rounded_int=True) -&gt; list[float]:\n    \"\"\"Denormalize coordinates\n\n    Args:\n        coord (list[float]): Normalized coordinates\n        height (int): Height\n        width (int): Width\n        rounded_int (bool): True to round denormalized float to nearest integer. Default to True\n\n    Returns:\n        list[float]: Unnormalized coordinates,\n    \"\"\"\n\n    denorm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            denorm.append(round(c * width) if rounded_int else c * width)\n        else:\n            denorm.append(round(c * height) if rounded_int else c * height)\n\n    return denorm\n</code></pre>"},{"location":"code/utils/boxes/#pixano.utils.boxes.format_bbox","title":"<code>format_bbox(bbox, confidence=0.0)</code>","text":"<p>Convert bounding box to frontend format</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>list[float]</code> <p>Bounding box</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence. Defaults to None.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>dict</code> <p>Bounding box in frontend format</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def format_bbox(bbox: list[float], confidence: float = 0.0) -&gt; dict:\n    \"\"\"Convert bounding box to frontend format\n\n    Args:\n        bbox (list[float]): Bounding box\n        confidence (float, optional): Bounding box confidence. Defaults to None.\n\n    Returns:\n        dict: Bounding box in frontend format\n    \"\"\"\n\n    if bbox != [0.0, 0.0, 0.0, 0.0]:\n        return {\n            \"x\": float(bbox[0]),\n            \"y\": float(bbox[1]),\n            \"width\": float(bbox[2]),\n            \"height\": float(bbox[3]),\n            \"predicted\": confidence != 0.0,\n            \"confidence\": confidence,\n        }\n</code></pre>"},{"location":"code/utils/boxes/#pixano.utils.boxes.mask_to_bbox","title":"<code>mask_to_bbox(mask)</code>","text":"<p>Return the smallest bounding box containing all the mask pixels</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask as NumPy Array</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized xywh bounding box</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def mask_to_bbox(mask: np.ndarray) -&gt; list[float]:\n    \"\"\"Return the smallest bounding box containing all the mask pixels\n\n    Args:\n        mask (np.ndarray): Mask as NumPy Array\n\n    Returns:\n        list[float]: Normalized xywh bounding box\n    \"\"\"\n\n    height, width = mask.shape\n    bool_mask = np.array(mask).astype(bool)\n\n    # Find all columns and rows that contain ones\n    rows = np.any(bool_mask, axis=1)\n    cols = np.any(bool_mask, axis=0)\n\n    # Find the min and max col/row index that contain ones\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    # Calculate bbox height and width\n    w = (cmax - cmin + 1) / width\n    h = (rmax - rmin + 1) / height\n\n    return [cmin / width, rmin / height, w, h]\n</code></pre>"},{"location":"code/utils/boxes/#pixano.utils.boxes.normalize_coords","title":"<code>normalize_coords(coord, height, width)</code>","text":"<p>Normalize coordinates</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Unnormalized coordinates</p> required <code>height</code> <code>int</code> <p>Height</p> required <code>width</code> <code>int</code> <p>Width</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized coordinates</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def normalize_coords(coord: list[float], height: int, width: int) -&gt; list[float]:\n    \"\"\"Normalize coordinates\n\n    Args:\n        coord (list[float]): Unnormalized coordinates\n        height (int): Height\n        width (int): Width\n\n    Returns:\n        list[float]: Normalized coordinates\n    \"\"\"\n\n    norm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            norm.append(c / width)\n        else:\n            norm.append(c / height)\n\n    return norm\n</code></pre>"},{"location":"code/utils/boxes/#pixano.utils.boxes.urle_to_bbox","title":"<code>urle_to_bbox(urle)</code>","text":"<p>Return the smallest bounding box containing all the mask pixels</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized xywh bounding box</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def urle_to_bbox(urle: dict) -&gt; list[float]:\n    \"\"\"Return the smallest bounding box containing all the mask pixels\n\n    Args:\n        urle (dict): Mask as uncompressed RLE\n\n    Returns:\n        list[float]: Normalized xywh bounding box\n    \"\"\"\n\n    return mask_to_bbox(rle_to_mask(urle_to_rle(urle)))\n</code></pre>"},{"location":"code/utils/boxes/#pixano.utils.boxes.xywh_to_xyxy","title":"<code>xywh_to_xyxy(xywh)</code>","text":"<p>Convert bounding box coordinates from xywh (using top left point as reference) to xyxy</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>xywh coordinates</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>xyxy coordinates</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def xywh_to_xyxy(xywh: list[float]) -&gt; list[float]:\n    \"\"\"Convert bounding box coordinates from xywh (using top left point as reference) to xyxy\n\n    Args:\n        xywh (list[float]): xywh coordinates\n\n    Returns:\n        list[float]: xyxy coordinates\n    \"\"\"\n\n    return [\n        float(xywh[0]),\n        float(xywh[1]),\n        float(xywh[0] + xywh[2]),\n        float(xywh[1] + xywh[3]),\n    ]\n</code></pre>"},{"location":"code/utils/boxes/#pixano.utils.boxes.xyxy_to_xywh","title":"<code>xyxy_to_xywh(xyxy)</code>","text":"<p>Convert bounding box coordinates from xyxy to xywh (using top left point as reference)</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>xyxy coordinates</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>xywh coordinates</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def xyxy_to_xywh(xyxy: list[float]) -&gt; list[float]:\n    \"\"\"Convert bounding box coordinates from xyxy to xywh (using top left point as reference)\n\n    Args:\n        xyxy (list[float]): xyxy coordinates\n\n    Returns:\n        list[float]: xywh coordinates\n    \"\"\"\n\n    return [\n        float(xyxy[0]),\n        float(xyxy[1]),\n        float(xyxy[2] - xyxy[0]),\n        float(xyxy[3] - xyxy[1]),\n    ]\n</code></pre>"},{"location":"code/utils/image/","title":"image","text":""},{"location":"code/utils/image/#pixano.utils.image","title":"<code>pixano.utils.image</code>","text":""},{"location":"code/utils/image/#pixano.utils.image.binary_to_url","title":"<code>binary_to_url(im_bytes)</code>","text":"<p>Encode image from binary to base 64 URL</p> <p>Parameters:</p> Name Type Description Default <code>im_bytes</code> <code>bytes</code> <p>Image as binary</p> required <p>Returns:</p> Type Description <code>str</code> <p>Image as base 64</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def binary_to_url(im_bytes: bytes) -&gt; str:\n    \"\"\"Encode image from binary to base 64 URL\n\n    Args:\n        im_bytes (bytes): Image as binary\n\n    Returns:\n        str: Image as base 64\n    \"\"\"\n\n    if im_bytes is not None:\n        encoded = base64.b64encode(im_bytes).decode(\"utf-8\")\n        return f\"data:image;base64,{encoded}\"\n    else:\n        return \"\"\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.depth_array_to_gray","title":"<code>depth_array_to_gray(depth, valid_start=0.2, valid_end=1, scale=1.0)</code>","text":"<p>Encode depth array to gray levels</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>ndarray</code> <p>Depth array</p> required <code>valid_start</code> <code>float</code> <p>Valid start. Defaults to 0.2.</p> <code>0.2</code> <code>valid_end</code> <code>float</code> <p>Valid end. Defaults to 1.</p> <code>1</code> <code>scale</code> <code>float</code> <p>Scale. Defaults to 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Depth array in gray levels</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def depth_array_to_gray(\n    depth: np.ndarray,\n    valid_start: float = 0.2,\n    valid_end: float = 1,\n    scale: float = 1.0,\n) -&gt; np.ndarray:\n    \"\"\"Encode depth array to gray levels\n\n    Args:\n        depth (np.ndarray): Depth array\n        valid_start (float, optional): Valid start. Defaults to 0.2.\n        valid_end (float, optional): Valid end. Defaults to 1.\n        scale (float, optional): Scale. Defaults to 1.0.\n\n    Returns:\n        np.ndarray: Depth array in gray levels\n    \"\"\"\n\n    mask = depth &gt; 1\n\n    # Scale gives depth in mm\n    depth_n = depth * scale * 0.001\n\n    if mask.sum() &gt; 0:\n        depth_n[mask] -= depth_n[mask].min()\n        depth_n[mask] /= depth_n[mask].max() / (valid_end - valid_start)\n        depth_n[mask] += valid_start\n\n    depth_n *= 255\n    depth_n = cv2.applyColorMap(\n        depth_n[:, :, np.newaxis].astype(np.uint8), cv2.COLORMAP_PLASMA\n    )\n\n    return depth_n\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.depth_file_to_binary","title":"<code>depth_file_to_binary(depth_path)</code>","text":"<p>Encode depth file to RGB image in binary</p> <p>Parameters:</p> Name Type Description Default <code>depth_path</code> <code>str</code> <p>Depth file path</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Depth file as RGB image in binary</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def depth_file_to_binary(depth_path: str) -&gt; bytes:\n    \"\"\"Encode depth file to RGB image in binary\n\n    Args:\n        depth_path (str): Depth file path\n\n    Returns:\n        bytes: Depth file as RGB image in binary\n    \"\"\"\n\n    depth = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH).astype(np.float32)\n    depth = depth_array_to_gray(depth)\n    depth_rgb = Image.fromarray(depth)\n\n    return image_to_binary(depth_rgb)\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.encode_rle","title":"<code>encode_rle(mask, height, width)</code>","text":"<p>Encode mask from polygons / uncompressed RLE / RLE to RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict</code> <p>Mask as polygons / uncompressed RLE / RLE</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def encode_rle(mask: list[list] | dict, height: int, width: int) -&gt; dict:\n    \"\"\"Encode mask from polygons / uncompressed RLE / RLE to RLE\n\n    Args:\n        mask (list[list] | dict): Mask as polygons / uncompressed RLE / RLE\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if isinstance(mask, list):\n        rle = polygons_to_rle(mask, height, width)\n    elif isinstance(mask, dict):\n        if isinstance(mask[\"counts\"], list):\n            rle = urle_to_rle(mask)\n        else:\n            rle = mask\n    else:\n        rle = None\n    return rle\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.image_to_binary","title":"<code>image_to_binary(image, format='PNG')</code>","text":"<p>Encode image from Pillow to binary</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Image as Pillow</p> required <code>format</code> <code>str</code> <p>Image file extension. Defaults to \"PNG\".</p> <code>'PNG'</code> <p>Returns:</p> Type Description <code>bytes</code> <p>Image as binary</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def image_to_binary(image: Image.Image, format: str = \"PNG\") -&gt; bytes:\n    \"\"\"Encode image from Pillow to binary\n\n    Args:\n        image (Image.Image): Image as Pillow\n        format (str, optional): Image file extension. Defaults to \"PNG\".\n\n    Returns:\n        bytes: Image as binary\n    \"\"\"\n\n    if image is None:\n        return None\n\n    with BytesIO() as output_bytes:\n        image.save(output_bytes, format)\n        im_bytes = output_bytes.getvalue()\n\n    return im_bytes\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.image_to_thumbnail","title":"<code>image_to_thumbnail(image)</code>","text":"<p>Generate image thumbnail</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>bytes | Image</code> <p>Image as binary or as Pillow</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Image thumbnail as binary</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def image_to_thumbnail(image: bytes | Image.Image) -&gt; bytes:\n    \"\"\"Generate image thumbnail\n\n    Args:\n        image (bytes | Image.Image): Image as binary or as Pillow\n\n    Returns:\n        bytes: Image thumbnail as binary\n    \"\"\"\n\n    if isinstance(image, bytes):\n        image = Image.open(BytesIO(image))\n\n    image.thumbnail((128, 128))\n    return image_to_binary(image)\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.mask_to_polygons","title":"<code>mask_to_polygons(mask)</code>","text":"<p>Encode mask from NumPy array to polygons</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask as NumPy array</p> required <p>Returns:</p> Type Description <code>list</code> <p>Mask as polygons</p> <code>bool</code> <p>Mask has holes</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def mask_to_polygons(mask: np.ndarray) -&gt; tuple[list, bool]:\n    \"\"\"Encode mask from NumPy array to polygons\n\n    Args:\n        mask (np.ndarray): Mask as NumPy array\n\n    Returns:\n        list: Mask as polygons\n        bool: Mask has holes\n    \"\"\"\n\n    if mask is not None:\n        # Some versions of cv2 does not support incontiguous arr\n        mask = np.ascontiguousarray(mask)\n\n        # cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level hierarchy.\n        # External contours (boundary) of the object are placed in hierarchy-1.\n        # Internal contours (holes) are placed in hierarchy-2.\n        # cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.\n        res = cv2.findContours(\n            mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n        )\n        hierarchy = res[-1]\n\n        # If mask is empty\n        if hierarchy is None:\n            return [], False\n\n        # Check if mask has holes\n        has_holes = (hierarchy.reshape(-1, 4)[:, 3] &gt;= 0).sum() &gt; 0\n\n        res = res[-2]\n        res = [x.flatten() for x in res]\n\n        # The coordinates from OpenCV are integers in range [0, W-1 or H-1].\n        # We add 0.5 to turn them into real-value coordinate space. A better solution\n        # would be to first +0.5 and then dilate the returned polygon by 0.5.\n        res = [x + 0.5 for x in res if len(x) &gt;= 6]\n\n        return res, has_holes\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.mask_to_rle","title":"<code>mask_to_rle(mask)</code>","text":"<p>Encode mask from Pillow or NumPy array to RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image</code> <p>Mask as Pillow or NumPy array</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def mask_to_rle(mask: Image.Image) -&gt; dict:\n    \"\"\"Encode mask from Pillow or NumPy array to RLE\n\n    Args:\n        mask (Image.Image): Mask as Pillow or NumPy array\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if mask is not None:\n        mask_array = np.asfortranarray(mask)\n        return mask_api.encode(mask_array)\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.polygons_to_rle","title":"<code>polygons_to_rle(polygons, height, width)</code>","text":"<p>Encode mask from polygons to RLE</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>Mask as polygons</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def polygons_to_rle(polygons: list[list], height: int, width: int) -&gt; dict:\n    \"\"\"Encode mask from polygons to RLE\n\n    Args:\n        polygons (list[list]): Mask as polygons\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if polygons is not None:\n        rles = mask_api.frPyObjects(polygons, height, width)\n        return mask_api.merge(rles)\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.rle_to_mask","title":"<code>rle_to_mask(rle)</code>","text":"<p>Decode mask from RLE to NumPy array</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, Any]</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Mask as NumPy array</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def rle_to_mask(rle: dict[str, Any]) -&gt; np.ndarray:\n    \"\"\"Decode mask from RLE to NumPy array\n\n    Args:\n        rle (dict[str, Any]): Mask as RLE\n\n    Returns:\n        np.ndarray: Mask as NumPy array\n    \"\"\"\n\n    if rle is not None:\n        return mask_api.decode(rle)\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.rle_to_polygons","title":"<code>rle_to_polygons(rle)</code>","text":"<p>Encode mask from RLE to polygons</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, Any]</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>list[list]</code> <p>Mask as polygons</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def rle_to_polygons(rle: dict[str, Any]) -&gt; list[list]:\n    \"\"\"Encode mask from RLE to polygons\n\n    Args:\n        rle (dict[str, Any]): Mask as RLE\n\n    Returns:\n        list[list]: Mask as polygons\n    \"\"\"\n\n    if rle is not None and \"size\" in rle:\n        h, w = rle[\"size\"]\n        polygons, _ = mask_to_polygons(rle_to_mask(rle))\n\n        # Normalize point coordinates\n        for p in polygons:\n            p[::2] /= w\n            p[1::2] /= h\n\n        # Cast to python list\n        polygons = [p.tolist() for p in polygons]\n\n        return polygons\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.rle_to_urle","title":"<code>rle_to_urle(rle)</code>","text":"<p>Encode mask from RLE to uncompressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, Any]</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Mask as uncompressed RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def rle_to_urle(rle: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Encode mask from RLE to uncompressed RLE\n\n    Args:\n        rle (dict[str, Any]): Mask as RLE\n\n    Returns:\n        dict[str, Any]: Mask as uncompressed RLE\n    \"\"\"\n\n    if rle is not None and rle[\"counts\"] is not None:\n        mask = rle_to_mask(rle)\n        urle = {\"counts\": [], \"size\": list(mask.shape)}\n        counts = urle.get(\"counts\")\n\n        for i, (value, elements) in enumerate(groupby(mask.ravel(order=\"F\"))):\n            if i == 0 and value == 1:\n                counts.append(0)\n            counts.append(len(list(elements)))\n\n        return urle\n</code></pre>"},{"location":"code/utils/image/#pixano.utils.image.urle_to_rle","title":"<code>urle_to_rle(urle)</code>","text":"<p>Encode mask from uncompressed RLE to RLE</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict[str, Any]</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def urle_to_rle(urle: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Encode mask from uncompressed RLE to RLE\n\n    Args:\n        urle (dict[str, Any]): Mask as uncompressed RLE\n\n    Returns:\n        dict[str, Any]: Mask as RLE\n    \"\"\"\n\n    if urle is not None:\n        height, width = urle[\"size\"]\n        return mask_api.frPyObjects(urle, height, width)\n</code></pre>"},{"location":"code/utils/labels/","title":"labels","text":""},{"location":"code/utils/labels/#pixano.utils.labels","title":"<code>pixano.utils.labels</code>","text":""},{"location":"code/utils/labels/#pixano.utils.labels.coco_ids_80to91","title":"<code>coco_ids_80to91(cat_id)</code>","text":"<p>Return COCO category ID (80 to 91 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID (80 classes)</p> required <p>Returns:</p> Type Description <code>int</code> <p>Category ID (91 classes)</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def coco_ids_80to91(cat_id: int) -&gt; int:\n    \"\"\"Return COCO category ID (80 to 91 classes)\n\n    Args:\n        cat_id (int): Category ID (80 classes)\n\n    Returns:\n        int: Category ID (91 classes)\n    \"\"\"\n\n    coco_dict = {\n        1: 1,\n        2: 2,\n        3: 3,\n        4: 4,\n        5: 5,\n        6: 6,\n        7: 7,\n        8: 8,\n        9: 9,\n        10: 10,\n        11: 11,\n        12: 13,\n        13: 14,\n        14: 15,\n        15: 16,\n        16: 17,\n        17: 18,\n        18: 19,\n        19: 20,\n        20: 21,\n        21: 22,\n        22: 23,\n        23: 24,\n        24: 25,\n        25: 27,\n        26: 28,\n        27: 31,\n        28: 32,\n        29: 33,\n        30: 34,\n        31: 35,\n        32: 36,\n        33: 37,\n        34: 38,\n        35: 39,\n        36: 40,\n        37: 41,\n        38: 42,\n        39: 43,\n        40: 44,\n        41: 46,\n        42: 47,\n        43: 48,\n        44: 49,\n        45: 50,\n        46: 51,\n        47: 52,\n        48: 53,\n        49: 54,\n        50: 55,\n        51: 56,\n        52: 57,\n        53: 58,\n        54: 59,\n        55: 60,\n        56: 61,\n        57: 62,\n        58: 63,\n        59: 64,\n        60: 65,\n        61: 67,\n        62: 70,\n        63: 72,\n        64: 73,\n        65: 74,\n        66: 75,\n        67: 76,\n        68: 77,\n        69: 78,\n        70: 79,\n        71: 80,\n        72: 81,\n        73: 82,\n        74: 84,\n        75: 85,\n        76: 86,\n        77: 87,\n        78: 88,\n        79: 89,\n        80: 90,\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"code/utils/labels/#pixano.utils.labels.coco_names_80","title":"<code>coco_names_80(cat_id)</code>","text":"<p>Return COCO category name (80 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def coco_names_80(cat_id: int) -&gt; str:\n    \"\"\"Return COCO category name (80 classes)\n\n    Args:\n        cat_id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"stop sign\",\n        13: \"parking meter\",\n        14: \"bench\",\n        15: \"bird\",\n        16: \"cat\",\n        17: \"dog\",\n        18: \"horse\",\n        19: \"sheep\",\n        20: \"cow\",\n        21: \"elephant\",\n        22: \"bear\",\n        23: \"zebra\",\n        24: \"giraffe\",\n        25: \"backpack\",\n        26: \"umbrella\",\n        27: \"handbag\",\n        28: \"tie\",\n        29: \"suitcase\",\n        30: \"frisbee\",\n        31: \"skis\",\n        32: \"snowboard\",\n        33: \"sports ball\",\n        34: \"kite\",\n        35: \"baseball bat\",\n        36: \"baseball glove\",\n        37: \"skateboard\",\n        38: \"surfboard\",\n        39: \"tennis racket\",\n        40: \"bottle\",\n        41: \"wine glass\",\n        42: \"cup\",\n        43: \"fork\",\n        44: \"knife\",\n        45: \"spoon\",\n        46: \"bowl\",\n        47: \"banana\",\n        48: \"apple\",\n        49: \"sandwich\",\n        50: \"orange\",\n        51: \"broccoli\",\n        52: \"carrot\",\n        53: \"hot dog\",\n        54: \"pizza\",\n        55: \"donut\",\n        56: \"cake\",\n        57: \"chair\",\n        58: \"couch\",\n        59: \"potted plant\",\n        60: \"bed\",\n        61: \"dining table\",\n        62: \"toilet\",\n        63: \"tv\",\n        64: \"laptop\",\n        65: \"mouse\",\n        66: \"remote\",\n        67: \"keyboard\",\n        68: \"cell phone\",\n        69: \"microwave\",\n        70: \"oven\",\n        71: \"toaster\",\n        72: \"sink\",\n        73: \"refrigerator\",\n        74: \"book\",\n        75: \"clock\",\n        76: \"vase\",\n        77: \"scissors\",\n        78: \"teddy bear\",\n        79: \"hair drier\",\n        80: \"toothbrush\",\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"code/utils/labels/#pixano.utils.labels.coco_names_91","title":"<code>coco_names_91(cat_id)</code>","text":"<p>Return COCO category name (91 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def coco_names_91(cat_id: int) -&gt; str:\n    \"\"\"Return COCO category name (91 classes)\n\n    Args:\n        cat_id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"street sign\",\n        13: \"stop sign\",\n        14: \"parking meter\",\n        15: \"bench\",\n        16: \"bird\",\n        17: \"cat\",\n        18: \"dog\",\n        19: \"horse\",\n        20: \"sheep\",\n        21: \"cow\",\n        22: \"elephant\",\n        23: \"bear\",\n        24: \"zebra\",\n        25: \"giraffe\",\n        26: \"hat\",\n        27: \"backpack\",\n        28: \"umbrella\",\n        29: \"shoe\",\n        30: \"eye glasses\",\n        31: \"handbag\",\n        32: \"tie\",\n        33: \"suitcase\",\n        34: \"frisbee\",\n        35: \"skis\",\n        36: \"snowboard\",\n        37: \"sports ball\",\n        38: \"kite\",\n        39: \"baseball bat\",\n        40: \"baseball glove\",\n        41: \"skateboard\",\n        42: \"surfboard\",\n        43: \"tennis racket\",\n        44: \"bottle\",\n        45: \"plate\",\n        46: \"wine glass\",\n        47: \"cup\",\n        48: \"fork\",\n        49: \"knife\",\n        50: \"spoon\",\n        51: \"bowl\",\n        52: \"banana\",\n        53: \"apple\",\n        54: \"sandwich\",\n        55: \"orange\",\n        56: \"broccoli\",\n        57: \"carrot\",\n        58: \"hot dog\",\n        59: \"pizza\",\n        60: \"donut\",\n        61: \"cake\",\n        62: \"chair\",\n        63: \"couch\",\n        64: \"potted plant\",\n        65: \"bed\",\n        66: \"mirror\",\n        67: \"dining table\",\n        68: \"window\",\n        69: \"desk\",\n        70: \"toilet\",\n        71: \"door\",\n        72: \"tv\",\n        73: \"laptop\",\n        74: \"mouse\",\n        75: \"remote\",\n        76: \"keyboard\",\n        77: \"cell phone\",\n        78: \"microwave\",\n        79: \"oven\",\n        80: \"toaster\",\n        81: \"sink\",\n        82: \"refrigerator\",\n        83: \"blender\",\n        84: \"book\",\n        85: \"clock\",\n        86: \"vase\",\n        87: \"scissors\",\n        88: \"teddy bear\",\n        89: \"hair drier\",\n        90: \"toothbrush\",\n        91: \"hair brush\",\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"code/utils/labels/#pixano.utils.labels.dota_ids","title":"<code>dota_ids(name)</code>","text":"<p>Return DOTAv2 category ID (18 classes)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>int</code> <p>Category name</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category ID</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def dota_ids(name: str) -&gt; int:\n    \"\"\"Return DOTAv2 category ID (18 classes)\n\n    Args:\n        name (int): Category name\n\n    Returns:\n        str: Category ID\n    \"\"\"\n\n    dota_dict = {\n        \"plane\": 1,\n        \"ship\": 2,\n        \"storage tank\": 3,\n        \"baseball diamond\": 4,\n        \"tennis court\": 5,\n        \"basketball court\": 6,\n        \"ground track field\": 7,\n        \"harbor\": 8,\n        \"bridge\": 9,\n        \"large vehicle\": 10,\n        \"small vehicle\": 11,\n        \"helicopter\": 12,\n        \"roundabout\": 13,\n        \"soccer ball field\": 14,\n        \"swimming pool\": 15,\n        \"container crane\": 16,\n        \"airport\": 17,\n        \"helipad\": 18,\n    }\n\n    return dota_dict[str(name).replace(\"-\", \" \")]\n</code></pre>"},{"location":"code/utils/labels/#pixano.utils.labels.voc_names","title":"<code>voc_names(cat_id)</code>","text":"<p>Return VOC category name (20 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def voc_names(cat_id: int) -&gt; str:\n    \"\"\"Return VOC category name (20 classes)\n\n    Args:\n        cat_id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    voc_dict = {\n        1: \"aeroplane\",\n        2: \"bicycle\",\n        3: \"bird\",\n        4: \"boat\",\n        5: \"bottle\",\n        6: \"bus\",\n        7: \"car\",\n        8: \"cat\",\n        9: \"chair\",\n        10: \"cow\",\n        11: \"dining table\",\n        12: \"dog\",\n        13: \"horse\",\n        14: \"motorbike\",\n        15: \"person\",\n        16: \"potted plant\",\n        17: \"sheep\",\n        18: \"sofa\",\n        19: \"train\",\n        20: \"tv / monitor\",\n    }\n\n    return voc_dict[int(cat_id)]\n</code></pre>"},{"location":"code/utils/python/","title":"python","text":""},{"location":"code/utils/python/#pixano.utils.python","title":"<code>pixano.utils.python</code>","text":""},{"location":"code/utils/python/#pixano.utils.python.estimate_size","title":"<code>estimate_size(folder_path)</code>","text":"<p>Estimate folder size and return it as a human-readable string</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Path</code> <p>Folder path</p> required <p>Returns:</p> Type Description <code>str</code> <p>Folder size as a human-readable string</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def estimate_size(folder_path: Path) -&gt; str:\n    \"\"\"Estimate folder size and return it as a human-readable string\n\n    Args:\n        folder_path (Path): Folder path\n\n    Returns:\n        str: Folder size as a human-readable string\n    \"\"\"\n\n    # Estimate size\n    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(folder_path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            # skip if it is symbolic link\n            if not os.path.islink(fp):\n                total_size += os.path.getsize(fp)\n\n    # Format size\n    i = 0\n    suffixes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    while total_size &gt;= 1024 and i &lt; len(suffixes) - 1:\n        total_size /= 1024.0\n        i += 1\n    f = (\"%.2f\" % total_size).rstrip(\"0\").rstrip(\".\")\n    readable_size = \"%s %s\" % (f, suffixes[i])\n\n    return readable_size\n</code></pre>"},{"location":"code/utils/python/#pixano.utils.python.natural_key","title":"<code>natural_key(string)</code>","text":"<p>Return key for string natural sort</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>Input string</p> required <p>Returns:</p> Type Description <code>list</code> <p>Sort key</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def natural_key(string: str) -&gt; list:\n    \"\"\"Return key for string natural sort\n\n    Args:\n        string (str): Input string\n\n    Returns:\n        list: Sort key\n    \"\"\"\n\n    return [int(s) if s.isdecimal() else s for s in re.split(r\"(\\d+)\", string)]\n</code></pre>"},{"location":"user/","title":"Getting started with Pixano","text":"<ul> <li>Install Pixano</li> <li>Use your existing datasets</li> <li>Check out this Jupyter notebook for importing your datasets to Pixano</li> <li>Check out this Jupyter notebook for exporting your annotated datasets from Pixano</li> <li>Use the Pixano apps</li> <li>Learn how to launch an app</li> <li>Read our user guide for Pixano Explorer</li> <li>Read our user guide for Pixano Annotator</li> </ul>"},{"location":"user/annotator/","title":"Using Pixano Annotator","text":""},{"location":"user/annotator/#home-page","title":"Home page","text":"<p>From the Annotator home page, you will be greeted with a list of all the Pixano format datasets found in the directory you provided.</p> <p>For each dataset, you can see its name, the number of elements inside it, and a thumbnail composed from six sample elements.</p> <p>You can hover over a dataset name to check the dataset description if it has one.</p> <p>You can click on a dataset to open its annotation page on its first element.</p>"},{"location":"user/annotator/#annotation-page","title":"Annotation page","text":""},{"location":"user/annotator/#element-view","title":"Element view","text":"<p>The selected element (image or images for multi-view datasets) is displayed.</p> <p>You can zoom in and out with the mouse wheel.</p> <p>You can grab and move images with the middle click or with the Pan tool available in the left-hand toolbar.</p> <p>You can double click on an image to move it above other images.</p> <p>Annotations, in form of segmentation mask, are displayed. Each object category is given a color.</p> <p>On the top of the image, when you have an input Tool selected, a panel is displayed that allows to choose a category.</p>"},{"location":"user/annotator/#left-toolbar","title":"Left toolbar","text":"<p>A toolbar is available on the left-hand side of the page with the following tools:</p> <ul> <li>Pan: Allows you to grab and move an image</li> <li>Points: Allows you to place input points to interactively segment your image</li> <li>You can place positive points with the + tool (points shown in green) to indicate what must be included in the segmentation</li> <li>You can place negative points with - tool (points shown in red) to indicate what must not be included in the segmentation</li> <li>You can hover over any point and press the Del key to remove it</li> <li>You can click and hold on any point to relocate it</li> <li>Rectangle: Allows you to draw rectangles approximatively around the objects of interest to interactively segment them</li> <li>You can click and drag on the image to draw a rectangle</li> <li>There can only be one rectangle at a time, so drawing a new rectangle will discard the previous one. You have to validate the obtained segmentation, if satisfactory, before drawing a new rectangle</li> </ul> <p>The Points and Rectangle tools depend on an ONNX segmentation model you have to provide. Please look at the interactive annotation documentation and notebook for more information.</p> <p>More tools will be coming soon.</p>"},{"location":"user/annotator/#center-toolbar","title":"Center toolbar","text":"<p>When an annotation tool is selected, a toolbar is available at the center on the page.</p> <p>Enter the label name for your annotation in the text box or select the label from the list of existing labels.</p> <p>If the Points tool is selected, a + icon and a - icon allow to quickly switch between positive and negative points</p> <p>Validate your annotation with the entered label by cliking on the Validate icon, or press Enter key.</p>"},{"location":"user/annotator/#right-toolbar","title":"Right toolbar","text":"<p>A toolbar is available on the right side of the page with the following tabs:</p> <ul> <li>Labels: This tab displays your annotations grouped by views and by labels</li> <li>Each annotation group can be opened or closed by clicking on it</li> <li>Each annotation and annotation group can be shown or hidden on the relevant image by clicking on the Visibility icon</li> <li>Each annotation can be deleted by clicking on the Delete icon</li> <li>Each annotation is represented by its unique ID.</li> <li>Dataset: This tab allows you to navigate through the dataset</li> <li>Each element of the dataset is displayed with its ID and its thumbnail</li> <li>The list will automatically expand as you scroll down</li> <li>You can click on any element to change the current element</li> </ul>"},{"location":"user/annotator/#annotating","title":"Annotating","text":"<p>You can currently annotate with the Points (+ and -), and Rectangle tools available in the left toolbar as described above.</p> <p>When using these tools, the generated annotation will be displayed in green. You can use both tools together to refine your annotation.</p> <p>You can press the Enter key or click the Validate icon of the center toolbar to validate your annotation. You can press the Esc key to reset all your Points and Rectangle inputs.</p>"},{"location":"user/annotator/#saving","title":"Saving","text":"<p>To save your annotations, a Save icon is available in the top right-hand corner. It will be highlighted if there are unsaved changes.</p> <p>If you try to go back to the home page or change element with unsaved changes, you will see a confirmation window. You can choose \"OK\" to discard your changes, or cancel to be able to go back save them.</p>"},{"location":"user/annotator/#going-home","title":"Going home","text":"<p>To go back to the home page, click on \"Pixano Annotator\" in the top left-and corner or on the Close icon in the top right-hand corner.</p>"},{"location":"user/explorer/","title":"Using Pixano Explorer","text":""},{"location":"user/explorer/#home-page","title":"Home page","text":"<p>From the Explorer home page, you will be greeted with a list of all the datasets in Pixano format found in the directory you provided.</p> <p>For each dataset, you can see its name, the number of elements inside it, and a thumbnail composed from six sample elements.</p> <p>You can hover over a dataset name to check the dataset description if it has one.</p> <p>You can click on a dataset to open its exploration page.</p>"},{"location":"user/explorer/#exploration-page","title":"Exploration page","text":""},{"location":"user/explorer/#statistics","title":"Statistics","text":"<p>Available statistics will be displayed on the left side of the dataset page.</p> <p>You can hover over different elements in the statistics to get more detailed information.</p> <p>Filtering your dataset based on the selected statistics will soon be available.</p>"},{"location":"user/explorer/#elements-list","title":"Elements list","text":"<p>The dataset elements will be displayed on the right side of the dataset page.</p> <p>Elements are displayed in scrollable pages of up to 100 elements.</p> <p>You can navigate between pages with the Previous and Next buttons at the bottom.</p> <p>You can click on any element to open it in the exploration page.</p> <p>For each element, you can see columns for its ID, a thumbnail for each of its media, and the dataset split it comes from.</p> <p>Filtering your dataset based on these columns will soon be available.</p>"},{"location":"user/explorer/#going-home","title":"Going home","text":"<p>To go back to the home page, click on \"Pixano Explorer\" in the top left-hand corner or on the Close icon in the top right-hand corner.</p>"},{"location":"user/explorer/#element-view-page","title":"Element view page","text":""},{"location":"user/explorer/#element-view","title":"Element view","text":"<p>The selected element (image or images for multi-view datasets) is displayed.</p> <p>You can zoom in and out with the mouse wheel.</p> <p>You can grab and move images on the canvas.</p> <p>You can double click on an image to move it above other images with a multi-view dataset.</p> <p>Annotations, in form of segmentation masks and bounding boxes, are displayed. Each object category is given a color.</p> <p>On each bounding box, the object category is displayed in the top left-hand corner, together with the confidence score if the bounding box was obtained by the inference of a given model.</p>"},{"location":"user/explorer/#right-toolbar","title":"Right toolbar","text":"<p>A toolbar is available on the right side of the page with the following sections:</p> <ul> <li> <p>A Data section to display information on the element, like its ID</p> </li> <li> <p>A Tools section to filter the annotations</p> </li> <li>The Show all annotations checkbox allows you to toggle annotations visibility</li> <li>The Show bounding boxes checkbox allows you to toggle bounding box visibility</li> <li>The Mask opacity slider allows you to adjust the opacity of segmentation masks</li> <li>The Confidence threshold slider allows you to adjust the threshold to filter the inferred boxes to display</li> <li>The Labels list allows you to see the number of annotations for any label, and to toggle annotations visibility for individual labels by clicking on their names</li> </ul> <p>More options to display ground truths and inference annotations separately and with different colors will be coming soon.</p> <p>More options for multi-view datasets will be coming soon.</p>"},{"location":"user/explorer/#going-home_1","title":"Going home","text":"<p>To go back to the home page, click on \"Pixano Explorer\" in the top left-hand corner.</p> <p>To go back to the exploration page, click on the dataset name in the top left-hand corner or on the Close icon in the top right-hand corner, or press the Esc key.</p>"},{"location":"user/export/","title":"Exporting datasets","text":"<p>Please refer to this Jupyter notebook for information on how to export your datasets.</p>"},{"location":"user/import/","title":"Importing datasets","text":"<p>Please refer to this Jupyter notebook for information on how to import your datasets.</p>"},{"location":"user/install/","title":"Installing Pixano","text":"<p>As Pixano requires specific versions for its dependencies, we recommend creating a new Python virtual environment to install it.</p> <p>For example, with conda:</p> <pre><code>conda create -n pixano_env python=3.10\nconda activate pixano_env\n</code></pre> <p>Then, you can install the Pixano package inside that environment with pip:</p> <pre><code>pip install pixano\n</code></pre>"},{"location":"user/launch/","title":"Launching an app","text":""},{"location":"user/launch/#from-a-terminal","title":"From a terminal","text":"<p>You can start the Pixano Explorer and Annotator apps with the following commands:</p> <pre><code>pixano-explorer &lt;path/to/your/datasets&gt;\n</code></pre> <pre><code>pixano-annotator &lt;path/to/your/datasets&gt;\n</code></pre> <p>You will then be provided with a URL to open in your browser to use the app.</p>"},{"location":"user/launch/#from-a-notebook","title":"From a notebook","text":"<p>If you are in a Jupyter or Google Colab notebook, you can start the Explorer and Annotator apps by running the following cells:</p> <pre><code>from pixano.apps import Explorer\nexplorer = Explorer(&lt;path/to/your/datasets&gt;)\n</code></pre> <pre><code>from pixano.apps import Annotator\nannotator = Annotator(&lt;path/to/your/datasets&gt;)\n</code></pre> <p>You can then use the apps directly from the notebook in another cell with:</p> <pre><code>explorer.display()\n</code></pre> <pre><code>annotator.display()\n</code></pre>"}]}