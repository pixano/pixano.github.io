{
  "config": {
    "lang": ["en"],
    "separator": "[\\s\\-]+",
    "pipeline": ["stopWordFilter"]
  },
  "docs": [
    {
      "location": "",
      "title": "Welcome to the Pixano Documentation!",
      "text": "<p>Pixano is a library of data-centric AI building blocks for computer vision applications.</p> <p>Get started</p> <p>Check the API reference</p>"
    },
    {
      "location": "code/",
      "title": "Pixano API reference",
      "text": "<p>Here you will find the documentation for all of our Python API.</p> <ul> <li>The analytics module contains useful functions for computing statistics on a dataset.</li> <li>The apps module contains the Pixano Explorer and Annotator PixanoApps.</li> <li>The core module contains the Pixano Datasets and custom data types.</li> <li>The data module contains the Pixano DataLoaders for importing and exporting datasets.</li> <li>The models module contains the Pixano InferenceModel for inference generation and embedding precomputing.</li> <li>The transforms module contains many useful functions to work with images, bounding boxes, and labels.</li> </ul>"
    },
    {
      "location": "code/analytics/feature_statistics/",
      "title": "feature_statistics",
      "text": ""
    },
    {
      "location": "code/analytics/feature_statistics/#analytics.feature_statistics",
      "title": "<code>analytics.feature_statistics</code>",
      "text": ""
    },
    {
      "location": "code/analytics/feature_statistics/#analytics.feature_statistics.categorical_stats",
      "title": "<code>categorical_stats(df, split, field_name)</code>",
      "text": "<p>Compute feature categorical statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>field_name</code> <code>str</code> <p>Selected field</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def categorical_stats(df: pd.DataFrame, split: str, field_name: str) -&gt; list[dict]:\n\"\"\"Compute feature categorical statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        field_name (str): Selected field\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    counts = df.value_counts(subset=field_name)\n    return [{field_name: k, \"counts\": v, \"split\": split} for k, v in counts.items()]\n</code></pre>"
    },
    {
      "location": "code/analytics/feature_statistics/#analytics.feature_statistics.compute_additional_data",
      "title": "<code>compute_additional_data(data_table)</code>",
      "text": "<p>Convert Table to DataFrame and add resolution and aspect ratio</p> <p>Parameters:</p> Name Type Description Default <code>data_table</code> <code>pa.Table</code> <p>Input Table</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: DataFrame with added resolution and aspect ratio</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def compute_additional_data(data_table: pa.Table) -&gt; pd.DataFrame:\n\"\"\"Convert Table to DataFrame and add resolution and aspect ratio\n\n    Args:\n        data_table (pa.Table): Input Table\n\n    Returns:\n        pd.DataFrame: DataFrame with added resolution and aspect ratio\n    \"\"\"\n\n    # Take a subset of table without image columns (which can't be converted to pandas)\n    if not all(p in data_table.column_names for p in [\"width\", \"height\"]):\n        return None\n    data = data_table.select([\"width\", \"height\"]).to_pandas()\n\n    # Compute additional data\n    data[\"resolution\"] = data.apply(\n        lambda x: str(x[\"width\"]) + \"x\" + str(x[\"height\"]), axis=1\n    )\n    data[\"aspect_ratio\"] = data.apply(\n        lambda x: str(Fraction(x[\"width\"], x[\"height\"])).replace(\"/\", \":\"), axis=1\n    )\n\n    return data\n</code></pre>"
    },
    {
      "location": "code/analytics/feature_statistics/#analytics.feature_statistics.compute_stats",
      "title": "<code>compute_stats(df, split, feature)</code>",
      "text": "<p>Compute feature statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>feature</code> <code>dict</code> <p>Selected feature</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def compute_stats(df: pd.DataFrame, split: str, feature: dict) -&gt; list[dict]:\n\"\"\"Compute feature statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        feature (dict): Selected feature\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    # Categorical\n    if feature[\"type\"] == \"categorical\":\n        return categorical_stats(df, split, feature[\"name\"])\n    # Numerical\n    elif feature[\"type\"] == \"numerical\":\n        return numerical_stats(df, split, feature[\"name\"], feature.get(\"range\", None))\n    # Else\n    else:\n        return []\n</code></pre>"
    },
    {
      "location": "code/analytics/feature_statistics/#analytics.feature_statistics.numerical_stats",
      "title": "<code>numerical_stats(df, split, field_name, field_range=None)</code>",
      "text": "<p>Compute feature numerical statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>field_name</code> <code>str</code> <p>Selected field</p> required <code>field_range</code> <code>list[float]</code> <p>Selected field range. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def numerical_stats(\n    df: pd.DataFrame, split: str, field_name: str, field_range: list[float] = None\n) -&gt; list[dict]:\n\"\"\"Compute feature numerical statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        field_name (str): Selected field\n        field_range (list[float], optional): Selected field range. Defaults to None.\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    counts, bins = np.histogram(df[field_name], range=field_range)\n    return [\n        {\n            \"bin_start\": float(bins[i]),\n            \"bin_end\": float(bins[i + 1]),\n            \"counts\": int(counts[i]),\n            \"split\": split,\n        }\n        for i in range(len(counts))\n    ]\n</code></pre>"
    },
    {
      "location": "code/analytics/feature_statistics/#analytics.feature_statistics.objects_tableToDF",
      "title": "<code>objects_tableToDF(data_table, field)</code>",
      "text": "<p>Convert a field from the objects column to a DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>data_table</code> <code>pa.Table</code> <p>Table with an objects column</p> required <code>field</code> <code>str</code> <p>Selected field from the objects column</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: Selected field as DataFrame</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def objects_tableToDF(data_table: pa.Table, field: str) -&gt; pd.DataFrame:\n\"\"\"Convert a field from the objects column to a DataFrame\n\n    Args:\n        data_table (pa.Table): Table with an objects column\n        field (str): Selected field from the objects column\n\n    Returns:\n        pd.DataFrame: Selected field as DataFrame\n    \"\"\"\n\n    try:\n        df_objs = data_table.select([\"objects\"]).to_pandas()\n        sel = [{field: d[field]} for objs in df_objs[\"objects\"] for d in objs]\n        return pd.DataFrame.from_dict(sel)\n    except Exception:\n        print(\"ERROR: Unable to convert table Pandas DataFrame\")\n        return None\n</code></pre>"
    },
    { "location": "code/apps/annotator/", "title": "annotator", "text": "" },
    {
      "location": "code/apps/annotator/#apps.annotator.serve",
      "title": "<code>apps.annotator.serve</code>",
      "text": ""
    },
    {
      "location": "code/apps/annotator/#apps.annotator.serve.AnnotatorApp",
      "title": "<code>AnnotatorApp(library_dir, host='127.0.0.1', port=0)</code>",
      "text": "<p>         Bases: <code>PixanoApp</code></p> <p>Pixano Annotator App</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>uvicorn.Config</code> <p>App config</p> <code>server</code> <code>uvicorn.Server</code> <p>App server</p> <code>task_function</code> <code>typing.Callable</code> <p>Run task function for running environment</p> <code>display_function</code> <code>typing.Callable</code> <p>Display function for running environment</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Dataset library directory</p> required <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 0.</p> <code>0</code> Source code in <code>pixano/apps/annotator/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    host: str = \"127.0.0.1\",\n    port: int = 0,\n) -&gt; None:\n\"\"\"Initialize and run Pixano Annotator app\n\n    Args:\n        library_dir (str): Dataset library directory\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 0.\n    \"\"\"\n\n    super().__init__(library_dir, ASSETS_PATH, TEMPLATE_PATH, host, port)\n</code></pre>"
    },
    {
      "location": "code/apps/annotator/#apps.annotator.serve.main",
      "title": "<code>main(library_dir, host, port)</code>",
      "text": "<p>Launch Pixano Annotator</p> <p>LIBRARY_DIR: Dataset library directory</p> Source code in <code>pixano/apps/annotator/serve.py</code> <pre><code>@click.command(context_settings={\"auto_envvar_prefix\": \"UVICORN\"})\n@click.argument(\n    \"library_dir\",\n    type=str,\n)\n@click.option(\n    \"--host\",\n    type=str,\n    default=\"127.0.0.1\",\n    help=\"Bind socket to this host.\",\n    show_default=True,\n)\n@click.option(\n    \"--port\",\n    type=int,\n    default=0,\n    help=\"Bind socket to this port.\",\n    show_default=True,\n)\ndef main(library_dir: str, host: str, port: int):\n\"\"\"Launch Pixano Annotator\n\n    LIBRARY_DIR: Dataset library directory\n    \"\"\"\n    AnnotatorApp(library_dir, host, port)\n</code></pre>"
    },
    { "location": "code/apps/explorer/", "title": "explorer", "text": "" },
    {
      "location": "code/apps/explorer/#apps.explorer.serve",
      "title": "<code>apps.explorer.serve</code>",
      "text": ""
    },
    {
      "location": "code/apps/explorer/#apps.explorer.serve.ExplorerApp",
      "title": "<code>ExplorerApp(library_dir, host='127.0.0.1', port=0)</code>",
      "text": "<p>         Bases: <code>PixanoApp</code></p> <p>Pixano Explorer App</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>uvicorn.Config</code> <p>App config</p> <code>server</code> <code>uvicorn.Server</code> <p>App server</p> <code>task_function</code> <code>typing.Callable</code> <p>Run task function for running environment</p> <code>display_function</code> <code>typing.Callable</code> <p>Display function for running environment</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Dataset library directory</p> required <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 0.</p> <code>0</code> Source code in <code>pixano/apps/explorer/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    host: str = \"127.0.0.1\",\n    port: int = 0,\n) -&gt; None:\n\"\"\"Initialize and run Pixano Explorer app\n\n    Args:\n        library_dir (str): Dataset library directory\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 0.\n    \"\"\"\n\n    super().__init__(library_dir, ASSETS_PATH, TEMPLATE_PATH, host, port)\n</code></pre>"
    },
    {
      "location": "code/apps/explorer/#apps.explorer.serve.main",
      "title": "<code>main(library_dir, host, port)</code>",
      "text": "<p>Launch Pixano Explorer</p> <p>LIBRARY_DIR: Dataset library directory</p> Source code in <code>pixano/apps/explorer/serve.py</code> <pre><code>@click.command(context_settings={\"auto_envvar_prefix\": \"UVICORN\"})\n@click.argument(\n    \"library_dir\",\n    type=str,\n)\n@click.option(\n    \"--host\",\n    type=str,\n    default=\"127.0.0.1\",\n    help=\"Bind socket to this host.\",\n    show_default=True,\n)\n@click.option(\n    \"--port\",\n    type=int,\n    default=0,\n    help=\"Bind socket to this port.\",\n    show_default=True,\n)\ndef main(library_dir: str, host: str, port: int):\n\"\"\"Launch Pixano Explorer\n\n    LIBRARY_DIR: Dataset library directory\n    \"\"\"\n    ExplorerApp(library_dir, host, port)\n</code></pre>"
    },
    { "location": "code/apps/core/db_utils/", "title": "db_utils", "text": "" },
    {
      "location": "code/apps/core/db_utils/#apps.core.db_utils",
      "title": "<code>apps.core.db_utils</code>",
      "text": ""
    },
    {
      "location": "code/apps/core/db_utils/#apps.core.db_utils.Feature",
      "title": "<code>Feature</code>",
      "text": "<p>         Bases: <code>BaseModel</code></p> <p>Feature</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Feature name</p> <code>dtype</code> <code>str</code> <p>Feature dtype</p> <code>value</code> <code>Any</code> <p>Feature value</p>"
    },
    {
      "location": "code/apps/core/db_utils/#apps.core.db_utils.get_item_details",
      "title": "<code>get_item_details(dataset, item_id, media_dir, inf_datasets=[])</code>",
      "text": "<p>Get item details</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ds.Dataset</code> <p>Dataset</p> required <code>item_id</code> <code>str</code> <p>Selected item ID</p> required <code>media_dir</code> <code>Path</code> <p>Dataset media directory</p> required <code>inf_datasets</code> <code>list[ds.Dataset]</code> <p>List of inference datasets. Defaults to [].</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>ImageDetails features for UI</p> Source code in <code>pixano/apps/core/db_utils.py</code> <pre><code>def get_item_details(\n    dataset: ds.Dataset,\n    item_id: str,\n    media_dir: Path,\n    inf_datasets: list[ds.Dataset] = [],\n) -&gt; dict:\n\"\"\"Get item details\n\n    Args:\n        dataset (ds.Dataset): Dataset\n        item_id (str): Selected item ID\n        media_dir (Path): Dataset media directory\n        inf_datasets (list[ds.Dataset], optional): List of inference datasets. Defaults to [].\n\n    Returns:\n        dict: ImageDetails features for UI\n    \"\"\"\n\n    # Get item\n    scanner = dataset.scanner(filter=ds.field(\"id\").isin([item_id]))\n    item = scanner.to_table().to_pylist()[0]\n\n    # Get item inference objects\n    for inf_ds in inf_datasets:\n        inf_scanner = inf_ds.scanner(filter=ds.field(\"id\").isin([item_id]))\n        inf_item = inf_scanner.to_table().to_pylist()[0]\n        if inf_item is not None:\n            item[\"objects\"].extend(inf_item[\"objects\"])\n\n    # Create features\n    features = {\n        \"id\": item[\"id\"],\n        \"filename\": None,\n        \"width\": None,\n        \"height\": None,\n        \"categoryStats\": [],\n        \"views\": {},\n    }\n\n    # Category statistics\n    cat_ids = [\n        obj[\"category_id\"] for obj in item[\"objects\"] if obj[\"category_id\"] is not None\n    ]\n    cat_names = [\n        obj[\"category_name\"]\n        for obj in item[\"objects\"]\n        if obj[\"category_id\"] is not None\n    ]\n    cat, index, count = np.unique(cat_ids, return_index=True, return_counts=True)\n    # Add to features\n    features[\"categoryStats\"] = [\n        {\n            \"id\": int(cat[i]),\n            \"name\": str(cat_names[index[i]]),\n            \"count\": int(count[i]),\n        }\n        for i in range(len(cat))\n        if cat[i] is not None\n    ]\n\n    # Views\n    for field in dataset.schema:\n        if arrow_types.is_image_type(field.type):\n            # Image\n            image = item[field.name]\n            image.uri_prefix = media_dir.absolute().as_uri()\n\n            # Objects IDs\n            ids = [obj[\"id\"] for obj in item[\"objects\"] if obj[\"view_id\"] == field.name]\n            # Categories\n            cats = [\n                {\"id\": obj[\"category_id\"], \"name\": obj[\"category_name\"]}\n                for obj in item[\"objects\"]\n                if obj[\"view_id\"] == field.name\n                and obj[\"category_id\"] is not None\n                and obj[\"category_name\"] is not None\n            ]\n            # Bounding boxes\n            boxes = [\n                transforms.format_bbox(\n                    obj[\"bbox\"],\n                    obj[\"bbox_confidence\"] is not None,\n                    obj[\"bbox_confidence\"],\n                )\n                for obj in item[\"objects\"]\n                if obj[\"view_id\"] == field.name and obj[\"bbox\"] is not None\n            ]\n            # Masks\n            masks = [\n                transforms.rle_to_urle(obj[\"mask\"])\n                for obj in item[\"objects\"]\n                if obj[\"view_id\"] == field.name and obj[\"mask\"] is not None\n            ]\n            # Add to features\n            features[\"views\"][field.name] = {\n                \"image\": image.url,\n                \"objects\": {\n                    \"id\": ids,\n                    \"category\": cats,\n                    \"boundingBox\": boxes,\n                    \"segmentation\": masks,\n                },\n            }\n\n    return features\n</code></pre>"
    },
    {
      "location": "code/apps/core/db_utils/#apps.core.db_utils.get_item_view_embedding",
      "title": "<code>get_item_view_embedding(emb_ds, item_id, view)</code>",
      "text": "<p>Get item embedding for a view</p> <p>Parameters:</p> Name Type Description Default <code>emb_ds</code> <code>ds.Dataset</code> <p>Embedding dataset</p> required <code>item_id</code> <code>str</code> <p>Item ID</p> required <code>view</code> <code>str</code> <p>Item embedding view</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Embedding in base 64</p> Source code in <code>pixano/apps/core/db_utils.py</code> <pre><code>def get_item_view_embedding(emb_ds: ds.Dataset, item_id: str, view: str) -&gt; bytes:\n\"\"\"Get item embedding for a view\n\n    Args:\n        emb_ds (ds.Dataset): Embedding dataset\n        item_id (str): Item ID\n        view (str): Item embedding view\n\n    Returns:\n        bytes: Embedding in base 64\n    \"\"\"\n\n    # Get item\n    emb_scanner = emb_ds.scanner(filter=ds.field(\"id\").isin([item_id]))\n    emb_item = emb_scanner.to_table().to_pylist()[0]\n    return emb_item[f\"{view}_embedding\"]\n</code></pre>"
    },
    {
      "location": "code/apps/core/db_utils/#apps.core.db_utils.get_items",
      "title": "<code>get_items(dataset, params=None)</code>",
      "text": "<p>Get items</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>pa.Dataset</code> <p>Dataset</p> required <code>params</code> <code>AbstractParams</code> <p>FastAPI params for pagination. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AbstractPage</code> <code>AbstractPage</code> <p>List of Features for UI (DatasetExplorer)</p> Source code in <code>pixano/apps/core/db_utils.py</code> <pre><code>def get_items(dataset: ds.Dataset, params: AbstractParams = None) -&gt; AbstractPage:\n\"\"\"Get items\n\n    Args:\n        dataset (pa.Dataset): Dataset\n        params (AbstractParams, optional): FastAPI params for pagination. Defaults to None.\n\n    Returns:\n        AbstractPage: List of Features for UI (DatasetExplorer)\n    \"\"\"\n\n    # Get page parameters\n    params = resolve_params(params)\n    raw_params = params.to_raw_params()\n    total = dataset.count_rows()\n\n    # Get page items\n    start = raw_params.offset\n    stop = min(raw_params.offset + raw_params.limit, total)\n    if start &gt;= stop:\n        return None\n    items_table = dataset.take(range(start, stop))\n\n    def _create_features(row: list) -&gt; list[Feature]:\n\"\"\"Create features based on field types\n\n        Args:\n            row (list): Input row\n\n        Returns:\n            list[Feature]: Row as list of features\n        \"\"\"\n\n        features = []\n\n        # Iterate on fields\n        for field in dataset.schema:\n            # Number fields\n            if arrow_types.is_number(field.type):\n                features.append(\n                    Feature(name=field.name, dtype=\"number\", value=row[field.name])\n                )\n            # Image fields\n            elif arrow_types.is_image_type(field.type):\n                thumbnail = row[field.name].preview_url\n                features.append(\n                    Feature(name=field.name, dtype=\"image\", value=thumbnail)\n                )\n            # String fields\n            elif pa.types.is_string(field.type):\n                features.append(\n                    Feature(name=field.name, dtype=\"text\", value=row[field.name])\n                )\n\n        return features\n\n    # Create items features\n    items = [_create_features(e) for e in items_table.to_pylist()]\n\n    return create_page(items, total=total, params=params)\n</code></pre>"
    },
    {
      "location": "code/apps/core/db_utils/#apps.core.db_utils.update_annotations",
      "title": "<code>update_annotations(dataset_dir, item_id, annotations)</code>",
      "text": "<p>Update dataset annotations</p> <p>Parameters:</p> Name Type Description Default <code>dataset_dir</code> <code>Path</code> <p>Dataset directory</p> required <code>item_id</code> <code>str</code> <p>Item ID</p> required <code>annotations</code> <code>list[arrow_types.ObjectAnnotation]</code> <p>Item annotations</p> required Source code in <code>pixano/apps/core/db_utils.py</code> <pre><code>def update_annotations(\n    dataset_dir: Path,\n    item_id: str,\n    annotations: list[arrow_types.ObjectAnnotation],\n):\n\"\"\"Update dataset annotations\n\n    Args:\n        dataset_dir (Path): Dataset directory\n        item_id (str): Item ID\n        annotations (list[arrow_types.ObjectAnnotation]): Item annotations\n    \"\"\"\n\n    # Convert URLE to RLE and add bounding box\n    # TODO: Find a fix for image datasets\n    item_anns = [o.dict() for o in annotations]\n    for ann in item_anns:\n        ann[\"bbox\"] = urle_to_bbox(ann[\"mask\"])\n        ann[\"bbox_source\"] = ann[\"mask_source\"]\n        ann[\"mask\"] = urle_to_rle(ann[\"mask\"])\n\n    # Dataset files\n    files = (dataset_dir / \"db\").glob(\"**/*.parquet\")\n    files = sorted(files, key=lambda x: natural_key(x.name))\n\n    # Iterate on dataset files\n    for file in files:\n        # Look for updated item\n        table = pq.read_table(file)\n        filter = table.filter(pc.field(\"id\").isin([item_id]))\n        item = filter.to_pylist()\n\n        # If item found\n        if item != []:\n            # Read table without item\n            updated_table = table.filter(~pc.field(\"id\").isin([item_id])).to_pydict()\n\n            # Add item with updated annotations\n            item[0][\"objects\"] = item_anns\n            for field in table.schema:\n                updated_table[field.name].append(item[0][field.name])\n\n            # Sort table fields according to IDs\n            for field in table.schema:\n                if field.name != \"id\":\n                    updated_table[field.name] = [\n                        x\n                        for _, x in sorted(\n                            zip(updated_table[\"id\"], updated_table[field.name]),\n                            key=lambda pair: natural_key(pair[0]),\n                        )\n                    ]\n            # Sort table IDs\n            updated_table[\"id\"] = sorted(updated_table[\"id\"], key=natural_key)\n\n            # Convert ExtensionTypes\n            arrays = []\n            for field in table.schema:\n                # Convert image types to dict before PyArrow conversion\n                # TODO: find a better way\n                if arrow_types.is_image_type(field.type):\n                    updated_table[field.name] = [\n                        i.to_dict() for i in updated_table[field.name]\n                    ]\n                arrays.append(\n                    arrow_types.convert_field(\n                        field_name=field.name,\n                        field_type=field.type,\n                        field_data=updated_table[field.name],\n                    )\n                )\n\n            # Save updated table\n            pq.write_table(\n                pa.Table.from_arrays(arrays, schema=table.schema),\n                file,\n            )\n            return\n</code></pre>"
    },
    { "location": "code/apps/core/main/", "title": "main", "text": "" },
    {
      "location": "code/apps/core/main/#apps.core.main",
      "title": "<code>apps.core.main</code>",
      "text": ""
    },
    {
      "location": "code/apps/core/main/#apps.core.main.Settings",
      "title": "<code>Settings</code>",
      "text": "<p>         Bases: <code>BaseSettings</code></p> <p>Dataset library settings</p> <p>Attributes:</p> Name Type Description <code>data_dir</code> <code>Path</code> <p>Dataset library directory</p>"
    },
    {
      "location": "code/apps/core/main/#apps.core.main.create_app",
      "title": "<code>create_app(settings)</code>",
      "text": "<p>Run Pixano app</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>Dataset Library</p> required <p>Raises:</p> Type Description <code>HTTPException</code> <p>404, Dataset is not found</p> <code>HTTPException</code> <p>404, Dataset stats are not found</p> <code>HTTPException</code> <p>404, Dataset is not found</p> <code>HTTPException</code> <p>404, Dataset is not found</p> <code>HTTPException</code> <p>404, Embedding dataset is not found</p> <p>Returns:</p> Name Type Description <code>FastAPI</code> <code>FastAPI</code> <p>Explorer app</p> Source code in <code>pixano/apps/core/main.py</code> <pre><code>def create_app(settings: Settings) -&gt; FastAPI:\n\"\"\"Run Pixano app\n\n    Args:\n        settings (Settings): Dataset Library\n\n    Raises:\n        HTTPException: 404, Dataset is not found\n        HTTPException: 404, Dataset stats are not found\n        HTTPException: 404, Dataset is not found\n        HTTPException: 404, Dataset is not found\n        HTTPException: 404, Embedding dataset is not found\n\n    Returns:\n        FastAPI: Explorer app\n    \"\"\"\n    app = FastAPI()\n\n    app.add_middleware(\n        CORSMiddleware,\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Check if library exists\n    if not settings.data_dir.exists():\n        raise FileNotFoundError(\n            f\"Dataset library '{settings.data_dir.absolute()}' not found\"\n        )\n\n    # Create models folder\n    model_dir = settings.data_dir / \"models\"\n    model_dir.mkdir(exist_ok=True)\n    app.mount(\"/models\", StaticFiles(directory=model_dir), name=\"models\")\n\n    @app.get(\"/datasets\", response_model=list[DatasetInfo])\n    async def get_datasets_list():\n        return load_library(settings)\n\n    @app.get(\"/datasets/{ds_id}/items\", response_model=Page[db_utils.Features])\n    async def get_dataset_items(ds_id, params: Params = Depends()):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n        # Return dataset items\n        res = db_utils.get_items(ds.load(), params)\n        if res is None:\n            raise HTTPException(status_code=404, detail=\"Data not found\")\n        else:\n            return res\n\n    @app.get(\"/datasets/{ds_id}/stats\")\n    async def get_dataset_stats(ds_id):\n        # Load dataset stats\n        stats = load_dataset_stats(ds_id, settings)\n        if stats is None:\n            raise HTTPException(status_code=404, detail=\"Stats not found\")\n        # Return dataset stats\n        return stats\n\n    @app.get(\"/datasets/{ds_id}/items/{item_id}\")\n    async def get_dataset_item_details(ds_id: str, item_id: str):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n\n        # Load inference datasets\n        inf_datasets = []\n        for inf_json in sorted(list(ds.path.glob(\"db_infer_*/infer.json\"))):\n            inf_datasets.append(InferenceDataset(inf_json.parent).load())\n\n        # Return item details\n        return db_utils.get_item_details(ds.load(), item_id, ds.media_dir, inf_datasets)\n\n    @app.post(\"/datasets/{ds_id}/items/{item_id}/{view}/embedding\")\n    async def get_dataset_item_view_embedding(ds_id: str, item_id: str, view: str):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n\n        # Load embedding dataset (currently selecting latest one)\n        emb_ds = None\n        for emb_json in sorted(list(ds.path.glob(\"db_embed_*/embed.json\"))):\n            emb_ds = EmbeddingDataset(emb_json.parent).load()\n        if emb_ds is None:\n            raise HTTPException(status_code=404, detail=\"Embedding dataset not found\")\n\n        # Return item embedding\n        return Response(content=db_utils.get_item_view_embedding(emb_ds, item_id, view))\n\n    @app.post(\n        \"/datasets/{ds_id}/items/{item_id}/annotations\",\n        response_model=list[arrow_types.ObjectAnnotation],\n    )\n    async def post_dataset_item_annotations(\n        ds_id: str,\n        item_id: str,\n        annotations: list[arrow_types.ObjectAnnotation],\n    ):\n        # Load dataset\n        ds = load_dataset(ds_id, settings)\n        if ds is None:\n            raise HTTPException(status_code=404, detail=\"Dataset not found\")\n\n        # Update dataset annotations\n        db_utils.update_annotations(ds.path, item_id, annotations)\n\n        return Response()\n\n    add_pagination(app)\n\n    return app\n</code></pre>"
    },
    {
      "location": "code/apps/core/main/#apps.core.main.load_dataset",
      "title": "<code>load_dataset(ds_id, settings)</code>",
      "text": "<p>Load dataset based on its ID</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>settings</code> <code>Settings</code> <p>Dataset library</p> required <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset</p> Source code in <code>pixano/apps/core/main.py</code> <pre><code>def load_dataset(ds_id: str, settings: Settings) -&gt; Dataset:\n\"\"\"Load dataset based on its ID\n\n    Args:\n        ds_id (str): Dataset ID\n        settings (Settings): Dataset library\n\n    Returns:\n        Dataset: Dataset\n    \"\"\"\n\n    for spec in settings.data_dir.glob(\"*/spec.json\"):\n        info = DatasetInfo.parse_file(spec)\n        if ds_id == info.id:\n            return Dataset(spec.parent)\n</code></pre>"
    },
    {
      "location": "code/apps/core/main/#apps.core.main.load_dataset_stats",
      "title": "<code>load_dataset_stats(ds_id, settings)</code>",
      "text": "<p>Load dataset stats based on its ID</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>settings</code> <code>Settings</code> <p>Dataset Library</p> required <p>Returns:</p> Type Description <code>dict</code> <p>list[dict]: Dataset stats</p> Source code in <code>pixano/apps/core/main.py</code> <pre><code>def load_dataset_stats(ds_id: str, settings: Settings) -&gt; dict:\n\"\"\"Load dataset stats based on its ID\n\n    Args:\n        ds_id (str): Dataset ID\n        settings (Settings): Dataset Library\n\n    Returns:\n        list[dict]: Dataset stats\n    \"\"\"\n\n    ds = load_dataset(ds_id, settings)\n    if ds is not None:\n        stats_file = ds.path / \"db_feature_statistics.json\"\n        if stats_file.is_file():\n            with open(stats_file, \"r\") as f:\n                return json.load(f)\n</code></pre>"
    },
    {
      "location": "code/apps/core/main/#apps.core.main.load_library",
      "title": "<code>load_library(settings)</code>",
      "text": "<p>Load all dataset info files in library</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>Dataset library settings</p> required <p>Returns:</p> Type Description <code>list[DatasetInfo]</code> <p>list[DatasetInfo]: Dataset info files</p> Source code in <code>pixano/apps/core/main.py</code> <pre><code>def load_library(settings: Settings) -&gt; list[DatasetInfo]:\n\"\"\"Load all dataset info files in library\n\n    Args:\n        settings (Settings): Dataset library settings\n\n    Returns:\n        list[DatasetInfo]: Dataset info files\n    \"\"\"\n\n    infos = []\n    for spec in sorted(settings.data_dir.glob(\"*/spec.json\")):\n        # Load dataset info\n        info = DatasetInfo.parse_file(spec)\n        # Load thumbnail\n        preview_path = spec.parent / \"preview.png\"\n        if preview_path.is_file():\n            im = arrow_types.Image(uri=preview_path.absolute().as_uri())\n            info.preview = im.url\n\n        # Load categories\n        info.categories = getattr(info, \"categories\", [])\n        if info.categories is None:\n            info.categories = []\n        # Save dataset info\n        infos.append(info)\n    return infos\n</code></pre>"
    },
    { "location": "code/apps/core/serve/", "title": "serve", "text": "" },
    {
      "location": "code/apps/core/serve/#apps.core.serve",
      "title": "<code>apps.core.serve</code>",
      "text": ""
    },
    {
      "location": "code/apps/core/serve/#apps.core.serve.PixanoApp",
      "title": "<code>PixanoApp(library_dir, assets_path, template_path, host='127.0.0.1', port=8000)</code>",
      "text": "<p>Pixano App</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>uvicorn.Config</code> <p>App config</p> <code>server</code> <code>uvicorn.Server</code> <p>App server</p> <code>task_function</code> <code>typing.Callable</code> <p>Run task function for running environment</p> <code>display_function</code> <code>typing.Callable</code> <p>Display function for running environment</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Dataset library directory</p> required <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 8000.</p> <code>8000</code> Source code in <code>pixano/apps/core/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    assets_path: str,\n    template_path: str,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n):\n\"\"\"Initialize and run Pixano app\n\n    Args:\n        library_dir (str): Dataset library directory\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 8000.\n    \"\"\"\n\n    # Create app\n    templates = Jinja2Templates(directory=template_path)\n    settings = Settings(data_dir=Path(library_dir))\n    app = create_app(settings)\n\n    @app.get(\"/\", response_class=HTMLResponse)\n    def main(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    app.mount(\"/assets\", StaticFiles(directory=assets_path), name=\"assets\")\n    self.config = uvicorn.Config(app, host=host, port=port)\n    self.server = uvicorn.Server(self.config)\n\n    # Get environmennt\n    self.task_function = {\n        \"colab\": asyncio.get_event_loop().create_task,\n        \"ipython\": asyncio.get_event_loop().create_task,\n        \"none\": asyncio.run,\n    }[get_env()]\n    self.display_function = {\n        \"colab\": display_colab,\n        \"ipython\": display_ipython,\n        \"none\": display_cli,\n    }[get_env()]\n\n    # Serve app\n    self.task_function(self.server.serve())\n</code></pre>"
    },
    {
      "location": "code/apps/core/serve/#apps.core.serve.PixanoApp.display",
      "title": "<code>display(height=1000)</code>",
      "text": "<p>Display Pixano app</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Frame height. Defaults to 1000.</p> <code>1000</code> Source code in <code>pixano/apps/core/serve.py</code> <pre><code>def display(self, height: int = 1000) -&gt; None:\n\"\"\"Display Pixano app\n\n    Args:\n        height (int, optional): Frame height. Defaults to 1000.\n    \"\"\"\n\n    # Wait for app to be online\n    while not self.server.started:\n        self.task_function(asyncio.wait(0.1))\n\n    # Display app\n    for server in self.server.servers:\n        for socket in server.sockets:\n            address = socket.getsockname()\n            self.display_function(\n                url=f\"http://{address[0]}\", port=address[1], height=height\n            )\n</code></pre>"
    },
    {
      "location": "code/apps/core/serve/#apps.core.serve.display_cli",
      "title": "<code>display_cli(url, port, height)</code>",
      "text": "<p>Display a Pixano app inside a command line interface</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/apps/core/serve.py</code> <pre><code>def display_cli(url: str, port: int, height: int):\n\"\"\"Display a Pixano app inside a command line interface\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    print(f\"Please visit {url}:{port} in a web browser.\")\n</code></pre>"
    },
    {
      "location": "code/apps/core/serve/#apps.core.serve.display_colab",
      "title": "<code>display_colab(url, port, height)</code>",
      "text": "<p>Display a Pixano app inside a Google Colab</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/apps/core/serve.py</code> <pre><code>def display_colab(url: str, port: int, height: int):\n\"\"\"Display a Pixano app inside a Google Colab\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    # Define frame template\n    shell = \"\"\"\n        (() =&gt; {\n            const url = new URL(%URL%);\n            const port = %PORT%;\n            if (port) {\n                url.port = port;\n            }\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '%HEIGHT%');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    \"\"\"\n\n    # Replace variables in template\n    replacements = [\n        (\"%HEIGHT%\", \"%d\" % height),\n        (\"%PORT%\", \"%d\" % port),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    script = IPython.display.Javascript(shell)\n    IPython.display.display(script)\n</code></pre>"
    },
    {
      "location": "code/apps/core/serve/#apps.core.serve.display_ipython",
      "title": "<code>display_ipython(url, port, height)</code>",
      "text": "<p>Display a Pixano app inside a Jupyter notebook</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/apps/core/serve.py</code> <pre><code>def display_ipython(url: str, port: int, height: int):\n\"\"\"Display a Pixano app inside a Jupyter notebook\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    # Define frame template\n    shell = \"\"\"\n        &lt;iframe id=\"%HTML_ID%\" width=\"100%\" height=\"%HEIGHT%\" frameborder=\"0\"&gt;\n        &lt;/iframe&gt;\n        &lt;script&gt;\n            (function() {\n                const frame = document.getElementById(%JSON_ID%);\n                const url = new URL(%URL%, window.location);\n                const port = %PORT%;\n                if (port) {\n                    url.port = port;\n                }\n                frame.src = url;\n            })();\n        &lt;/script&gt;\n    \"\"\"\n\n    # Replace variables in template\n    frame_id = f\"frame-{shortuuid.uuid()}\"\n    replacements = [\n        (\"%HTML_ID%\", html.escape(frame_id, quote=True)),\n        (\"%JSON_ID%\", json.dumps(frame_id)),\n        (\"%HEIGHT%\", \"%d\" % height),\n        (\"%PORT%\", \"%d\" % port),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    iframe = IPython.display.HTML(shell)\n    IPython.display.display(iframe)\n</code></pre>"
    },
    {
      "location": "code/apps/core/serve/#apps.core.serve.get_env",
      "title": "<code>get_env()</code>",
      "text": "<p>Get current running environment</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Running environment</p> Source code in <code>pixano/apps/core/serve.py</code> <pre><code>def get_env() -&gt; str:\n\"\"\"Get current running environment\n\n    Returns:\n        str: Running environment\n    \"\"\"\n\n    # If Google colab import succeeds\n    try:\n        import google.colab\n        import IPython\n    except ImportError:\n        pass\n    else:\n        if IPython.get_ipython() is not None:\n            return \"colab\"\n\n    # If IPython import succeeds\n    try:\n        import IPython\n    except ImportError:\n        pass\n    else:\n        ipython = IPython.get_ipython()\n        if ipython is not None and ipython.has_trait(\"kernel\"):\n            return \"ipython\"\n\n    # Else\n    return \"none\"\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/",
      "title": "arrow_types",
      "text": ""
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types",
      "title": "<code>core.arrow_types</code>",
      "text": ""
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.BBoxType",
      "title": "<code>BBoxType()</code>",
      "text": "<p>         Bases: <code>pa.ExtensionType</code></p> <p>Bounding box type as PyArrow list of PyArrow float32</p> Source code in <code>pixano/core/arrow_types/features.py</code> <pre><code>def __init__(self):\n    super(BBoxType, self).__init__(pa.list_(pa.float32(), list_size=4), \"bbox\")\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.CompressedRLEType",
      "title": "<code>CompressedRLEType()</code>",
      "text": "<p>         Bases: <code>pa.ExtensionType</code></p> <p>Segmentation mask type as PyArrow StructType</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def __init__(self):\n    super(CompressedRLEType, self).__init__(\n        pa.struct(\n            [\n                pa.field(\"size\", pa.list_(pa.int32())),\n                pa.field(\"counts\", pa.binary()),\n            ]\n        ),\n        \"mask[rle]\",\n    )\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.Embedding",
      "title": "<code>Embedding</code>",
      "text": "<p>         Bases: <code>BaseModel</code></p> <p>Embedding class</p> <p>Attributes:</p> Name Type Description <code>embedding</code> <code>bytes</code> <p>Embedding as binary</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.EmbeddingType",
      "title": "<code>EmbeddingType()</code>",
      "text": "<p>         Bases: <code>pa.ExtensionType</code></p> <p>Embedding type as PyArrow binary</p> Source code in <code>pixano/core/arrow_types/features.py</code> <pre><code>def __init__(self):\n    super(EmbeddingType, self).__init__(pa.binary(), \"embedding\")\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.Image",
      "title": "<code>Image(uri, bytes=None, preview_bytes=None, uri_prefix=None)</code>",
      "text": "<p>Image type using URI or bytes</p> <p>Attributes:</p> Name Type Description <code>_uri</code> <code>str</code> <p>Image URI</p> <code>_bytes</code> <code>bytes</code> <p>Image bytes</p> <code>_preview_bytes</code> <code>bytes</code> <p>Image preview bytes</p> <code>uri_prefix</code> <code>str</code> <p>URI prefix for relative URIs</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>str</code> <p>Image URI</p> <code>bytes</code> <code>bytes</code> <p>Image bytes. Defaults to None.</p> <code>preview_bytes</code> <code>bytes</code> <p>Image preview bytes. Defaults to None.</p> <code>uri_prefix</code> <code>str</code> <p>URI prefix for relative URIs. Defaults to None.</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def __init__(\n    self,\n    uri: str,\n    bytes: bytes = None,\n    preview_bytes: bytes = None,\n    uri_prefix: str = None,\n):\n\"\"\"Initialize image from URI or bytes\n\n    Attributes:\n        uri (str): Image URI\n        bytes (bytes, optional): Image bytes. Defaults to None.\n        preview_bytes (bytes, optional): Image preview bytes. Defaults to None.\n        uri_prefix (str, optional): URI prefix for relative URIs. Defaults to None.\n    \"\"\"\n\n    self._uri = uri\n    self._bytes = bytes\n    self._preview_bytes = preview_bytes\n    self.uri_prefix = uri_prefix\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.bytes",
      "title": "<code>bytes: bytes</code>  <code>property</code>",
      "text": "<p>Return image bytes</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Image bytes</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.preview_bytes",
      "title": "<code>preview_bytes: bytes</code>  <code>property</code>",
      "text": "<p>Return image preview bytes</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Image bytes</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.preview_url",
      "title": "<code>preview_url: str</code>  <code>property</code>",
      "text": "<p>Return image preview URL</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Image preview URL</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.size",
      "title": "<code>size: list[int]</code>  <code>property</code>",
      "text": "<p>Return image size</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: Image size</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.uri",
      "title": "<code>uri: str</code>  <code>property</code>",
      "text": "<p>Return image URI</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Image URI</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.url",
      "title": "<code>url: str</code>  <code>property</code>",
      "text": "<p>Return image URL</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Image URL</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.as_cv2",
      "title": "<code>as_cv2()</code>",
      "text": "<p>Open image as OpenCV</p> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Image as OpenCV</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def as_cv2(self) -&gt; np.ndarray:\n\"\"\"Open image as OpenCV\n\n    Returns:\n        np.ndarray: Image as OpenCV\n    \"\"\"\n\n    im_arr = np.frombuffer(self.open().read(), dtype=np.uint8)\n    return cv2.imdecode(im_arr, cv2.IMREAD_COLOR)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.as_pillow",
      "title": "<code>as_pillow()</code>",
      "text": "<p>Open image as Pillow</p> <p>Returns:</p> Type Description <code>PILImage.Image</code> <p>PIL.Image.Image: Image as Pillow</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def as_pillow(self) -&gt; PILImage.Image:\n\"\"\"Open image as Pillow\n\n    Returns:\n        PIL.Image.Image: Image as Pillow\n    \"\"\"\n\n    return PILImage.open(self.open()).convert(\"RGB\")\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.display",
      "title": "<code>display(preview=False)</code>",
      "text": "<p>Display image</p> <p>Parameters:</p> Name Type Description Default <code>preview</code> <code>bool</code> <p>True to display image preview instead of full image. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>IPyImage</code> <p>IPython.core.display.Image: Image as IPython Display</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def display(self, preview=False) -&gt; IPyImage:\n\"\"\"Display image\n\n    Args:\n        preview (bool, optional): True to display image preview instead of full image. Defaults to False.\n\n    Returns:\n        IPython.core.display.Image: Image as IPython Display\n    \"\"\"\n\n    im_bytes = self._preview_bytes if preview else self.bytes\n    return IPyImage(url=binary_to_url(im_bytes), format=IPyImage(im_bytes).format)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.open",
      "title": "<code>open()</code>",
      "text": "<p>Open image</p> <p>Returns:</p> Name Type Description <code>IO</code> <code>IO</code> <p>Opened image</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def open(self) -&gt; IO:\n\"\"\"Open image\n\n    Returns:\n        IO: Opened image\n    \"\"\"\n\n    return urlopen(self.uri)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.image.Image.to_dict",
      "title": "<code>to_dict()</code>",
      "text": "<p>Return image attributes as dict</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Image attributes</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def to_dict(self) -&gt; dict:\n\"\"\"Return image attributes as dict\n\n    Returns:\n        dict: Image attributes\n    \"\"\"\n\n    return {\n        \"uri\": self._uri,\n        \"bytes\": self._bytes,\n        \"preview_bytes\": self._preview_bytes,\n    }\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.ImageType",
      "title": "<code>ImageType()</code>",
      "text": "<p>         Bases: <code>pa.ExtensionType</code></p> <p>Externalized image type containing the URI string in UTF-8</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def __init__(self):\n    super(ImageType, self).__init__(\n        pa.struct(\n            [\n                pa.field(\"uri\", pa.utf8()),\n                pa.field(\"bytes\", pa.binary()),\n                pa.field(\"preview_bytes\", pa.binary()),\n            ]\n        ),\n        \"Image\",\n    )\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.ObjectAnnotation",
      "title": "<code>ObjectAnnotation</code>",
      "text": "<p>         Bases: <code>BaseModel</code></p> <p>ObjectAnnotation class to contain all annotation data</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Annotation unique ID</p> <code>view_id</code> <code>str</code> <p>View ID (e.g. 'image', 'cam_2')</p> <code>bbox</code> <code>list[float]</code> <p>Bounding box coordinates in xywh format (using top left point as reference)</p> <code>bbox_source</code> <code>str</code> <p>Bounding box source</p> <code>bbox_confidence</code> <code>float</code> <p>Bounding box confidence</p> <code>is_group_of</code> <code>bool</code> <p>is_group_of</p> <code>is_difficult</code> <code>bool</code> <p>is_difficult</p> <code>is_truncated</code> <code>bool</code> <p>is_truncated</p> <code>mask</code> <code>dict[str, bytes]</code> <p>Mask</p> <code>mask_source</code> <code>str</code> <p>Mask source</p> <code>area</code> <code>float</code> <p>area</p> <code>pose</code> <code>dict[str, list[float]]</code> <p>Pose</p> <code>category_id</code> <code>int</code> <p>Category ID</p> <code>category_name</code> <code>str</code> <p>Category name</p> <code>identity</code> <code>str</code> <p>Identity</p>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.ObjectAnnotationType",
      "title": "<code>ObjectAnnotationType()</code>",
      "text": "<p>ObjectAnnotation type as PyArrow StructType</p> <p>Returns:</p> Type Description <code>pa.StructType</code> <p>pa.StructType: ObjectAnnotation StructType</p> Source code in <code>pixano/core/arrow_types/features.py</code> <pre><code>def ObjectAnnotationType() -&gt; pa.StructType:\n\"\"\"ObjectAnnotation type as PyArrow StructType\n\n    Returns:\n        pa.StructType: ObjectAnnotation StructType\n    \"\"\"\n\n    pose_schema = pa.struct(\n        [\n            pa.field(\"cam_R_m2c\", pa.list_(pa.float64(), list_size=9)),\n            pa.field(\"cam_t_m2c\", pa.list_(pa.float64(), list_size=3)),\n        ]\n    )\n\n    return pa.struct(\n        [\n            # Object ID and View ID\n            pa.field(\"id\", pa.string()),\n            pa.field(\"view_id\", pa.string(), nullable=True),\n            # Bounding Box\n            pa.field(\"bbox\", BBoxType(), nullable=True),\n            pa.field(\"bbox_source\", pa.string(), nullable=True),\n            pa.field(\"bbox_confidence\", pa.float32(), nullable=True),\n            pa.field(\"is_group_of\", pa.bool_(), nullable=True),\n            pa.field(\"is_difficult\", pa.bool_(), nullable=True),\n            pa.field(\"is_truncated\", pa.bool_(), nullable=True),\n            # Mask\n            pa.field(\"mask\", CompressedRLEType(), nullable=True),\n            pa.field(\"mask_source\", pa.string(), nullable=True),\n            pa.field(\"area\", pa.float32(), nullable=True),\n            # 6D Poses\n            pa.field(\"pose\", pose_schema, nullable=True),\n            # Category\n            pa.field(\"category_id\", pa.int32(), nullable=True),\n            pa.field(\"category_name\", pa.string(), nullable=True),\n            pa.field(\"identity\", pa.string(), nullable=True),\n        ]\n    )\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.convert_field",
      "title": "<code>convert_field(field_name, field_type, field_data)</code>",
      "text": "<p>Convert PyArrow ExtensionTypes properly</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name</p> required <code>field_type</code> <code>pa.DataType</code> <p>Target PyArrow format</p> required <code>field_data</code> <code>list</code> <p>Data in Python format</p> required <p>Returns:</p> Type Description <code>pa.Array</code> <p>pa.Array: Data in target PyArrow format</p> Source code in <code>pixano/core/arrow_types/__init__.py</code> <pre><code>def convert_field(\n    field_name: str, field_type: pa.DataType, field_data: list\n) -&gt; pa.Array:\n\"\"\"Convert PyArrow ExtensionTypes properly\n\n    Args:\n        field_name (str): Name\n        field_type (pa.DataType): Target PyArrow format\n        field_data (list): Data in Python format\n\n    Returns:\n        pa.Array: Data in target PyArrow format\n    \"\"\"\n\n    # If target format is an ExtensionType\n    if isinstance(field_type, pa.ExtensionType):\n        storage = pa.array(field_data, type=field_type.storage_type)\n        return pa.ExtensionArray.from_storage(field_type, storage)\n\n    # If target format is an extension of ListType\n    elif pa.types.is_list(field_type):\n        native_arr = pa.array(field_data)\n        if isinstance(native_arr, pa.NullArray):\n            return pa.nulls(len(native_arr), field_type)\n        offsets = native_arr.offsets\n        values = native_arr.values.to_numpy(zero_copy_only=False)\n        return pa.ListArray.from_arrays(\n            offsets,\n            convert_field(f\"{field_name}.elements\", field_type.value_type, values),\n        )\n\n    # If target format is an extension of StructType\n    elif pa.types.is_struct(field_type):\n        native_arr = pa.array(field_data)\n        if isinstance(native_arr, pa.NullArray):\n            return pa.nulls(len(native_arr), field_type)\n        arrays = []\n        for subfield in field_type:\n            sub_arr = native_arr.field(subfield.name)\n            converted = convert_field(\n                f\"{field_name}.{subfield.name}\",\n                subfield.type,\n                sub_arr.to_numpy(zero_copy_only=False),\n            )\n            arrays.append(converted)\n        return pa.StructArray.from_arrays(arrays, fields=field_type)\n\n    # For other target formats\n    else:\n        return pa.array(field_data, type=field_type)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.is_embedding_type",
      "title": "<code>is_embedding_type(t)</code>",
      "text": "<p>Returns True if value is an instance of EmbeddingType</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>pa.DataType</code> <p>Value to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Type checking response</p> Source code in <code>pixano/core/arrow_types/features.py</code> <pre><code>def is_embedding_type(t: pa.DataType) -&gt; bool:\n\"\"\"Returns True if value is an instance of EmbeddingType\n\n    Args:\n        t (pa.DataType): Value to check\n\n    Returns:\n        bool: Type checking response\n    \"\"\"\n    return isinstance(t, EmbeddingType)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.is_image_type",
      "title": "<code>is_image_type(t)</code>",
      "text": "<p>Returns True if value is an instance of ImageType</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>pa.DataType</code> <p>Value to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Type checking response</p> Source code in <code>pixano/core/arrow_types/image.py</code> <pre><code>def is_image_type(t: pa.DataType) -&gt; bool:\n\"\"\"Returns True if value is an instance of ImageType\n\n    Args:\n        t (pa.DataType): Value to check\n\n    Returns:\n        bool: Type checking response\n    \"\"\"\n    return isinstance(t, ImageType)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.is_number",
      "title": "<code>is_number(t)</code>",
      "text": "<p>Check if DataType is a a number (integer or float)</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>pa.DataType</code> <p>DataType to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if DataType is an integer or a float</p> Source code in <code>pixano/core/arrow_types/__init__.py</code> <pre><code>def is_number(t: pa.DataType) -&gt; bool:\n\"\"\"Check if DataType is a a number (integer or float)\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is an integer or a float\n    \"\"\"\n\n    return pa.types.is_integer(t) or pa.types.is_floating(t)\n</code></pre>"
    },
    {
      "location": "code/core/arrow_types/#core.arrow_types.register_extension_types",
      "title": "<code>register_extension_types()</code>",
      "text": "<p>Register PyArrow ExtensionTypes</p> Source code in <code>pixano/core/arrow_types/__init__.py</code> <pre><code>def register_extension_types():\n\"\"\"Register PyArrow ExtensionTypes\"\"\"\n\n    types = [\n        BBoxType(),\n        CompressedRLEType(),\n        EmbeddingType(),\n        ImageType(),\n    ]\n\n    for t in types:\n        # Register ExtensionType\n        try:\n            pa.register_extension_type(t)\n        # If ExtensionType is already registered\n        except pa.ArrowKeyError:\n            pass\n</code></pre>"
    },
    { "location": "code/core/dataset/", "title": "dataset", "text": "" },
    {
      "location": "code/core/dataset/#core.dataset",
      "title": "<code>core.dataset</code>",
      "text": ""
    },
    {
      "location": "code/core/dataset/#core.dataset.Dataset",
      "title": "<code>Dataset(path)</code>",
      "text": "<p>Dataset class</p> <p>Attributes:</p> Name Type Description <code>_path</code> <code>Path</code> <p>Dataset path</p> <code>_info</code> <code>DatasetInfo</code> <p>Dataset info</p> <code>_partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Dataset path</p> required Source code in <code>pixano/core/dataset.py</code> <pre><code>def __init__(self, path: Path):\n\"\"\"Initialize dataset\n\n    Args:\n        path (Path): Dataset path\n    \"\"\"\n\n    self._path = path\n    self._info = DatasetInfo.parse_file(self._path / \"spec.json\")\n</code></pre>"
    },
    {
      "location": "code/core/dataset/#core.dataset.DatasetInfo",
      "title": "<code>DatasetInfo</code>",
      "text": "<p>         Bases: <code>pydantic.BaseModel</code></p> <p>DatasetInfo</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Dataset ID</p> <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>num_elements</code> <code>int</code> <p>Number of elements in dataset</p> <code>preview</code> <code>str</code> <p>Dataset preview</p> <code>categories</code> <code>list[dict]</code> <p>Dataset categories</p>"
    },
    {
      "location": "code/core/dataset/#core.dataset.EmbeddingDataset",
      "title": "<code>EmbeddingDataset(path)</code>",
      "text": "<p>         Bases: <code>Dataset</code></p> <p>Embedding Dataset</p> <p>Attributes:</p> Name Type Description <code>_path</code> <code>Path</code> <p>Dataset path</p> <code>_info</code> <code>DatasetInfo</code> <p>Dataset info</p> <code>_partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> Source code in <code>pixano/core/dataset.py</code> <pre><code>def __init__(self, path: Path):\n    self._path = path\n    self._info = DatasetInfo.parse_file(self._path / \"embed.json\")\n</code></pre>"
    },
    {
      "location": "code/core/dataset/#core.dataset.InferenceDataset",
      "title": "<code>InferenceDataset(path)</code>",
      "text": "<p>         Bases: <code>Dataset</code></p> <p>Inference Dataset</p> <p>Attributes:</p> Name Type Description <code>_path</code> <code>Path</code> <p>Dataset path</p> <code>_info</code> <code>DatasetInfo</code> <p>Dataset info</p> <code>_partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> Source code in <code>pixano/core/dataset.py</code> <pre><code>def __init__(self, path: Path):\n    self._path = path\n    self._info = DatasetInfo.parse_file(self._path / \"infer.json\")\n</code></pre>"
    },
    { "location": "code/data/coco_loader/", "title": "CocoLoader", "text": "" },
    {
      "location": "code/data/coco_loader/#data.COCOLoader",
      "title": "<code>data.COCOLoader(name, description, splits)</code>",
      "text": "<p>         Bases: <code>DataLoader</code></p> <p>Data Loader class for COCO instances dataset</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>schema</code> <code>pa.schema</code> <p>Dataset schema</p> <code>partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required Source code in <code>pixano/data/coco_loader.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n):\n\"\"\"Initialize COCO Loader\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n    \"\"\"\n\n    # Dataset views\n    views = [pa.field(\"image\", arrow_types.ImageType())]\n\n    # Initialize Data Loader\n    super().__init__(name, description, splits, views)\n</code></pre>"
    },
    {
      "location": "code/data/coco_loader/#data.coco_loader.COCOLoader.export_dataset",
      "title": "<code>export_dataset(input_dir, export_dir, input_dbs=[], portable=False)</code>",
      "text": "<p>Export dataset back to original format</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input directory</p> required <code>export_dir</code> <code>Path</code> <p>Export directory</p> required <code>input_dbs</code> <code>list[str]</code> <p>Input databases to export, all if []. Defaults to [].</p> <code>[]</code> <code>portable</code> <code>bool</code> <p>True to export dataset portable media files. Defaults to False.</p> <code>False</code> Source code in <code>pixano/data/coco_loader.py</code> <pre><code>def export_dataset(\n    self,\n    input_dir: Path,\n    export_dir: Path,\n    input_dbs: list = [],\n    portable: bool = False,\n):\n\"\"\"Export dataset back to original format\n\n    Args:\n        input_dir (Path): Input directory\n        export_dir (Path): Export directory\n        input_dbs (list[str]): Input databases to export, all if []. Defaults to [].\n        portable (bool, optional): True to export dataset portable media files. Defaults to False.\n    \"\"\"\n\n    # Load spec.json\n    input_info = DatasetInfo.parse_file(input_dir / \"spec.json\")\n\n    # Create URI prefix\n    media_dir = input_dir / \"media\"\n    uri_prefix = media_dir.absolute().as_uri()\n    export_uri_prefix = (export_dir / \"media\").absolute().as_uri()\n\n    # If no splits provided, select all splits\n    if not self.splits:\n        splits = [s.name for s in os.scandir(input_dir / \"db\") if s.is_dir()]\n    # Else, format provided splits\n    else:\n        splits = [\n            f\"split={s}\" if not s.startswith(\"split=\") else s for s in self.splits\n        ]\n    # Check if the splits exist\n    for split in splits:\n        split_dir = input_dir / \"db\" / split\n        if not split_dir.exists():\n            raise Exception(f\"{split_dir} does not exist.\")\n        if not any(split_dir.iterdir()):\n            raise Exception(f\"{split_dir} is empty.\")\n\n    # If no input databases provided, select all input databases\n    if not input_dbs:\n        input_dbs = [\"db\"]\n        for inf_json in sorted(list(input_dir.glob(\"db_infer_*/infer.json\"))):\n            input_dbs.append(inf_json.parent.name)\n    # Else, format provided inference datasets\n    else:\n        input_dbs = [\n            f\"db_infer_{i}\" if not i.startswith(\"db\") else i for i in input_dbs\n        ]\n\n    # Check if the datasets exist\n    for ds in input_dbs:\n        ds_dir = input_dir / ds\n        if not ds_dir.exists():\n            raise Exception(f\"{ds_dir} does not exist.\")\n        if not any(ds_dir.iterdir()):\n            raise Exception(f\"{ds_dir} is empty.\")\n\n    # Create export directory\n    ann_dir = export_dir / f\"annotations_[{','.join(input_dbs)}]\"\n    ann_dir.mkdir(parents=True, exist_ok=True)\n\n    # Iterate on splits\n    for split in splits:\n        # List split files\n        files = (input_dir / \"db\" / split).glob(\"*.parquet\")\n        files = sorted(files, key=lambda x: natural_key(x.name))\n        split_name = split.replace(\"split=\", \"\")\n\n        # Create COCO json\n        coco_json = {\n            \"info\": {\n                \"description\": input_info.name,\n                \"url\": \"N/A\",\n                \"version\": f\"v{datetime.datetime.now().strftime('%y%m%d.%H%M%S')}\",\n                \"year\": datetime.date.today().year,\n                \"contributor\": \"Exported from Pixano\",\n                \"date_created\": datetime.date.today().isoformat(),\n            },\n            \"licences\": [\n                {\n                    \"url\": \"N/A\",\n                    \"id\": 1,\n                    \"name\": \"Unknown\",\n                },\n            ],\n            \"images\": [],\n            \"annotations\": [],\n            \"categories\": [],\n        }\n\n        # Iterate on files\n        for file in tqdm(files, desc=f\"Processing {split_name} split\", position=0):\n            seen_category_ids = [None]\n\n            # Load media table\n            media_fields = [\n                field.name\n                for field in self.schema\n                if arrow_types.is_image_type(field.type)\n            ]\n            media_table = pq.read_table(file).select([\"id\"] + media_fields)\n\n            # Load annotation tables\n            ann_files = [input_dir / ds / split / file.name for ds in input_dbs]\n            ann_tables = [pq.read_table(f).select([\"objects\"]) for f in ann_files]\n\n            # Iterate on rows\n            for row in tqdm(\n                range(media_table.num_rows),\n                desc=f\"Processing {file.name}\",\n                position=1,\n            ):\n                media_row = media_table.take([row])\n                ann_rows = [ann_table.take([row]) for ann_table in ann_tables]\n                images = {}\n\n                for field in media_fields:\n                    # Open image\n                    images[field] = media_row[field][0].as_py(uri_prefix)\n                    im_uri = (\n                        media_row[field][0].as_py(export_uri_prefix).uri\n                        if portable\n                        else images[field].uri\n                    )\n                    im_filename = Path(urlparse(im_uri).path).name\n                    im_w, im_h = images[field].size\n                    # Append image info\n                    coco_json[\"images\"].append(\n                        {\n                            \"license\": 1,\n                            \"coco_url\": im_uri,\n                            \"file_name\": im_filename,\n                            \"height\": im_h,\n                            \"width\": im_w,\n                            \"id\": media_row[\"id\"][0].as_py(),\n                        }\n                    )\n\n                for ann_row in ann_rows:\n                    anns = ann_row[\"objects\"][0].as_py()\n\n                    for ann in anns:\n                        # Append annotation\n                        im_w, im_h = images[ann[\"view_id\"]].size\n                        urle = rle_to_urle(ann[\"mask\"])\n                        bbox = (\n                            ann[\"bbox\"]\n                            if ann[\"bbox\"] != [0.0, 0.0, 0.0, 0.0]\n                            else urle_to_bbox(urle)\n                        )\n                        coco_json[\"annotations\"].append(\n                            {\n                                \"segmentation\": urle,\n                                \"area\": ann[\"area\"],\n                                \"iscrowd\": 0,\n                                \"image_id\": media_row[\"id\"][0].as_py(),\n                                \"bbox\": denormalize(bbox, im_h, im_w),\n                                \"category_id\": ann[\"category_id\"],\n                                \"category_name\": ann[\"category_name\"],\n                                \"id\": ann[\"id\"],\n                            }\n                        )\n                        # Append category if not seen yet\n                        if (\n                            ann[\"category_id\"] not in seen_category_ids\n                            and ann[\"category_name\"] is not None\n                        ):\n                            coco_json[\"categories\"].append(\n                                {\n                                    \"supercategory\": \"N/A\",\n                                    \"id\": ann[\"category_id\"],\n                                    \"name\": ann[\"category_name\"],\n                                },\n                            )\n                            seen_category_ids.append(ann[\"category_id\"])\n\n        # Sort categories\n        coco_json[\"categories\"] = sorted(\n            coco_json[\"categories\"], key=lambda c: c[\"id\"]\n        )\n\n        # Save COCO json\n        with open(ann_dir / f\"instances_{split_name}.json\", \"w\") as f:\n            json.dump(coco_json, f)\n\n        # Move media directory if portable and directory exists\n        if portable:\n            if media_dir.exists():\n                media_dir.rename(export_dir / \"media\")\n            else:\n                raise Exception(\n                    f\"Activated portable option for export but {media_dir} does not exist.\"\n                )\n</code></pre>"
    },
    {
      "location": "code/data/coco_loader/#data.coco_loader.COCOLoader.import_row",
      "title": "<code>import_row(input_dirs, split, portable=False)</code>",
      "text": "<p>Process dataset row for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>split</code> <code>str</code> <p>Dataset split</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/coco_loader.py</code> <pre><code>def import_row(\n    self,\n    input_dirs: dict[str, Path],\n    split: str,\n    portable: bool = False,\n) -&gt; Iterator:\n\"\"\"Process dataset row for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        split (str): Dataset split\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    # Open annotation files\n    with open(input_dirs[\"objects\"] / f\"instances_{split}.json\", \"r\") as f:\n        coco_instances = json.load(f)\n\n    # Group annotations by image ID\n    annotations = defaultdict(list)\n    for ann in coco_instances[\"annotations\"]:\n        annotations[ann[\"image_id\"]].append(ann)\n\n    # Process rows\n    for im in sorted(coco_instances[\"images\"], key=lambda x: natural_key(x[\"id\"])):\n        # Load image annotations\n        im_anns = annotations[im[\"id\"]]\n        # Load image\n        file_name_uri = urlparse(im[\"file_name\"])\n        if file_name_uri.scheme == \"\":\n            im_path = input_dirs[\"image\"] / split / im[\"file_name\"]\n        else:\n            im_path = Path(file_name_uri.path)\n\n        # Create image thumbnail\n        im_thumb = image_to_thumbnail(im_path.read_bytes())\n\n        # Set image URI\n        im_uri = (\n            f\"image/{split}/{im_path.name}\"\n            if portable\n            else im_path.absolute().as_uri()\n        )\n\n        # Fill row with ID, image, and list of image annotations\n        row = {\n            \"id\": str(im[\"id\"]),\n            \"image\": arrow_types.Image(im_uri, None, im_thumb).to_dict(),\n            \"objects\": [\n                arrow_types.ObjectAnnotation(\n                    id=str(ann[\"id\"]),\n                    view_id=\"image\",\n                    area=float(ann[\"area\"]) if ann[\"area\"] else None,\n                    bbox=normalize(ann[\"bbox\"], im[\"height\"], im[\"width\"]),\n                    mask=encode_rle(ann[\"segmentation\"], im[\"height\"], im[\"width\"]),\n                    is_group_of=bool(ann[\"iscrowd\"]) if ann[\"iscrowd\"] else None,\n                    category_id=int(ann[\"category_id\"]),\n                    category_name=coco_names_91(ann[\"category_id\"]),\n                ).dict()\n                for ann in im_anns\n            ],\n            \"split\": split,\n        }\n\n        # Return row\n        yield row\n</code></pre>"
    },
    { "location": "code/data/data_loader/", "title": "DataLoader", "text": "" },
    {
      "location": "code/data/data_loader/#data.DataLoader",
      "title": "<code>data.DataLoader(name, description, splits, views)</code>",
      "text": "<p>         Bases: <code>ABC</code></p> <p>Abstract Data Loader class</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>schema</code> <code>pa.schema</code> <p>Dataset schema</p> <code>partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required <code>views</code> <code>list[pa.field]</code> <p>Dataset views</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n    views: list[pa.field],\n):\n\"\"\"Initialize Data Loader\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n        views (list[pa.field]): Dataset views\n    \"\"\"\n\n    # Dataset info\n    self.info = DatasetInfo(\n        id=shortuuid.uuid(),\n        name=name,\n        description=description,\n        num_elements=0,\n        preview=None,\n        categories=[],\n    )\n    self.splits = splits\n\n    # Dataset schema\n    fields = [\n        pa.field(\"split\", pa.string()),\n        pa.field(\"id\", pa.string()),\n        pa.field(\"objects\", pa.list_(arrow_types.ObjectAnnotationType())),\n    ]\n    fields.extend(views)\n    self.schema = pa.schema(fields)\n    self.partitioning = ds.partitioning(\n        pa.schema([(\"split\", pa.string())]), flavor=\"hive\"\n    )\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.create_json",
      "title": "<code>create_json(import_dir, categories=[])</code>",
      "text": "<p>Create dataset spec.json</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>categories</code> <code>list[dict]</code> <p>Dataset categories. Defaults to [].</p> <code>[]</code> Source code in <code>pixano/data/data_loader.py</code> <pre><code>def create_json(self, import_dir: Path, categories: list[dict] = []):\n\"\"\"Create dataset spec.json\n\n    Args:\n        import_dir (Path): Import directory\n        categories (list[dict], optional): Dataset categories. Defaults to [].\n    \"\"\"\n\n    with tqdm(desc=\"Creating dataset info file\", total=1) as progress:\n        # Read dataset\n        dataset = ds.dataset(import_dir / \"db\", partitioning=self.partitioning)\n\n        # Check number of rows in the created dataset\n        self.info.num_elements = dataset.count_rows()\n\n        # Add categories\n        if categories:\n            self.info.categories = categories\n\n        # Create spec.json\n        with open(import_dir / \"spec.json\", \"w\") as f:\n            json.dump(vars(self.info), f)\n        progress.update(1)\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.create_preview",
      "title": "<code>create_preview(import_dir)</code>",
      "text": "<p>Create dataset preview image</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def create_preview(self, import_dir: Path):\n\"\"\"Create dataset preview image\n\n    Args:\n        import_dir (Path): Import directory\n    \"\"\"\n\n    # Read dataset\n    dataset = ds.dataset(import_dir / \"db\", partitioning=self.partitioning)\n\n    # Get list of image fields\n    image_fields = []\n    for field in self.schema:\n        if arrow_types.is_image_type(field.type):\n            image_fields.append(field.name)\n\n    if image_fields:\n        with tqdm(desc=\"Creating dataset thumbnail\", total=1) as progress:\n            tile_w = 64\n            tile_h = 64\n            preview = Image.new(\"RGB\", (3 * tile_w, 2 * tile_h))\n            for i in range(6):\n                field = image_fields[i % len(image_fields)]\n                row_number = random.randrange(dataset.count_rows())\n                row = dataset.take([row_number]).to_pylist()[0]\n                with Image.open(BytesIO(row[field]._preview_bytes)) as im:\n                    preview.paste(im, ((i % 3) * tile_w, (int(i / 3) % 2) * tile_h))\n            preview.save(import_dir / \"preview.png\")\n            progress.update(1)\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.create_stats",
      "title": "<code>create_stats(import_dir)</code>",
      "text": "<p>Create dataset statistics</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def create_stats(self, import_dir: Path):\n\"\"\"Create dataset statistics\n\n    Args:\n        import_dir (Path): Import directory\n    \"\"\"\n\n    # Reset json file\n    open(import_dir / \"db_feature_statistics.json\", \"w\").close()\n    # Create objects stats\n    self.objects_stats(import_dir)\n    # Create image stats\n    self.image_stats(import_dir)\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.export_dataset",
      "title": "<code>export_dataset(input_dir, export_dir)</code>",
      "text": "<p>Export dataset back to original format</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input directory</p> required <code>export_dir</code> <code>Path</code> <p>Export directory</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def export_dataset(self, input_dir: Path, export_dir: Path):\n\"\"\"Export dataset back to original format\n\n    Args:\n        input_dir (Path): Input directory\n        export_dir (Path): Export directory\n    \"\"\"\n\n    pass\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.image_stats",
      "title": "<code>image_stats(import_dir)</code>",
      "text": "<p>Create dataset image statistics</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def image_stats(self, import_dir: Path):\n\"\"\"Create dataset image statistics\n\n    Args:\n        import_dir (Path): Import directory\n    \"\"\"\n\n    # Read dataset\n    dataset = ds.dataset(import_dir / \"db\", partitioning=self.partitioning)\n\n    # Create URI prefix\n    media_dir = import_dir / \"media\"\n    uri_prefix = media_dir.absolute().as_uri()\n\n    # Iterate over dataset columns\n    for field in dataset.schema:\n        # If column has images\n        if arrow_types.is_image_type(field.type):\n            features = []\n            rows = dataset.to_batches(columns=[field.name, \"split\"], batch_size=1)\n\n            # Get features\n            for row in tqdm(\n                rows,\n                desc=f\"Computing {field.name} stats\",\n                total=dataset.count_rows(),\n            ):\n                # Open image\n                im = row[field.name][0].as_py(uri_prefix)\n                im_w, im_h = im.size\n                # Compute image features\n                aspect_ratio = round(im_w / im_h, 1)\n                features.append(\n                    {\n                        f\"{field.name} - aspect ratio\": aspect_ratio,\n                        \"split\": row[\"split\"][0].as_py(),\n                    }\n                )\n            features_df = pd.DataFrame.from_records(features).astype(\n                {\n                    f\"{field.name} - aspect ratio\": \"float\",\n                    \"split\": \"string\",\n                }\n            )\n\n            # Initialize stats\n            stats = [\n                {\n                    \"name\": f\"{field.name} - aspect ratio\",\n                    \"type\": \"numerical\",\n                    \"histogram\": [],\n                    \"range\": [\n                        features_df[f\"{field.name} - aspect ratio\"].min(),\n                        features_df[f\"{field.name} - aspect ratio\"].max(),\n                    ],\n                },\n            ]\n\n            # Save stats\n            self.save_stats(import_dir, stats, features_df)\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.import_dataset",
      "title": "<code>import_dataset(input_dirs, import_dir, portable=False, batch_size=2048)</code>",
      "text": "<p>Import dataset to Pixano format</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>portable</code> <code>int</code> <p>True to move or download files inside import directory. Defaults to False.</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>Number of rows per file. Defaults to 2048.</p> <code>2048</code> Source code in <code>pixano/data/data_loader.py</code> <pre><code>def import_dataset(\n    self,\n    input_dirs: dict[str, Path],\n    import_dir: Path,\n    portable: bool = False,\n    batch_size: int = 2048,\n):\n\"\"\"Import dataset to Pixano format\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        import_dir (Path): Import directory\n        portable (int, optional): True to move or download files inside import directory. Defaults to False.\n        batch_size (int, optional): Number of rows per file. Defaults to 2048.\n    \"\"\"\n\n    # Check input directories\n    for source_path in input_dirs.values():\n        if not source_path.exists():\n            raise Exception(f\"{source_path} does not exist.\")\n        if not any(source_path.iterdir()):\n            raise Exception(f\"{source_path} is empty.\")\n\n    # Dataset categories\n    categories = []\n    seen_category_ids = [None]\n\n    # Iterate on splits\n    for split in self.splits:\n        batches = _batch_dict(\n            self.import_row(input_dirs, split, portable), batch_size\n        )\n        # Iterate on batches\n        for i, batch in tqdm(enumerate(batches), desc=f\"Converting {split} split\"):\n            # Append batch categories\n            for field in self.schema:\n                # If column has annotations\n                # TODO: Change to checking type when ObjectAnnotationType is rebuilt\n                if field.name == \"objects\":\n                    for row in batch[field.name]:\n                        for ann in row:\n                            if (\n                                ann[\"category_id\"] not in seen_category_ids\n                                and ann[\"category_name\"] is not None\n                            ):\n                                categories.append(\n                                    {\n                                        \"supercategory\": \"N/A\",\n                                        \"id\": ann[\"category_id\"],\n                                        \"name\": ann[\"category_name\"],\n                                    },\n                                )\n                                seen_category_ids.append(ann[\"category_id\"])\n\n            # Convert batch fields to PyArrow format\n            arrays = []\n            for field in self.schema:\n                arrays.append(\n                    arrow_types.convert_field(\n                        field_name=field.name,\n                        field_type=field.type,\n                        field_data=batch[field.name],\n                    )\n                )\n            # Save to file\n            ds.write_dataset(\n                data=pa.Table.from_arrays(arrays, schema=self.schema),\n                base_dir=import_dir / \"db\",\n                basename_template=f\"part-{{i}}-{i}.parquet\",\n                format=\"parquet\",\n                existing_data_behavior=\"overwrite_or_ignore\",\n                partitioning=self.partitioning,\n            )\n\n    # Sort categories\n    categories = sorted(categories, key=lambda c: c[\"id\"])\n\n    # Create spec.json\n    self.create_json(import_dir, categories)\n\n    # Create preview.png\n    self.create_preview(import_dir)\n\n    # Move media directories if portable\n    if portable:\n        for field in tqdm(self.schema, desc=f\"Moving media directories\"):\n            if arrow_types.is_image_type(field.type):\n                field_dir = import_dir / \"media\" / field.name\n                field_dir.mkdir(parents=True, exist_ok=True)\n                input_dirs[field.name].rename(field_dir)\n\n    # Create stats\n    self.create_stats(import_dir)\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.import_row",
      "title": "<code>import_row(input_dirs, split, portable=False)</code>  <code>abstractmethod</code>",
      "text": "<p>Process dataset row for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>split</code> <code>str</code> <p>Dataset split</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/data_loader.py</code> <pre><code>@abstractmethod\ndef import_row(\n    self,\n    input_dirs: dict[str, Path],\n    split: str,\n    portable: bool = False,\n) -&gt; Iterator:\n\"\"\"Process dataset row for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        split (str): Dataset split\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    pass\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.objects_stats",
      "title": "<code>objects_stats(import_dir)</code>",
      "text": "<p>Create dataset objects statistics</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def objects_stats(self, import_dir: Path):\n\"\"\"Create dataset objects statistics\n\n    Args:\n        import_dir (Path): Import directory\n    \"\"\"\n\n    # Read dataset\n    dataset = ds.dataset(import_dir / \"db\", partitioning=self.partitioning)\n\n    # Create stats if objects field exist\n    objects = pa.field(\"objects\", pa.list_(arrow_types.ObjectAnnotationType()))\n    if objects in self.schema:\n        # Create dataframe\n        df = dataset.to_table(columns=[\"split\", \"objects\"]).to_pandas()\n        # Split objects in one object per row\n        df = df.explode(\"objects\")\n        # Remove empty objects\n        df = df[df[\"objects\"].notnull()]\n\n        # Get features\n        features = []\n        for split, object in tqdm(\n            zip(df[\"split\"], df[\"objects\"]),\n            desc=\"Computing objects stats\",\n            total=len(df.index),\n        ):\n            try:\n                area = 100 * (object[\"area\"] / np.prod(object[\"mask\"][\"size\"]))\n            except TypeError:\n                area = None\n            features.append(\n                {\n                    \"id\": object[\"id\"],\n                    \"view id\": object[\"view_id\"],\n                    \"objects - is group of\": object[\"is_group_of\"],\n                    \"objects - area (%)\": area,\n                    \"objects - category\": object[\"category_name\"],\n                    \"split\": split,\n                }\n            )\n        features_df = pd.DataFrame.from_records(features).astype(\n            {\n                \"id\": \"string\",\n                \"view id\": \"string\",\n                \"objects - is group of\": bool,\n                \"objects - area (%)\": float,\n                \"objects - category\": \"string\",\n                \"split\": \"string\",\n            }\n        )\n\n        # Initialize stats\n        stats = [\n            {\n                \"name\": \"objects - category\",\n                \"type\": \"categorical\",\n                \"histogram\": [],\n            },\n            {\n                \"name\": \"objects - is group of\",\n                \"type\": \"categorical\",\n                \"histogram\": [],\n            },\n            {\n                \"name\": \"objects - area (%)\",\n                \"type\": \"numerical\",\n                \"range\": [0.0, 100.0],\n                \"histogram\": [],\n            },\n        ]\n\n        # Save stats\n        self.save_stats(import_dir, stats, features_df)\n</code></pre>"
    },
    {
      "location": "code/data/data_loader/#data.data_loader.DataLoader.save_stats",
      "title": "<code>save_stats(import_dir, stats, df)</code>",
      "text": "<p>Compute and save stats to json</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>stats</code> <code>list[dict]</code> <p>List of stats to save</p> required <code>df</code> <code>pd.DataFrame</code> <p>DataFrame to create stats from</p> required Source code in <code>pixano/data/data_loader.py</code> <pre><code>def save_stats(self, import_dir: Path, stats: list[dict], df: pd.DataFrame):\n\"\"\"Compute and save stats to json\n\n    Args:\n        import_dir (Path): Import directory\n        stats (list[dict]): List of stats to save\n        df (pd.DataFrame): DataFrame to create stats from\n    \"\"\"\n\n    # Compute stats\n    for split in self.splits:\n        for stat in stats:\n            split_df = df[df[\"split\"] == split]\n            stat[\"histogram\"].extend(compute_stats(split_df, split, stat))\n\n    # Check for existing db_feature_statistics.json\n    with open(import_dir / \"db_feature_statistics.json\", \"r\") as f:\n        try:\n            stat_json = json.load(f)\n            stat_json.extend(stats)\n        except ValueError:\n            stat_json = stats\n\n    # Add to db_feature_statistics.json\n    with open(import_dir / \"db_feature_statistics.json\", \"w\") as f:\n        json.dump(stat_json, f)\n</code></pre>"
    },
    { "location": "code/data/dota_loader/", "title": "DOTALoader", "text": "" },
    {
      "location": "code/data/dota_loader/#data.DOTALoader",
      "title": "<code>data.DOTALoader(name, description, splits)</code>",
      "text": "<p>         Bases: <code>DataLoader</code></p> <p>Data Loader class for DOTA dataset</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>schema</code> <code>pa.schema</code> <p>Dataset schema</p> <code>partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required Source code in <code>pixano/data/dota_loader.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n):\n\"\"\"Initialize COCO Loader\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n    \"\"\"\n\n    # Dataset views\n    views = [pa.field(\"image\", arrow_types.ImageType())]\n\n    # Initialize Data Loader\n    super().__init__(name, description, splits, views)\n</code></pre>"
    },
    {
      "location": "code/data/dota_loader/#data.dota_loader.DOTALoader.import_row",
      "title": "<code>import_row(input_dirs, split, portable=False)</code>",
      "text": "<p>Process dataset row for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>split</code> <code>str</code> <p>Dataset split</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/dota_loader.py</code> <pre><code>def import_row(\n    self,\n    input_dirs: dict[str, Path],\n    split: str,\n    portable: bool = False,\n) -&gt; Iterator:\n\"\"\"Process dataset row for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        split (str): Dataset split\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    # Get images paths\n    image_paths = glob.glob(str(input_dirs[\"image\"] / split / \"*.png\"))\n    image_paths = [Path(p) for p in sorted(image_paths, key=natural_key)]\n\n    # Process rows\n    for im_path in image_paths:\n        # Load image annotations\n        im_anns_file = (\n            input_dirs[\"objects\"]\n            / split\n            / \"hbb\"\n            / im_path.name.replace(\"png\", \"txt\")\n        )\n\n        # Allow DOTA largest images\n        Image.MAX_IMAGE_PIXELS = 806504000\n\n        # Get image dimensions and thumbnail\n        with Image.open(im_path) as im:\n            im_w, im_h = im.size\n            im_thumb = image_to_thumbnail(im)\n\n        # Set image URI\n        im_uri = (\n            f\"image/{split}/{im_path.name}\"\n            if portable\n            else im_path.absolute().as_uri()\n        )\n\n        # Fill row with ID, image, and list of image annotations\n        with open(im_anns_file) as im_anns:\n            row = {\n                \"id\": im_path.stem,\n                \"image\": arrow_types.Image(im_uri, None, im_thumb).to_dict(),\n                \"objects\": [\n                    arrow_types.ObjectAnnotation(\n                        id=shortuuid.uuid(),\n                        view_id=\"image\",\n                        bbox=normalize(\n                            xyxy_to_xywh(\n                                [\n                                    float(line.strip().split()[0]),\n                                    float(line.strip().split()[1]),\n                                    float(line.strip().split()[4]),\n                                    float(line.strip().split()[5]),\n                                ]\n                            ),\n                            im_h,\n                            im_w,\n                        ),\n                        is_difficult=bool(line.strip().split()[9]),\n                        category_id=dota_ids(str(line.strip().split()[8])),\n                        category_name=str(line.strip().split()[8]).replace(\n                            \"-\", \" \"\n                        ),\n                    ).dict()\n                    for line in im_anns\n                ],\n                \"split\": split,\n            }\n\n        # Return row\n        yield row\n</code></pre>"
    },
    {
      "location": "code/data/image_loader/",
      "title": "ImageLoader",
      "text": ""
    },
    {
      "location": "code/data/image_loader/#data.ImageLoader",
      "title": "<code>data.ImageLoader(name, description, splits)</code>",
      "text": "<p>         Bases: <code>DataLoader</code></p> <p>Data Loader class for demo datasets</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>schema</code> <code>pa.schema</code> <p>Dataset schema</p> <code>partitioning</code> <code>ds.partitioning</code> <p>Dataset partitioning</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required Source code in <code>pixano/data/image_loader.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n):\n\"\"\"Initialize COCO Loader\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n    \"\"\"\n\n    # Dataset views\n    views = [pa.field(\"image\", arrow_types.ImageType())]\n\n    # Initialize Data Loader\n    super().__init__(name, description, splits, views)\n</code></pre>"
    },
    {
      "location": "code/data/image_loader/#data.image_loader.ImageLoader.import_row",
      "title": "<code>import_row(input_dirs, split, portable=False)</code>",
      "text": "<p>Process dataset row for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directories</p> required <code>split</code> <code>str</code> <p>Dataset split</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/image_loader.py</code> <pre><code>def import_row(\n    self,\n    input_dirs: dict[str, Path],\n    split: str,\n    portable: bool = False,\n) -&gt; Iterator:\n\"\"\"Process dataset row for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directories\n        split (str): Dataset split\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    # Get images paths\n    image_paths = []\n    for type in [\"*.png\", \"*.jpg\", \"*.jpeg\"]:\n        image_paths.extend(glob.glob(str(input_dirs[\"image\"] / split / type)))\n    image_paths = [Path(p) for p in sorted(image_paths, key=natural_key)]\n\n    # Process rows\n    for im_path in image_paths:\n        # Create image thumbnail\n        im_thumb = image_to_thumbnail(im_path.read_bytes())\n\n        # Set image URI\n        im_uri = (\n            f\"image/{split}/{im_path.name}\"\n            if portable\n            else im_path.absolute().as_uri()\n        )\n\n        # Fill row with ID, image, and list of image annotations\n        row = {\n            \"id\": im_path.name,\n            \"image\": arrow_types.Image(im_uri, None, im_thumb).to_dict(),\n            # TODO: find a way to return an empty list\n            \"objects\": [\n                arrow_types.ObjectAnnotation(\n                    id=shortuuid.uuid(),\n                    category_id=0,\n                ).dict()\n            ],\n            \"split\": split,\n        }\n\n        # Return row\n        yield row\n</code></pre>"
    },
    {
      "location": "code/data/legacy_loader/",
      "title": "LegacyLoader",
      "text": ""
    },
    {
      "location": "code/data/legacy_loader/#data.LegacyLoader",
      "title": "<code>data.LegacyLoader(name, description, splits, views, json_files)</code>",
      "text": "<p>         Bases: <code>DataLoader</code></p> <p>Data Loader class for Pixano legacy format datasets</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>views</code> <code>list[str]</code> <p>Dataset views</p> <code>json_files</code> <code>dict[str, str]</code> <p>json file paths relative to workspace</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>json_files</code> <code>dict[str, str]</code> <p>json file paths relative to workspace</p> required Source code in <code>pixano/data/legacy_loader.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    splits: list[str],\n    views: list[str],\n    json_files: dict[str, str],\n):\n\"\"\"Initialize Pixano Legacy Loader\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        splits (list[str]): Dataset splits\n        views (list[str]): Dataset views\n        json_files (dict[str, str]): json file paths relative to workspace\n    \"\"\"\n\n    self.views = views\n    self.json_files = json_files\n\n    # Initialize Data Loader\n    super().__init__(\n        name,\n        description,\n        splits,\n        [pa.field(view, arrow_types.ImageType()) for view in views],\n    )\n</code></pre>"
    },
    {
      "location": "code/data/legacy_loader/#data.legacy_loader.LegacyLoader.import_row",
      "title": "<code>import_row(input_dirs, split, portable=False)</code>",
      "text": "<p>Process dataset row for import</p> <p>Parameters:</p> Name Type Description Default <code>input_dirs</code> <code>dict[str, Path]</code> <p>Input directory workspace for json files and images</p> required <code>split</code> <code>str</code> <p>Dataset split</p> required <code>portable</code> <code>bool</code> <p>True to move or download media files inside dataset. Defaults to False.</p> <code>False</code> <p>Yields:</p> Name Type Description <code>Iterator</code> <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/legacy_loader.py</code> <pre><code>def import_row(\n    self,\n    input_dirs: dict[str, Path],\n    split: str,\n    portable: bool = False,\n) -&gt; Iterator:\n\"\"\"Process dataset row for import\n\n    Args:\n        input_dirs (dict[str, Path]): Input directory workspace for json files and images\n        split (str): Dataset split\n        portable (bool, optional): True to move or download media files inside dataset. Defaults to False.\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    category_ids = {}\n    feats = defaultdict(list)\n    for view in self.views:\n        # Open annotation files\n        with open(input_dirs[\"workspace\"] / self.json_files[view], \"r\") as f:\n            pix_json = json.load(f)\n\n            # Group annotations by image ID (timestamp)\n            annotations = defaultdict(list)\n            for ann in pix_json[\"annotations\"]:\n                annotations[str(ann[\"timestamp\"])].append(ann)\n\n            # Process rows\n            for im in sorted(\n                pix_json[\"data\"][\"children\"], key=lambda x: x[\"timestamp\"]\n            ):\n                # Load image\n                file_name_uri = urlparse(im[\"path\"])\n                if file_name_uri.scheme == \"\":\n                    im_path = input_dirs[\"workspace\"] / im[\"path\"]\n                else:\n                    im_path = Path(file_name_uri.path)\n\n                image = Image.open(BytesIO(im_path.read_bytes()))\n                im_w = image.width\n                im_h = image.height\n                im_thumb = image_to_thumbnail(image)\n\n                feats[str(im[\"timestamp\"])].append(\n                    {\n                        \"viewId\": view,\n                        \"width\": im_w,\n                        \"height\": im_h,\n                        \"im_thumb\": im_thumb,\n                        \"im_uri\": (\n                            f\"image/{split}/{im_path.name}\"\n                            if portable\n                            else im_path.absolute().as_uri()\n                        ),\n                        \"anns\": annotations[str(im[\"timestamp\"])],\n                    }\n                )\n\n    for timestamp in feats:\n        # Fill row with ID, image\n        row = {\n            \"id\": timestamp,\n            \"objects\": [],\n            \"split\": split,\n        }\n        for f in feats[timestamp]:\n            row[f[\"viewId\"]] = arrow_types.Image(\n                f[\"im_uri\"], None, f[\"im_thumb\"]\n            ).to_dict()\n\n            # Fill row with list of image annotations\n            for ann in f[\"anns\"]:\n                # collect categories to build category ids\n                if ann[\"category\"] not in category_ids:\n                    category_ids[ann[\"category\"]] = len(category_ids)\n\n                bbox = [0.0, 0.0, 0.0, 0.0]\n                mask = None\n\n                if \"geometry\" in ann:\n                    if (\n                        ann[\"geometry\"][\"type\"] == \"polygon\"\n                        and ann[\"geometry\"][\"vertices\"]\n                    ):\n                        # Polygon\n                        # we have normalized coords, we must denorm before making RLE\n                        if not isnan(ann[\"geometry\"][\"vertices\"][0]):\n                            if len(ann[\"geometry\"][\"vertices\"]) &gt; 4:\n                                denorm = denormalize(\n                                    ann[\"geometry\"][\"vertices\"],\n                                    f[\"height\"],\n                                    f[\"width\"],\n                                )\n                                rles = mask_api.frPyObjects(\n                                    [denorm], f[\"height\"], f[\"width\"]\n                                )\n                                mask = mask_api.merge(rles)\n                            else:\n                                print(\n                                    \"Polygon with 2 or less points. Discarded\\n\",\n                                    ann[\"geometry\"],\n                                )\n                    elif (\n                        ann[\"geometry\"][\"type\"] == \"mpolygon\"\n                        and ann[\"geometry\"][\"mvertices\"]\n                    ):\n                        # MultiPolygon\n                        if not isnan(ann[\"geometry\"][\"mvertices\"][0][0]):\n                            denorm = [\n                                denormalize(poly, f[\"height\"], f[\"width\"])\n                                for poly in ann[\"geometry\"][\"mvertices\"]\n                            ]\n                            rles = mask_api.frPyObjects(\n                                denorm, f[\"height\"], f[\"width\"]\n                            )\n                            mask = mask_api.merge(rles)\n                    elif (\n                        ann[\"geometry\"][\"type\"] == \"rectangle\"\n                        and ann[\"geometry\"][\"vertices\"]\n                    ):  # BBox\n                        if not isnan(ann[\"geometry\"][\"vertices\"][0]):\n                            denorm = denormalize(\n                                [ann[\"geometry\"][\"vertices\"]],\n                                f[\"height\"],\n                                f[\"width\"],\n                            )\n                            bbox = xyxy_to_xywh(denorm)\n                    elif (\n                        ann[\"geometry\"][\"type\"] == \"graph\"\n                        and ann[\"geometry\"][\"vertices\"]\n                    ):  # Keypoints\n                        print(\"Keypoints are not implemented yet\")\n                    else:\n                        # print('Unknown geometry', ann['geometry']['type'])  # log can be annoying if many...\n                        pass\n                else:\n                    # Ca peut etre un mask, ou 3d, trackink... etc.\n                    print(\"No geometry?\")\n\n                row[\"objects\"].append(\n                    arrow_types.ObjectAnnotation(\n                        id=str(ann[\"id\"]),\n                        view_id=f[\"viewId\"],\n                        bbox=bbox,\n                        mask=mask,\n                        is_group_of=bool(ann[\"iscrowd\"])\n                        if \"iscrowd\" in ann\n                        else None,\n                        category_id=category_ids[ann[\"category\"]],\n                        category_name=ann[\"category\"],\n                    ).dict()\n                )\n\n        # Return row\n        yield row\n</code></pre>"
    },
    {
      "location": "code/models/inference_model/",
      "title": "InferenceModel",
      "text": ""
    },
    {
      "location": "code/models/inference_model/#models.InferenceModel",
      "title": "<code>models.InferenceModel(name, id='', device='', source='', info='')</code>",
      "text": "<p>         Bases: <code>ABC</code></p> <p>Abstract parent class for OfflineModel and OnlineModel</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Model name</p> <code>id</code> <code>str</code> <p>Model ID</p> <code>device</code> <code>str</code> <p>Model GPU or CPU device</p> <code>source</code> <code>str</code> <p>Model source</p> <code>info</code> <code>str</code> <p>Additional model info</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>id</code> <code>str</code> <p>Model ID. Defaults to \"\".</p> <code>''</code> <code>device</code> <code>str</code> <p>Model GPU or CPU device. Defaults to \"\".</p> <code>''</code> <code>source</code> <code>str</code> <p>Model source. Defaults to \"\".</p> <code>''</code> <code>info</code> <code>str</code> <p>Additional model info. Defaults to \"\".</p> <code>''</code> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    id: str = \"\",\n    device: str = \"\",\n    source: str = \"\",\n    info: str = \"\",\n) -&gt; None:\n\"\"\"Initialize model name and ID\n\n    Args:\n        name (str): Model name\n        id (str, optional): Model ID. Defaults to \"\".\n        device (str, optional): Model GPU or CPU device. Defaults to \"\".\n        source (str, optional): Model source. Defaults to \"\".\n        info (str, optional): Additional model info. Defaults to \"\".\n    \"\"\"\n\n    self.name = name\n    if id == \"\":\n        self.id = f\"{datetime.now().strftime('%y%m%d_%H%M%S')}_{name}\"\n    else:\n        self.id = id\n    self.device = device\n    self.source = source\n    self.info = info\n</code></pre>"
    },
    {
      "location": "code/models/inference_model/#models.inference_model.InferenceModel.create_json",
      "title": "<code>create_json(output_dir, filename, spec_json, num_elements)</code>",
      "text": "<p>Save output .json</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>Path</code> <p>Output dataset directory</p> required <code>filename</code> <code>str</code> <p>Output .json filename</p> required <code>spec_json</code> <code>dict</code> <p>Input dataset .json</p> required <code>num_elements</code> <code>int</code> <p>Number of processed rows</p> required Source code in <code>pixano/models/inference_model.py</code> <pre><code>def create_json(\n    self,\n    output_dir: Path,\n    filename: str,\n    spec_json: dict,\n    num_elements: int,\n):\n\"\"\"Save output .json\n\n    Args:\n        output_dir (Path): Output dataset directory\n        filename (str): Output .json filename\n        spec_json (dict): Input dataset .json\n        num_elements (int): Number of processed rows\n    \"\"\"\n\n    # Load existing .json\n    if (output_dir / f\"{filename}.json\").is_file():\n        with open(output_dir / f\"{filename}.json\", \"r\") as f:\n            output_json = json.load(f)\n        output_json[\"num_elements\"] += num_elements\n\n    # Or create .json from scratch\n    else:\n        output_json = {\n            \"id\": spec_json[\"id\"],\n            \"name\": spec_json[\"name\"],\n            \"description\": spec_json[\"description\"],\n            \"num_elements\": num_elements,\n            \"model_id\": self.id,\n            \"model_name\": self.name,\n            \"model_source\": self.source,\n            \"model_info\": self.info,\n        }\n\n    # Save .json\n    with open(output_dir / f\"{filename}.json\", \"w\") as f:\n        json.dump(output_json, f)\n</code></pre>"
    },
    {
      "location": "code/models/inference_model/#models.inference_model.InferenceModel.embedding_batch",
      "title": "<code>embedding_batch(batch, view, uri_prefix)</code>",
      "text": "<p>Embedding precomputing for a batch</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>pa.RecordBatch</code> <p>Input batch</p> required <code>view</code> <code>str</code> <p>Dataset view</p> required <code>uri_prefix</code> <code>str</code> <p>URI prefix for media files</p> required <p>Returns:</p> Type Description <code>list[np.ndarray]</code> <p>list[np.ndarray]: Model embeddings as NumPy arrays</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def embedding_batch(\n    self,\n    batch: pa.RecordBatch,\n    view: str,\n    uri_prefix: str,\n) -&gt; list[np.ndarray]:\n\"\"\"Embedding precomputing for a batch\n\n    Args:\n        batch (pa.RecordBatch): Input batch\n        view (str): Dataset view\n        uri_prefix (str): URI prefix for media files\n\n    Returns:\n        list[np.ndarray]: Model embeddings as NumPy arrays\n    \"\"\"\n\n    pass\n</code></pre>"
    },
    {
      "location": "code/models/inference_model/#models.inference_model.InferenceModel.export_to_onnx",
      "title": "<code>export_to_onnx(library_dir)</code>",
      "text": "<p>Export Torch model to ONNX</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>Path</code> <p>Dataset library directory</p> required Source code in <code>pixano/models/inference_model.py</code> <pre><code>def export_to_onnx(self, library_dir: Path):\n\"\"\"Export Torch model to ONNX\n\n    Args:\n        library_dir (Path): Dataset library directory\n    \"\"\"\n\n    pass\n</code></pre>"
    },
    {
      "location": "code/models/inference_model/#models.inference_model.InferenceModel.inference_batch",
      "title": "<code>inference_batch(batch, view, uri_prefix, threshold=0.0)</code>",
      "text": "<p>Inference preannotation for a batch</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>pa.RecordBatch</code> <p>Input batch</p> required <code>view</code> <code>str</code> <p>Dataset view</p> required <code>uri_prefix</code> <code>str</code> <p>URI prefix for media files</p> required <code>threshold</code> <code>float</code> <p>Confidence threshold. Defaults to 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>list[list[arrow_types.ObjectAnnotation]]</code> <p>list[list[arrow_types.ObjectAnnotation]]: Model inferences as lists of ObjectAnnotation</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def inference_batch(\n    self,\n    batch: pa.RecordBatch,\n    view: str,\n    uri_prefix: str,\n    threshold: float = 0.0,\n) -&gt; list[list[arrow_types.ObjectAnnotation]]:\n\"\"\"Inference preannotation for a batch\n\n    Args:\n        batch (pa.RecordBatch): Input batch\n        view (str): Dataset view\n        uri_prefix (str): URI prefix for media files\n        threshold (float, optional): Confidence threshold. Defaults to 0.0.\n\n    Returns:\n        list[list[arrow_types.ObjectAnnotation]]: Model inferences as lists of ObjectAnnotation\n    \"\"\"\n\n    pass\n</code></pre>"
    },
    {
      "location": "code/models/inference_model/#models.inference_model.InferenceModel.process_dataset",
      "title": "<code>process_dataset(input_dir, process_type, views, splits=[], batch_size=1, threshold=0.0)</code>",
      "text": "<p>Process dataset for inference preannotation or embedding precomputing</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input dataset directory</p> required <code>process_type</code> <code>str</code> <p>Process type ('infer' for inference preannotation or 'embed' for embedding precomputing)</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits, all if []. Defaults to [].</p> <code>[]</code> <code>batch_size</code> <code>int</code> <p>Rows per batch. Defaults to 1.</p> <code>1</code> <code>threshold</code> <code>float</code> <p>Confidence threshold for predictions. Defaults to 0.0.</p> <code>0.0</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Output dataset directory</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def process_dataset(\n    self,\n    input_dir: Path,\n    process_type: str,\n    views: list[str],\n    splits: list[str] = [],\n    batch_size: int = 1,\n    threshold: float = 0.0,\n) -&gt; Path:\n\"\"\"Process dataset for inference preannotation or embedding precomputing\n\n    Args:\n        input_dir (Path): Input dataset directory\n        process_type (str): Process type ('infer' for inference preannotation or 'embed' for embedding precomputing)\n        views (list[str]): Dataset views\n        splits (list[str], optional): Dataset splits, all if []. Defaults to [].\n        batch_size (int, optional): Rows per batch. Defaults to 1.\n        threshold (float, optional): Confidence threshold for predictions. Defaults to 0.0.\n\n    Returns:\n        Path: Output dataset directory\n    \"\"\"\n\n    output_dir = input_dir / f\"db_{process_type}_{self.id}\"\n\n    # Load spec.json\n    with open(input_dir / \"spec.json\", \"r\") as f:\n        spec_json = json.load(f)\n\n    # Create URI prefix\n    media_dir = input_dir / \"media\"\n    uri_prefix = media_dir.absolute().as_uri()\n\n    # If no splits provided, select all splits\n    if not splits:\n        splits = [s.name for s in os.scandir(input_dir / \"db\") if s.is_dir()]\n    # Else, format provided splits\n    else:\n        splits = [\n            f\"split={s}\" if not s.startswith(\"split=\") else s for s in self.splits\n        ]\n    # Check if the splits exist\n    for split in splits:\n        split_dir = input_dir / \"db\" / split\n        if split_dir.exists():\n            raise Exception(f\"{split_dir} does not exist.\")\n        if not any(split_dir.iterdir()):\n            raise Exception(f\"{split_dir} is empty.\")\n\n    # Create schema\n    fields = [pa.field(\"id\", pa.string())]\n    if process_type == \"infer\":\n        fields.extend(\n            [\n                pa.field(\"objects\", pa.list_(arrow_types.ObjectAnnotationType())),\n            ]\n        )\n    elif process_type == \"embed\":\n        fields.extend(\n            [\n                pa.field(f\"{view}_embedding\", arrow_types.EmbeddingType())\n                for view in views\n            ]\n        )\n    schema = pa.schema(fields)\n\n    # Iterate on splits\n    for split in splits:\n        # List split files\n        files = (input_dir / \"db\" / split).glob(\"*.parquet\")\n        files = sorted(files, key=lambda x: natural_key(x.name))\n\n        # Create output split directory\n        split_dir = output_dir / split\n        split_dir.mkdir(parents=True, exist_ok=True)\n        split_name = split.replace(\"split=\", \"\")\n\n        # Check for already processed files\n        processed = [p.name for p in split_dir.glob(\"*.parquet\")]\n\n        # Iterate on files\n        for file in tqdm(files, desc=f\"Processing {split_name} split\", position=0):\n            # Process only remaining files\n            if file.name not in processed:\n                # Load file into batches\n                table = pq.read_table(file)\n                batches = table.to_batches(max_chunksize=batch_size)\n\n                # Iterate on batches\n                data = {field.name: [] for field in schema}\n                for batch in tqdm(\n                    batches, desc=f\"Processing {file.name}\", position=1\n                ):\n                    # Add row IDs\n                    data[\"id\"].extend([str(row) for row in batch[\"id\"]])\n                    # For inferences\n                    if process_type == \"infer\":\n                        # Iterate on views\n                        batch_inf = []\n                        for view in views:\n                            batch_inf.append(\n                                self.inference_batch(\n                                    batch, view, uri_prefix, threshold\n                                )\n                            )\n                        # Regroup view inferences by row\n                        data[\"objects\"].append(\n                            [\n                                inf.dict()\n                                for row in range(len(batch[\"id\"]))\n                                for view_inf in batch_inf\n                                for inf in view_inf[row]\n                            ]\n                        )\n                    # For embeddings\n                    elif process_type == \"embed\":\n                        # Iterate on views\n                        for view in views:\n                            view_emb = self.embedding_batch(batch, view, uri_prefix)\n                            for emb in view_emb:\n                                emb_bytes = BytesIO()\n                                np.save(emb_bytes, emb)\n                                data[f\"{view}_embedding\"].append(\n                                    emb_bytes.getvalue()\n                                )\n\n                # Convert ExtensionTypes\n                arrays = []\n                for field in schema:\n                    arrays.append(\n                        arrow_types.convert_field(\n                            field_name=field.name,\n                            field_type=field.type,\n                            field_data=data[field.name],\n                        )\n                    )\n\n                # Save to file\n                pq.write_table(\n                    pa.Table.from_arrays(arrays, schema=schema),\n                    split_dir / file.name,\n                )\n\n                # Save.json\n                self.create_json(\n                    output_dir=output_dir,\n                    filename=process_type,\n                    spec_json=spec_json,\n                    num_elements=pq.read_metadata(split_dir / file.name).num_rows,\n                )\n\n    return output_dir\n</code></pre>"
    },
    { "location": "code/transforms/boxes/", "title": "boxes", "text": "" },
    {
      "location": "code/transforms/boxes/#transforms.boxes",
      "title": "<code>transforms.boxes</code>",
      "text": ""
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.denormalize",
      "title": "<code>denormalize(coord, height, width)</code>",
      "text": "<p>Denormalize coordinates</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Normalized coordinates</p> required <code>height</code> <code>int</code> <p>Height</p> required <code>width</code> <code>int</code> <p>Width</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: Unnormalized coordinates</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def denormalize(coord: list[float], height: int, width: int) -&gt; list[float]:\n\"\"\"Denormalize coordinates\n\n    Args:\n        coord (list[float]): Normalized coordinates\n        height (int): Height\n        width (int): Width\n\n    Returns:\n        list[float]: Unnormalized coordinates\n    \"\"\"\n\n    denorm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            denorm.append(c * width)\n        else:\n            denorm.append(c * height)\n\n    return denorm\n</code></pre>"
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.format_bbox",
      "title": "<code>format_bbox(bbox, is_predicted=False, confidence=None)</code>",
      "text": "<p>Convert bounding box to frontend format</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>list[float]</code> <p>Bounding box</p> required <code>is_predicted</code> <code>bool</code> <p>True for prediction, False for ground truth. Defaults to False.</p> <code>False</code> <code>confidence</code> <code>float</code> <p>Bounding box confidence. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Bounding box in frontend format</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def format_bbox(bbox, is_predicted=False, confidence=None) -&gt; dict:\n\"\"\"Convert bounding box to frontend format\n\n    Args:\n        bbox (list[float]): Bounding box\n        is_predicted (bool, optional): True for prediction, False for ground truth. Defaults to False.\n        confidence (float, optional): Bounding box confidence. Defaults to None.\n\n    Returns:\n        dict: Bounding box in frontend format\n    \"\"\"\n\n    return {\n        \"x\": float(bbox[0]),\n        \"y\": float(bbox[1]),\n        \"width\": float(bbox[2]),\n        \"height\": float(bbox[3]),\n        \"is_predict\": is_predicted,\n        \"confidence\": confidence,\n    }\n</code></pre>"
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.mask_to_bbox",
      "title": "<code>mask_to_bbox(mask)</code>",
      "text": "<p>Returns the smallest bounding box containing all the mask pixels</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>np.ndarray</code> <p>Mask as NumPy Array</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: Normalized xywh bounding box</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def mask_to_bbox(mask: np.ndarray) -&gt; list[float]:\n\"\"\"Returns the smallest bounding box containing all the mask pixels\n\n    Args:\n        mask (np.ndarray): Mask as NumPy Array\n\n    Returns:\n        list[float]: Normalized xywh bounding box\n    \"\"\"\n\n    height, width = mask.shape\n    bool_mask = np.array(mask).astype(bool)\n\n    # Find all columns and rows that contain ones\n    rows = np.any(bool_mask, axis=1)\n    cols = np.any(bool_mask, axis=0)\n\n    # Find the min and max col/row index that contain ones\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    # Calculate bbox height and width\n    w = (cmax - cmin + 1) / width\n    h = (rmax - rmin + 1) / height\n\n    return [cmin / width, rmin / height, w, h]\n</code></pre>"
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.normalize",
      "title": "<code>normalize(coord, height, width)</code>",
      "text": "<p>Normalize coordinates</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Unnormalized coordinates</p> required <code>height</code> <code>int</code> <p>Height</p> required <code>width</code> <code>int</code> <p>Width</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: Normalized coordinates</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def normalize(coord: list[float], height: int, width: int) -&gt; list[float]:\n\"\"\"Normalize coordinates\n\n    Args:\n        coord (list[float]): Unnormalized coordinates\n        height (int): Height\n        width (int): Width\n\n    Returns:\n        list[float]: Normalized coordinates\n    \"\"\"\n\n    norm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            norm.append(c / width)\n        else:\n            norm.append(c / height)\n\n    return norm\n</code></pre>"
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.urle_to_bbox",
      "title": "<code>urle_to_bbox(urle)</code>",
      "text": "<p>Returns the smallest bounding box containing all the mask pixels</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: Normalized xywh bounding box</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def urle_to_bbox(urle: dict) -&gt; list[float]:\n\"\"\"Returns the smallest bounding box containing all the mask pixels\n\n    Args:\n        urle (dict): Mask as uncompressed RLE\n\n    Returns:\n        list[float]: Normalized xywh bounding box\n    \"\"\"\n\n    return mask_to_bbox(rle_to_mask(urle_to_rle(urle)))\n</code></pre>"
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.xywh_to_xyxy",
      "title": "<code>xywh_to_xyxy(xywh)</code>",
      "text": "<p>Convert bounding box coordinates from xywh (using top left point as reference) to xyxy</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>xywh coordinates</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: xyxy coordinates</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def xywh_to_xyxy(xywh: list[float]) -&gt; list[float]:\n\"\"\"Convert bounding box coordinates from xywh (using top left point as reference) to xyxy\n\n    Args:\n        xywh (list[float]): xywh coordinates\n\n    Returns:\n        list[float]: xyxy coordinates\n    \"\"\"\n\n    return [\n        float(xywh[0]),\n        float(xywh[1]),\n        float(xywh[0] + xywh[2]),\n        float(xywh[1] + xywh[3]),\n    ]\n</code></pre>"
    },
    {
      "location": "code/transforms/boxes/#transforms.boxes.xyxy_to_xywh",
      "title": "<code>xyxy_to_xywh(xyxy)</code>",
      "text": "<p>Convert bounding box coordinates from xyxy to xywh (using top left point as reference)</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>xyxy coordinates</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: xywh coordinates</p> Source code in <code>pixano/transforms/boxes.py</code> <pre><code>def xyxy_to_xywh(xyxy: list[float]) -&gt; list[float]:\n\"\"\"Convert bounding box coordinates from xyxy to xywh (using top left point as reference)\n\n    Args:\n        xyxy (list[float]): xyxy coordinates\n\n    Returns:\n        list[float]: xywh coordinates\n    \"\"\"\n\n    return [\n        float(xyxy[0]),\n        float(xyxy[1]),\n        float(xyxy[2] - xyxy[0]),\n        float(xyxy[3] - xyxy[1]),\n    ]\n</code></pre>"
    },
    { "location": "code/transforms/image/", "title": "image", "text": "" },
    {
      "location": "code/transforms/image/#transforms.image",
      "title": "<code>transforms.image</code>",
      "text": ""
    },
    {
      "location": "code/transforms/image/#transforms.image.binary_to_url",
      "title": "<code>binary_to_url(im_bytes)</code>",
      "text": "<p>Encode image from binary to base 64 URL</p> <p>Parameters:</p> Name Type Description Default <code>im_bytes</code> <code>bytes</code> <p>Image as binary</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Image as base 64</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def binary_to_url(im_bytes: bytes) -&gt; str:\n\"\"\"Encode image from binary to base 64 URL\n\n    Args:\n        im_bytes (bytes): Image as binary\n\n    Returns:\n        str: Image as base 64\n    \"\"\"\n\n    if im_bytes is not None:\n        encoded = base64.b64encode(im_bytes).decode(\"utf-8\")\n        return f\"data:image;base64,{encoded}\"\n    else:\n        return \"\"\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.depth_array_to_gray",
      "title": "<code>depth_array_to_gray(depth, valid_start=0.2, valid_end=1, scale=1.0)</code>",
      "text": "<p>Encode depth array to gray levels</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>np.ndarray</code> <p>Depth array</p> required <code>valid_start</code> <code>float</code> <p>Valid start. Defaults to 0.2.</p> <code>0.2</code> <code>valid_end</code> <code>float</code> <p>Valid end. Defaults to 1.</p> <code>1</code> <code>scale</code> <code>float</code> <p>Scale. Defaults to 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Depth array in gray levels</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def depth_array_to_gray(\n    depth: np.ndarray,\n    valid_start: float = 0.2,\n    valid_end: float = 1,\n    scale: float = 1.0,\n) -&gt; np.ndarray:\n\"\"\"Encode depth array to gray levels\n\n    Args:\n        depth (np.ndarray): Depth array\n        valid_start (float, optional): Valid start. Defaults to 0.2.\n        valid_end (float, optional): Valid end. Defaults to 1.\n        scale (float, optional): Scale. Defaults to 1.0.\n\n    Returns:\n        np.ndarray: Depth array in gray levels\n    \"\"\"\n\n    mask = depth &gt; 1\n\n    # Scale gives depth in mm\n    depth_n = depth * scale * 0.001\n\n    if mask.sum() &gt; 0:\n        depth_n[mask] -= depth_n[mask].min()\n        depth_n[mask] /= depth_n[mask].max() / (valid_end - valid_start)\n        depth_n[mask] += valid_start\n\n    depth_n *= 255\n    depth_n = cv2.applyColorMap(\n        depth_n[:, :, np.newaxis].astype(np.uint8), cv2.COLORMAP_PLASMA\n    )\n\n    return depth_n\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.depth_file_to_binary",
      "title": "<code>depth_file_to_binary(depth_path)</code>",
      "text": "<p>Encode depth file to RGB image in binary</p> <p>Parameters:</p> Name Type Description Default <code>depth_path</code> <code>str</code> <p>Depth file path</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Depth file as RGB image in binary</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def depth_file_to_binary(depth_path: str) -&gt; bytes:\n\"\"\"Encode depth file to RGB image in binary\n\n    Args:\n        depth_path (str): Depth file path\n\n    Returns:\n        bytes: Depth file as RGB image in binary\n    \"\"\"\n\n    depth = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH).astype(np.float32)\n    depth = depth_array_to_gray(depth)\n    depth_rgb = Image.fromarray(depth)\n\n    return image_to_binary(depth_rgb)\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.encode_rle",
      "title": "<code>encode_rle(mask, height, width)</code>",
      "text": "<p>Encode mask from polygons / uncompressed RLE / RLE to RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict</code> <p>Mask as polygons / uncompressed RLE / RLE</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def encode_rle(mask: list[list] | dict, height: int, width: int) -&gt; dict:\n\"\"\"Encode mask from polygons / uncompressed RLE / RLE to RLE\n\n    Args:\n        mask (list[list] | dict): Mask as polygons / uncompressed RLE / RLE\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if isinstance(mask, list):\n        rle = polygons_to_rle(mask, height, width)\n    elif isinstance(mask, dict):\n        if isinstance(mask[\"counts\"], list):\n            rle = urle_to_rle(mask)\n        else:\n            rle = mask\n    else:\n        rle = None\n    return rle\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.image_to_binary",
      "title": "<code>image_to_binary(image, format='PNG')</code>",
      "text": "<p>Encode image from Pillow to binary</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image.Image</code> <p>Image as Pillow</p> required <code>format</code> <code>str</code> <p>Image file extension. Defaults to \"PNG\".</p> <code>'PNG'</code> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Image as binary</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def image_to_binary(image: Image.Image, format: str = \"PNG\") -&gt; bytes:\n\"\"\"Encode image from Pillow to binary\n\n    Args:\n        image (Image.Image): Image as Pillow\n        format (str, optional): Image file extension. Defaults to \"PNG\".\n\n    Returns:\n        bytes: Image as binary\n    \"\"\"\n\n    with BytesIO() as output_bytes:\n        image.save(output_bytes, format)\n        im_bytes = output_bytes.getvalue()\n\n    return im_bytes\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.image_to_thumbnail",
      "title": "<code>image_to_thumbnail(image)</code>",
      "text": "<p>Generate image thumbnail</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>bytes | Image.Image</code> <p>Image as binary or as Pillow</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Image thumbnail as binary</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def image_to_thumbnail(image: bytes | Image.Image) -&gt; bytes:\n\"\"\"Generate image thumbnail\n\n    Args:\n        image (bytes | Image.Image): Image as binary or as Pillow\n\n    Returns:\n        bytes: Image thumbnail as binary\n    \"\"\"\n\n    if isinstance(image, bytes):\n        image = Image.open(BytesIO(image))\n\n    image.thumbnail((128, 128))\n    return image_to_binary(image)\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.mask_to_polygons",
      "title": "<code>mask_to_polygons(mask)</code>",
      "text": "<p>Encode mask from NumPy array to polygons</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>np.ndarray</code> <p>Mask as NumPy array</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>Mask as polygons</p> <code>bool</code> <code>bool</code> <p>Mask has holes</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def mask_to_polygons(mask: np.ndarray) -&gt; tuple[list, bool]:\n\"\"\"Encode mask from NumPy array to polygons\n\n    Args:\n        mask (np.ndarray): Mask as NumPy array\n\n    Returns:\n        list: Mask as polygons\n        bool: Mask has holes\n    \"\"\"\n\n    if mask is not None:\n        # Some versions of cv2 does not support incontiguous arr\n        mask = np.ascontiguousarray(mask)\n\n        # cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level hierarchy.\n        # External contours (boundary) of the object are placed in hierarchy-1.\n        # Internal contours (holes) are placed in hierarchy-2.\n        # cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.\n        res = cv2.findContours(\n            mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n        )\n        hierarchy = res[-1]\n\n        # If mask is empty\n        if hierarchy is None:\n            return [], False\n\n        # Check if mask has holes\n        has_holes = (hierarchy.reshape(-1, 4)[:, 3] &gt;= 0).sum() &gt; 0\n\n        res = res[-2]\n        res = [x.flatten() for x in res]\n\n        # The coordinates from OpenCV are integers in range [0, W-1 or H-1].\n        # We add 0.5 to turn them into real-value coordinate space. A better solution\n        # would be to first +0.5 and then dilate the returned polygon by 0.5.\n        res = [x + 0.5 for x in res if len(x) &gt;= 6]\n\n        return res, has_holes\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.mask_to_rle",
      "title": "<code>mask_to_rle(mask)</code>",
      "text": "<p>Encode mask from Pillow or NumPy array to RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image.Image</code> <p>Mask as Pillow or NumPy array</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def mask_to_rle(mask: Image.Image) -&gt; dict:\n\"\"\"Encode mask from Pillow or NumPy array to RLE\n\n    Args:\n        mask (Image.Image): Mask as Pillow or NumPy array\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if mask is not None:\n        mask_array = np.asfortranarray(mask)\n        return mask_api.encode(mask_array)\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.polygons_to_rle",
      "title": "<code>polygons_to_rle(polygons, height, width)</code>",
      "text": "<p>Encode mask from polygons to RLE</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>Mask as polygons</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def polygons_to_rle(polygons: list[list], height: int, width: int) -&gt; dict:\n\"\"\"Encode mask from polygons to RLE\n\n    Args:\n        polygons (list[list]): Mask as polygons\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if polygons is not None:\n        rles = mask_api.frPyObjects(polygons, height, width)\n        return mask_api.merge(rles)\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.rle_to_mask",
      "title": "<code>rle_to_mask(rle)</code>",
      "text": "<p>Decode mask from RLE to NumPy array</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Mask as NumPy array</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def rle_to_mask(rle: dict) -&gt; np.ndarray:\n\"\"\"Decode mask from RLE to NumPy array\n\n    Args:\n        rle (dict): Mask as RLE\n\n    Returns:\n        np.ndarray: Mask as NumPy array\n    \"\"\"\n\n    if rle is not None:\n        return mask_api.decode(rle)\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.rle_to_polygons",
      "title": "<code>rle_to_polygons(rle)</code>",
      "text": "<p>Encode mask from RLE to polygons</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>list[list]</code> <p>list[list]: Mask as polygons</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def rle_to_polygons(rle: dict) -&gt; list[list]:\n\"\"\"Encode mask from RLE to polygons\n\n    Args:\n        rle (dict): Mask as RLE\n\n    Returns:\n        list[list]: Mask as polygons\n    \"\"\"\n\n    if rle is not None and \"size\" in rle:\n        h, w = rle[\"size\"]\n        polygons, _ = mask_to_polygons(rle_to_mask(rle))\n\n        # Normalize point coordinates\n        for p in polygons:\n            p[::2] /= w\n            p[1::2] /= h\n\n        # Cast to python list\n        polygons = [p.tolist() for p in polygons]\n\n        return polygons\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.rle_to_urle",
      "title": "<code>rle_to_urle(rle)</code>",
      "text": "<p>Encode mask from RLE to uncompressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict</code> <p>Mask as RLE</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Mask as uncompressed RLE</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def rle_to_urle(rle: dict) -&gt; dict:\n\"\"\"Encode mask from RLE to uncompressed RLE\n\n    Args:\n        rle (dict): Mask as RLE\n\n    Returns:\n        dict: Mask as uncompressed RLE\n    \"\"\"\n\n    if rle is not None:\n        mask = rle_to_mask(rle)\n        urle = {\"counts\": [], \"size\": list(mask.shape)}\n        counts = urle.get(\"counts\")\n\n        for i, (value, elements) in enumerate(groupby(mask.ravel(order=\"F\"))):\n            if i == 0 and value == 1:\n                counts.append(0)\n            counts.append(len(list(elements)))\n\n        return urle\n</code></pre>"
    },
    {
      "location": "code/transforms/image/#transforms.image.urle_to_rle",
      "title": "<code>urle_to_rle(urle)</code>",
      "text": "<p>Encode mask from uncompressed RLE to RLE</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/transforms/image.py</code> <pre><code>def urle_to_rle(urle: dict) -&gt; dict:\n\"\"\"Encode mask from uncompressed RLE to RLE\n\n    Args:\n        urle (dict): Mask as uncompressed RLE\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if urle is not None:\n        height, width = urle[\"size\"]\n        return mask_api.frPyObjects(urle, height, width)\n</code></pre>"
    },
    { "location": "code/transforms/labels/", "title": "labels", "text": "" },
    {
      "location": "code/transforms/labels/#transforms.labels",
      "title": "<code>transforms.labels</code>",
      "text": ""
    },
    {
      "location": "code/transforms/labels/#transforms.labels.coco_ids_80to91",
      "title": "<code>coco_ids_80to91(id)</code>",
      "text": "<p>Return COCO category ID (80 to 91 classes)</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>Category ID (80 classes)</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Category ID (91 classes)</p> Source code in <code>pixano/transforms/labels.py</code> <pre><code>def coco_ids_80to91(id: int) -&gt; int:\n\"\"\"Return COCO category ID (80 to 91 classes)\n\n    Args:\n        id (int): Category ID (80 classes)\n\n    Returns:\n        int: Category ID (91 classes)\n    \"\"\"\n\n    coco_dict = {\n        1: 1,\n        2: 2,\n        3: 3,\n        4: 4,\n        5: 5,\n        6: 6,\n        7: 7,\n        8: 8,\n        9: 9,\n        10: 10,\n        11: 11,\n        12: 13,\n        13: 14,\n        14: 15,\n        15: 16,\n        16: 17,\n        17: 18,\n        18: 19,\n        19: 20,\n        20: 21,\n        21: 22,\n        22: 23,\n        23: 24,\n        24: 25,\n        25: 27,\n        26: 28,\n        27: 31,\n        28: 32,\n        29: 33,\n        30: 34,\n        31: 35,\n        32: 36,\n        33: 37,\n        34: 38,\n        35: 39,\n        36: 40,\n        37: 41,\n        38: 42,\n        39: 43,\n        40: 44,\n        41: 46,\n        42: 47,\n        43: 48,\n        44: 49,\n        45: 50,\n        46: 51,\n        47: 52,\n        48: 53,\n        49: 54,\n        50: 55,\n        51: 56,\n        52: 57,\n        53: 58,\n        54: 59,\n        55: 60,\n        56: 61,\n        57: 62,\n        58: 63,\n        59: 64,\n        60: 65,\n        61: 67,\n        62: 70,\n        63: 72,\n        64: 73,\n        65: 74,\n        66: 75,\n        67: 76,\n        68: 77,\n        69: 78,\n        70: 79,\n        71: 80,\n        72: 81,\n        73: 82,\n        74: 84,\n        75: 85,\n        76: 86,\n        77: 87,\n        78: 88,\n        79: 89,\n        80: 90,\n    }\n\n    return coco_dict[int(id)]\n</code></pre>"
    },
    {
      "location": "code/transforms/labels/#transforms.labels.coco_names_80",
      "title": "<code>coco_names_80(id)</code>",
      "text": "<p>Return COCO category name (80 classes)</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Category name</p> Source code in <code>pixano/transforms/labels.py</code> <pre><code>def coco_names_80(id: int) -&gt; str:\n\"\"\"Return COCO category name (80 classes)\n\n    Args:\n        id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"stop sign\",\n        13: \"parking meter\",\n        14: \"bench\",\n        15: \"bird\",\n        16: \"cat\",\n        17: \"dog\",\n        18: \"horse\",\n        19: \"sheep\",\n        20: \"cow\",\n        21: \"elephant\",\n        22: \"bear\",\n        23: \"zebra\",\n        24: \"giraffe\",\n        25: \"backpack\",\n        26: \"umbrella\",\n        27: \"handbag\",\n        28: \"tie\",\n        29: \"suitcase\",\n        30: \"frisbee\",\n        31: \"skis\",\n        32: \"snowboard\",\n        33: \"sports ball\",\n        34: \"kite\",\n        35: \"baseball bat\",\n        36: \"baseball glove\",\n        37: \"skateboard\",\n        38: \"surfboard\",\n        39: \"tennis racket\",\n        40: \"bottle\",\n        41: \"wine glass\",\n        42: \"cup\",\n        43: \"fork\",\n        44: \"knife\",\n        45: \"spoon\",\n        46: \"bowl\",\n        47: \"banana\",\n        48: \"apple\",\n        49: \"sandwich\",\n        50: \"orange\",\n        51: \"broccoli\",\n        52: \"carrot\",\n        53: \"hot dog\",\n        54: \"pizza\",\n        55: \"donut\",\n        56: \"cake\",\n        57: \"chair\",\n        58: \"couch\",\n        59: \"potted plant\",\n        60: \"bed\",\n        61: \"dining table\",\n        62: \"toilet\",\n        63: \"tv\",\n        64: \"laptop\",\n        65: \"mouse\",\n        66: \"remote\",\n        67: \"keyboard\",\n        68: \"cell phone\",\n        69: \"microwave\",\n        70: \"oven\",\n        71: \"toaster\",\n        72: \"sink\",\n        73: \"refrigerator\",\n        74: \"book\",\n        75: \"clock\",\n        76: \"vase\",\n        77: \"scissors\",\n        78: \"teddy bear\",\n        79: \"hair drier\",\n        80: \"toothbrush\",\n    }\n\n    return coco_dict[int(id)]\n</code></pre>"
    },
    {
      "location": "code/transforms/labels/#transforms.labels.coco_names_91",
      "title": "<code>coco_names_91(id)</code>",
      "text": "<p>Return COCO category name (91 classes)</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Category name</p> Source code in <code>pixano/transforms/labels.py</code> <pre><code>def coco_names_91(id: int) -&gt; str:\n\"\"\"Return COCO category name (91 classes)\n\n    Args:\n        id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"street sign\",\n        13: \"stop sign\",\n        14: \"parking meter\",\n        15: \"bench\",\n        16: \"bird\",\n        17: \"cat\",\n        18: \"dog\",\n        19: \"horse\",\n        20: \"sheep\",\n        21: \"cow\",\n        22: \"elephant\",\n        23: \"bear\",\n        24: \"zebra\",\n        25: \"giraffe\",\n        26: \"hat\",\n        27: \"backpack\",\n        28: \"umbrella\",\n        29: \"shoe\",\n        30: \"eye glasses\",\n        31: \"handbag\",\n        32: \"tie\",\n        33: \"suitcase\",\n        34: \"frisbee\",\n        35: \"skis\",\n        36: \"snowboard\",\n        37: \"sports ball\",\n        38: \"kite\",\n        39: \"baseball bat\",\n        40: \"baseball glove\",\n        41: \"skateboard\",\n        42: \"surfboard\",\n        43: \"tennis racket\",\n        44: \"bottle\",\n        45: \"plate\",\n        46: \"wine glass\",\n        47: \"cup\",\n        48: \"fork\",\n        49: \"knife\",\n        50: \"spoon\",\n        51: \"bowl\",\n        52: \"banana\",\n        53: \"apple\",\n        54: \"sandwich\",\n        55: \"orange\",\n        56: \"broccoli\",\n        57: \"carrot\",\n        58: \"hot dog\",\n        59: \"pizza\",\n        60: \"donut\",\n        61: \"cake\",\n        62: \"chair\",\n        63: \"couch\",\n        64: \"potted plant\",\n        65: \"bed\",\n        66: \"mirror\",\n        67: \"dining table\",\n        68: \"window\",\n        69: \"desk\",\n        70: \"toilet\",\n        71: \"door\",\n        72: \"tv\",\n        73: \"laptop\",\n        74: \"mouse\",\n        75: \"remote\",\n        76: \"keyboard\",\n        77: \"cell phone\",\n        78: \"microwave\",\n        79: \"oven\",\n        80: \"toaster\",\n        81: \"sink\",\n        82: \"refrigerator\",\n        83: \"blender\",\n        84: \"book\",\n        85: \"clock\",\n        86: \"vase\",\n        87: \"scissors\",\n        88: \"teddy bear\",\n        89: \"hair drier\",\n        90: \"toothbrush\",\n        91: \"hair brush\",\n    }\n\n    return coco_dict[int(id)]\n</code></pre>"
    },
    {
      "location": "code/transforms/labels/#transforms.labels.dota_ids",
      "title": "<code>dota_ids(name)</code>",
      "text": "<p>Return DOTAv2 category ID (18 classes)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>int</code> <p>Category name</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>int</code> <p>Category ID</p> Source code in <code>pixano/transforms/labels.py</code> <pre><code>def dota_ids(name: str) -&gt; int:\n\"\"\"Return DOTAv2 category ID (18 classes)\n\n    Args:\n        name (int): Category name\n\n    Returns:\n        str: Category ID\n    \"\"\"\n\n    dota_dict = {\n        \"plane\": 1,\n        \"ship\": 2,\n        \"storage tank\": 3,\n        \"baseball diamond\": 4,\n        \"tennis court\": 5,\n        \"basketball court\": 6,\n        \"ground track field\": 7,\n        \"harbor\": 8,\n        \"bridge\": 9,\n        \"large vehicle\": 10,\n        \"small vehicle\": 11,\n        \"helicopter\": 12,\n        \"roundabout\": 13,\n        \"soccer ball field\": 14,\n        \"swimming pool\": 15,\n        \"container crane\": 16,\n        \"airport\": 17,\n        \"helipad\": 18,\n    }\n\n    return dota_dict[str(name).replace(\"-\", \" \")]\n</code></pre>"
    },
    {
      "location": "code/transforms/labels/#transforms.labels.voc_names",
      "title": "<code>voc_names(id)</code>",
      "text": "<p>Return VOC category name (20 classes)</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Category name</p> Source code in <code>pixano/transforms/labels.py</code> <pre><code>def voc_names(id: int) -&gt; str:\n\"\"\"Return VOC category name (20 classes)\n\n    Args:\n        id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    voc_dict = {\n        1: \"aeroplane\",\n        2: \"bicycle\",\n        3: \"bird\",\n        4: \"boat\",\n        5: \"bottle\",\n        6: \"bus\",\n        7: \"car\",\n        8: \"cat\",\n        9: \"chair\",\n        10: \"cow\",\n        11: \"dining table\",\n        12: \"dog\",\n        13: \"horse\",\n        14: \"motorbike\",\n        15: \"person\",\n        16: \"potted plant\",\n        17: \"sheep\",\n        18: \"sofa\",\n        19: \"train\",\n        20: \"tv / monitor\",\n    }\n\n    return voc_dict[int(id)]\n</code></pre>"
    },
    {
      "location": "user/",
      "title": "Getting started with Pixano",
      "text": "<ul> <li>Install Pixano</li> <li>Use your existing datasets<ul> <li>Check out this Jupyter notebook for importing your datasets to Pixano</li> <li>Check out this Jupyter notebook for exporting your annotated datasets from Pixano</li> </ul> </li> <li>Use the Pixano apps<ul> <li>Learn how to launch an app</li> <li>Read our user guide for Pixano Explorer</li> <li>Read our user guide for Pixano Annotator</li> </ul> </li> </ul>"
    },
    {
      "location": "user/annotator/",
      "title": "Using Pixano Annotator",
      "text": ""
    },
    {
      "location": "user/annotator/#home-page",
      "title": "Home page",
      "text": "<p>From the Annotator home page, you will be greeted with a list of all the Pixano format datasets found in the directory you provided.</p> <p>For each dataset, you can see its name, the number of elements inside it, and a thumbnail composed from six sample elements.</p> <p>You can hover over a dataset name to check the dataset description if it has one.</p> <p>You can click on a dataset to open its annotation page on its first element.</p>"
    },
    {
      "location": "user/annotator/#annotation-page",
      "title": "Annotation page",
      "text": ""
    },
    {
      "location": "user/annotator/#element-view",
      "title": "Element view",
      "text": "<p>The selected element (image or images for multi-view datasets) is displayed.</p> <p>You can zoom in and out with the mouse wheel.</p> <p>You can grab and move images with the middle click or with the Pan tool available in the left-hand toolbar. </p> <p>You can double click on an image to move it above other images.</p> <p>Annotations, in form of segmentation mask, are displayed. Each object category is given a color.</p> <p>On the top of the image, when you have an input Tool selected, a panel is displayed that allows to choose a category.</p>"
    },
    {
      "location": "user/annotator/#left-toolbar",
      "title": "Left toolbar",
      "text": "<p>A toolbar is available on the left-hand side of the page with the following tools:</p> <ul> <li>Pan: Allows you to grab and move an image</li> <li>Points: Allows you to place input points to interactively segment your image<ul> <li>You can place positive points with the + tool (points shown in green) to indicate what must be included in the segmentation</li> <li>You can place negative points with - tool (points shown in red) to indicate what must not be included in the segmentation</li> <li>You can hover over any point and press the Del key to remove it</li> <li>You can click and hold on any point to relocate it</li> </ul> </li> <li>Rectangle: Allows you to draw rectangles approximatively around the objects of interest to interactively segment them<ul> <li>You can click and drag on the image to draw a rectangle</li> <li>There can only be one rectangle at a time, so drawing a new rectangle will discard the previous one. You have to validate the obtained segmentation, if satisfactory, before drawing a new rectangle</li> </ul> </li> </ul> <p>The Points and Rectangle tools depend on an ONNX segmentation model you have to provide. Please look at the interactive annotation documentation and notebook for more information. </p> <p>More tools will be coming soon.</p>"
    },
    {
      "location": "user/annotator/#center-toolbar",
      "title": "Center toolbar",
      "text": "<p>When an annotation tool is selected, a toolbar is available at the center on the page.</p> <p>Enter the label name for your annotation in the text box or select the label from the list of existing labels.</p> <p>If the Points tool is selected, a + icon and a - icon allow to quickly switch between positive and negative points</p> <p>Validate your annotation with the entered label by cliking on the Validate icon, or press Enter key.</p>"
    },
    {
      "location": "user/annotator/#right-toolbar",
      "title": "Right toolbar",
      "text": "<p>A toolbar is available on the right side of the page with the following tabs:</p> <ul> <li>Labels: This tab displays your annotations grouped by views and by labels<ul> <li>Each annotation group can be opened or closed by clicking on it</li> <li>Each annotation and annotation group can be shown or hidden on the relevant image by clicking on the Visibility icon</li> <li>Each annotation can be deleted by clicking on the Delete icon</li> <li>Each annotation is represented by its unique ID.</li> </ul> </li> <li>Dataset: This tab allows you to navigate through the dataset<ul> <li>Each element of the dataset is displayed with its ID and its thumbnail</li> <li>The list will automatically expand as you scroll down</li> <li>You can click on any element to change the current element</li> </ul> </li> </ul>"
    },
    {
      "location": "user/annotator/#annotating",
      "title": "Annotating",
      "text": "<p>You can currently annotate with the Points (+ and -), and Rectangle tools available in the left toolbar as described above.</p> <p>When using these tools, the generated annotation will be displayed in green. You can use both tools together to refine your annotation.</p> <p>You can press the Enter key or click the Validate icon of the center toolbar to validate your annotation. You can press the Esc key to reset all your Points and Rectangle inputs.</p>"
    },
    {
      "location": "user/annotator/#saving",
      "title": "Saving",
      "text": "<p>To save your annotations, a Save icon is available in the top right-hand corner. It will be highlighted if there are unsaved changes.</p> <p>If you try to go back to the home page or change element with unsaved changes, you will see a confirmation window. You can choose \"OK\" to discard your changes, or cancel to be able to go back save them.</p>"
    },
    {
      "location": "user/annotator/#going-home",
      "title": "Going home",
      "text": "<p>To go back to the home page, click on \"Pixano Annotator\" in the top left-and corner or on the Close icon in the top right-hand corner.</p>"
    },
    {
      "location": "user/explorer/",
      "title": "Using Pixano Explorer",
      "text": ""
    },
    {
      "location": "user/explorer/#home-page",
      "title": "Home page",
      "text": "<p>From the Explorer home page, you will be greeted with a list of all the datasets in Pixano format found in the directory you provided.</p> <p>For each dataset, you can see its name, the number of elements inside it, and a thumbnail composed from six sample elements.</p> <p>You can hover over a dataset name to check the dataset description if it has one.</p> <p>You can click on a dataset to open its exploration page.</p>"
    },
    {
      "location": "user/explorer/#exploration-page",
      "title": "Exploration page",
      "text": ""
    },
    {
      "location": "user/explorer/#statistics",
      "title": "Statistics",
      "text": "<p>Available statistics will be displayed on the left side of the dataset page.</p> <p>You can hover over different elements in the statistics to get more detailed information.</p> <p>Filtering your dataset based on the selected statistics will soon be available.</p>"
    },
    {
      "location": "user/explorer/#elements-list",
      "title": "Elements list",
      "text": "<p>The dataset elements will be displayed on the right side of the dataset page.</p> <p>Elements are displayed in scrollable pages of up to 100 elements.</p> <p>You can navigate between pages with the Previous and Next buttons at the bottom.</p> <p>You can click on any element to open it in the exploration page.</p> <p>For each element, you can see columns for its ID, a thumbnail for each of its media, and the dataset split it comes from.</p> <p>Filtering your dataset based on these columns will soon be available.</p>"
    },
    {
      "location": "user/explorer/#going-home",
      "title": "Going home",
      "text": "<p>To go back to the home page, click on \"Pixano Explorer\" in the top left-hand corner or on the Close icon in the top right-hand corner.</p>"
    },
    {
      "location": "user/explorer/#element-view-page",
      "title": "Element view page",
      "text": ""
    },
    {
      "location": "user/explorer/#element-view",
      "title": "Element view",
      "text": "<p>The selected element (image or images for multi-view datasets) is displayed.</p> <p>You can zoom in and out with the mouse wheel.</p> <p>You can grab and move images on the canvas.</p> <p>You can double click on an image to move it above other images with a multi-view dataset.</p> <p>Annotations, in form of segmentation masks and bounding boxes, are displayed. Each object category is given a color.</p> <p>On each bounding box, the object category is displayed in the top left-hand corner, together with the confidence score if the bounding box was obtained by the inference of a given model.</p>"
    },
    {
      "location": "user/explorer/#right-toolbar",
      "title": "Right toolbar",
      "text": "<p>A toolbar is available on the right side of the page with the following sections:</p> <ul> <li> <p>A Data section to display information on the element, like its ID</p> </li> <li> <p>A Tools section to filter the annotations</p> <ul> <li>The Show all annotations checkbox allows you to toggle annotations visibility</li> <li>The Show bounding boxes checkbox allows you to toggle bounding box visibility</li> <li>The Mask opacity slider allows you to adjust the opacity of segmentation masks</li> <li>The Confidence threshold slider allows you to adjust the threshold to filter the inferred boxes to display</li> <li>The Labels list allows you to see the number of annotations for any label, and to toggle annotations visibility for individual labels by clicking on their names</li> </ul> </li> </ul> <p>More options to display ground truths and inference annotations separately and with different colors will be coming soon.</p> <p>More options for multi-view datasets will be coming soon.</p>"
    },
    {
      "location": "user/explorer/#going-home_1",
      "title": "Going home",
      "text": "<p>To go back to the home page, click on \"Pixano Explorer\" in the top left-hand corner.</p> <p>To go back to the exploration page, click on the dataset name in the top left-hand corner or on the Close icon in the top right-hand corner, or press the Esc key.</p>"
    },
    {
      "location": "user/export/",
      "title": "Exporting datasets",
      "text": "<p>Please refer to this Jupyter notebook for information on how to export your datasets.</p>"
    },
    {
      "location": "user/import/",
      "title": "Importing datasets",
      "text": "<p>Please refer to this Jupyter notebook for information on how to import your datasets.</p>"
    },
    {
      "location": "user/install/",
      "title": "Installing Pixano",
      "text": "<p>As Pixano requires specific versions for its dependencies, we recommend creating a new Python virtual environment to install it.</p> <p>For example, with conda:</p> <pre><code>conda create -n pixano_env python=3.10\nconda activate pixano_env\n</code></pre> <p>Then, you can install the Pixano package inside that environment with pip:</p> <pre><code>pip install pixano\n</code></pre>"
    },
    { "location": "user/launch/", "title": "Launching an app", "text": "" },
    {
      "location": "user/launch/#from-a-terminal",
      "title": "From a terminal",
      "text": "<p>You can start the Pixano Explorer and Annotator apps with the following commands:</p> <pre><code>pixano-explorer &lt;path/to/your/datasets&gt;\n</code></pre> <pre><code>pixano-annotator &lt;path/to/your/datasets&gt;\n</code></pre> <p>You will then be provided with a URL to open in your browser to use the app.</p>"
    },
    {
      "location": "user/launch/#from-a-notebook",
      "title": "From a notebook",
      "text": "<p>If you are in a Jupyter or Google Colab notebook, you can start the Explorer and Annotator apps by running the following cells:</p> <pre><code>from pixano.apps import ExplorerApp\nexplorer = ExplorerApp(&lt;path/to/your/datasets&gt;)\n</code></pre> <pre><code>from pixano.apps import AnnotatorApp\nannotator = AnnotatorApp(&lt;path/to/your/datasets&gt;)\n</code></pre> <p>You can then use the apps directly from the notebook in another cell with:</p> <pre><code>explorer.display()\n</code></pre> <pre><code>annotator.display()\n</code></pre>"
    }
  ]
}
